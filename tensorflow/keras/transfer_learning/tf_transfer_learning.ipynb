{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90321e5c",
   "metadata": {},
   "source": [
    "\n",
    "# TensorFlow Tutorials\n",
    "* [Transfer learning and fine-tuning](https://www.tensorflow.org/guide/keras/transfer_learning)\n",
    "* [Transfer learning and fine-tuning (Image)](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
    "\n",
    "> In this tutorial, you will learn how to classify images of cats and dogs by using transfer learning from a pre-trained network (Mobile Net V2).\n",
    "> First, instantiate a MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the include_top=False argument, you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction.  \n",
    "> This feature extractor converts each 160x160x3 image into a 5x5x1280 block of features. Let's see what it does to an example batch of images:\n",
    "> ```\n",
    "> IMG_SHAPE = IMG_SIZE + (3,)\n",
    "> base_model = tf.keras.applications.MobileNetV2(\n",
    ">     input_shape=IMG_SHAPE, include_top=False, weights='imagenet'\n",
    "> )\n",
    "> \n",
    "> image_batch, label_batch = next(iter(train_dataset))\n",
    "> feature_batch = base_model(image_batch)\n",
    "> print(feature_batch.shape)\n",
    "> ---\n",
    "> (32, 5, 5, 1280)\n",
    "> ```\n",
    "\n",
    "\n",
    "\n",
    "# Machine Learning Mastery\n",
    "\n",
    "* [Transfer Learning in Keras with Computer Vision Models - Pre-Trained Model as Feature Extractor Preprocessor](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)\n",
    "\n",
    "> We will load the model with the classifier output part of the model (VGG16), but manually remove the final output layer. This means that the second last fully connected layer with 4,096 nodes will be the new output layer.\n",
    "> ```\n",
    "> # load model\n",
    "> model = VGG16()\n",
    "> # remove the output layer\n",
    "> model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "> ```\n",
    "\n",
    "The last layer (-1) of the VGG16 model is classificaiton layer. Use up to -2 layer ```fc2``` to extract the feature of 4096 dimensions.\n",
    "\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #\n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 224, 224, 3)       0\n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792\n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928\n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0\n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856\n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584\n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0\n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168\n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080\n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080\n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0\n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160\n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808\n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808\n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0\n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808\n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808\n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808\n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0\n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 25088)             0\n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 4096)              102764544\n",
    "_________________________________________________________________\n",
    "fc2 (Dense)                  (None, 4096)              16781312\n",
    "_________________________________________________________________\n",
    "predictions (Dense)          (None, 1000)              4097000\n",
    "=================================================================\n",
    "Total params: 138,357,544\n",
    "Trainable params: 138,357,544\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b214f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
