{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf91226f",
   "metadata": {},
   "source": [
    "# Keras Input \n",
    "\n",
    "## Input is NOT a Layer\n",
    "\n",
    "Note that ```keras.Input``` is NOT in ```keras.layer``` package as it is not a Layer but a **Tensor**,\n",
    "\n",
    "* [Input Object](https://keras.io/api/layers/core_layers/input/)\n",
    "\n",
    "> Input() is used to instantiate a Keras **tensor**.\n",
    "\n",
    "\n",
    "\n",
    "## Input Shape\n",
    "\n",
    "Because the preprocessing normalization layer is the first layer to take inputs, it requires ```input_shape```.\n",
    "\n",
    "* [Keras input explanation: input_shape, units, batch_size, dim, etc](https://stackoverflow.com/a/44748370/4281353)\n",
    "\n",
    "> Example: if you have 30 images of 50x50 pixels in RGB (3 channels), the shape of your input data is (30,50,50,3). \n",
    "> \n",
    "> Keras demands the input shape at the first layer only, and Keras ignores the first dimension of the input data, which is the batch size. Your model should be able to deal with any batch size, so you define only the other dimensions:\n",
    "> ```\n",
    "> #regardless of how many images I have, each image has this shape   \n",
    "> input_shape = (50,50,3)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530bf2bb",
   "metadata": {},
   "source": [
    "# Regularizer\n",
    "\n",
    "* [What is the difference between kernel, bias, and activity regulizers](https://stats.stackexchange.com/a/383326/105137)\n",
    "\n",
    "> With a neural network regression equation ```ð‘¦=ð‘Šð‘¥+ð‘```\n",
    "> * Kernel Regularizer: Tries to reduce the weights ð‘Š (excluding bias).\n",
    "> * Bias Regularizer: Tries to reduce the bias ð‘\n",
    "> * Activity Regularizer: Tries to reduce the layer's output ```ð‘¦``` thus will reduce the weights and adjust bias so ```ð‘Šð‘¥+ð‘``` is smallest.\n",
    "> \n",
    "> Usually, if you have no prior on the distribution that you wish to model, you would only use the kernel regularizer, since a large enough network can still model your function even if the regularization on the weights are big.\n",
    "> \n",
    "> If you want the output function to pass through (or have an intercept closer to) the origin, you can use the bias regularizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd8b68",
   "metadata": {},
   "source": [
    "---\n",
    "# Categorical Label vs Sparce Categorical Label\n",
    "\n",
    "## Sparse Categorical Label\n",
    "\n",
    "A label is a single index of a class.\n",
    "\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(y_train[:5])\n",
    "-----\n",
    "[[6]\n",
    " [9]\n",
    " [9]\n",
    " [4]\n",
    " [1]]\n",
    "```\n",
    "\n",
    "Need to use ```sparce categorical``` for the loss calculation and metrics to evaluate.\n",
    "\n",
    "* [tf.keras.metrics.sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_categorical_crossentropy)\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    # metrics=['accuracy']   # <--- 'TF/Keras auto detect categorical or sparse category with 'accuracy' string\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "```\n",
    "\n",
    "## Categorical Label\n",
    "\n",
    "A label is one-hot-encoded. Need to use ```categorical``` for the loss calculation and metrics to evaluate.\n",
    "\n",
    "\n",
    "* [tf.keras.metrics.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_crossentropy)\n",
    "\n",
    "```\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.categorical_crossentropy, \n",
    "    # metrics=['accuracy']\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15fde7",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluation Metrics\n",
    "\n",
    "During the training, TF/Keras calculates the evaluation metrics e.g. accuracy, precision, auc, etc.\n",
    "\n",
    "```\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  # <--- metrics Keras calculates during the training\n",
    ")\n",
    "```\n",
    "\n",
    "**String metric** identifier can be used instead of the metrics instance.\n",
    "\n",
    "```\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "For **convenience**, we can specify a string ```'accuracy'``` which TF/Keras auto-detect the correct accuracy metric.\n",
    "\n",
    "```\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    metrics=['accuracy']  <--- 'TF/Keras auto detect categorical or sparse category with 'accuracy' string\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## List of Metrics\n",
    "\n",
    "See [Module: tf.keras.metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) for the available metrices.\n",
    "\n",
    "\n",
    "## Availability of Metrics\n",
    "\n",
    "Metrics e.g. Recall, Prcision, AUC are only for **Binary** categorical labels only.\n",
    "\n",
    "Example of the error using ```precision``` for multi categorical label. \n",
    "\n",
    "```\n",
    "print(y_train[:5])\n",
    "-----\n",
    "[[6]\n",
    " [9]\n",
    " [9]\n",
    " [4]\n",
    " [1]]\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    metrics=[tf.keras.metrics.Precision()]\n",
    ")\n",
    "model.fit(X=x_train, y_train)\n",
    "-----\n",
    "ValueError: Shapes (32, 10) and (32, 1) are incompatible  # <--- expected binary 1 class, got 10 classes.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44c6cd",
   "metadata": {},
   "source": [
    "---\n",
    "# Monitoring Metric\n",
    "\n",
    "TF/Keras callbacks e.g. ```EarlyStopping``` monitor the validation metrics during the trainig, \n",
    "\n",
    "* [TensorFlow/Keras where are 'loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error' defined?](https://stackoverflow.com/questions/75479364)\n",
    "\n",
    "> Specify the prefix ```val_```, with the metric computed on validation set. [Available metrics](https://keras.io/api/metrics/) to find the metric names (except ```loss```).\n",
    "\n",
    "```\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # <--- e.g. val_accuracy, val_auc\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x, \n",
    "    y,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    epochs=number_of_epochs,\n",
    "    validation_split=validation_split,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=verbosity,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        earlystop_callback\n",
    "    ]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e01f8f",
   "metadata": {},
   "source": [
    "---\n",
    "# Monitoring Mode\n",
    "\n",
    "* [ModelCheckpoint](https://keras.io/api/callbacks/model_checkpoint/)\n",
    "\n",
    "> * mode: one of {'auto', 'min', 'max'}.  \n",
    "> \n",
    "> Based on either **the maximization or the minimization of the monitored quantity**. For ```val_acc```, this should be **max**, for ```val_loss``` this should be **min**, etc. In ```auto``` mode, the mode is set to **max** if the quantities monitored are ```'acc'``` or start with ```'fmeasure'``` and are set to ```min``` for the rest of the quantities.\n",
    "\n",
    "```\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',          # <--- validation loss should be minimizing, hence 'min'\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
