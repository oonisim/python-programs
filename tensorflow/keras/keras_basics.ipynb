{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf91226f",
   "metadata": {},
   "source": [
    "# Keras Input \n",
    "\n",
    "## Input is NOT a Layer\n",
    "\n",
    "Note that ```keras.Input``` is NOT in ```keras.layer``` package as it is not a Layer but a **Tensor**,\n",
    "\n",
    "* [Input Object](https://keras.io/api/layers/core_layers/input/)\n",
    "\n",
    "> Input() is used to instantiate a Keras **tensor**.\n",
    "\n",
    "\n",
    "\n",
    "## Input Shape\n",
    "\n",
    "Because the preprocessing normalization layer is the first layer to take inputs, it requires ```input_shape```.\n",
    "\n",
    "* [Keras input explanation: input_shape, units, batch_size, dim, etc](https://stackoverflow.com/a/44748370/4281353)\n",
    "\n",
    "> Example: if you have 30 images of 50x50 pixels in RGB (3 channels), the shape of your input data is (30,50,50,3). \n",
    "> \n",
    "> Keras demands the input shape at the first layer only, and Keras ignores the first dimension of the input data, which is the batch size. Your model should be able to deal with any batch size, so you define only the other dimensions:\n",
    "> ```\n",
    "> #regardless of how many images I have, each image has this shape   \n",
    "> input_shape = (50,50,3)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6480940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
