{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949bbc15",
   "metadata": {},
   "source": [
    "# Tensorflow Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f17ad",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Classify structured data using Keras preprocessing layers](https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers)\n",
    "\n",
    "> This tutorial demonstrates how to classify structured data, such as tabular data, using a simplified version of the PetFinder dataset from a Kaggle competition stored in a CSV file.\n",
    "\n",
    "## [tf.keras.layers.CategoryEncoding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding)\n",
    "\n",
    "Keras preprocessing Category encoding layer.\n",
    "\n",
    "\n",
    "## [tf.one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot)\n",
    "* ```tf.one_hot``` does **NOT accept string** categories. You must convert strings into integers by yourself.\n",
    "* ```tf.one_hot``` needs **depth** to tell how many unique categories.\n",
    "\n",
    "\n",
    "### tf.feature_columns\n",
    "\n",
    "This is for TF1. DO NOT USE for TF2.\n",
    "\n",
    "* [Classify structured data with feature columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns)\n",
    "\n",
    "> tf.feature_columns module was designed for use with TF1 Estimators. In TF2, Keras preprocessing layers cover this functionality, for migration instructions see the Migrating feature columns guide.\n",
    "\n",
    "\n",
    "<img src=\"./image/keras_category_encoding.png\" align=\"left\" width=750/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf80e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07af5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "file_path = \"~/.keras/datasets/petfinder-mini/petfinder-mini.csv\"\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', url, extract=True)\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddac0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the original dataset, `'AdoptionSpeed'` of `4` indicates a pet was not adopted.\n",
    "df['label'] = np.where(df['AdoptionSpeed']==4, 0, 1)\n",
    "\n",
    "# Drop unused features.\n",
    "df = df.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1dd18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11537 entries, 0 to 11536\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Type          11537 non-null  object\n",
      " 1   Age           11537 non-null  int64 \n",
      " 2   Breed1        11537 non-null  object\n",
      " 3   Gender        11537 non-null  object\n",
      " 4   Color1        11537 non-null  object\n",
      " 5   Color2        11537 non-null  object\n",
      " 6   MaturitySize  11537 non-null  object\n",
      " 7   FurLength     11537 non-null  object\n",
      " 8   Vaccinated    11537 non-null  object\n",
      " 9   Sterilized    11537 non-null  object\n",
      " 10  Health        11537 non-null  object\n",
      " 11  Fee           11537 non-null  int64 \n",
      " 12  PhotoAmt      11537 non-null  int64 \n",
      " 13  label         11537 non-null  int64 \n",
      "dtypes: int64(4), object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3886a7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1 Gender Color1 Color2 MaturitySize FurLength  \\\n",
       "0  Cat    3                 Tabby   Male  Black  White        Small     Short   \n",
       "1  Cat    1  Domestic Medium Hair   Male  Black  Brown       Medium    Medium   \n",
       "2  Dog    1           Mixed Breed   Male  Brown  White       Medium    Medium   \n",
       "\n",
       "  Vaccinated Sterilized   Health  Fee  PhotoAmt  label  \n",
       "0         No         No  Healthy  100         1      1  \n",
       "1   Not Sure   Not Sure  Healthy    0         2      1  \n",
       "2        Yes         No  Healthy    0         7      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d6626",
   "metadata": {},
   "source": [
    "---\n",
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b45d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(0.8*len(df)), int(0.9*len(df))])\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c772525",
   "metadata": {},
   "source": [
    "## Convert pandas dataframe to TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5818d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('label')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(dataframe),   # <--- X: features\n",
    "        labels             # <--- Y: labels\n",
    "    ))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573a124",
   "metadata": {},
   "source": [
    "## Examin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d92859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 13:59:54.965321: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e0f093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Type': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Age': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'Breed1': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Color1': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Color2': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'MaturitySize': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'FurLength': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Vaccinated': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Sterilized': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Health': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Fee': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'PhotoAmt': TensorSpec(shape=(None,), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.get_structure(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8540b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n",
      "A batch of ages: tf.Tensor([2 7 2 1 1], shape=(5,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([1 1 0 1 1], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Features:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90223bf",
   "metadata": {},
   "source": [
    "---\n",
    "# Keras Preprocessing\n",
    "Note that it is a **Keras layer** which takes a TF dataset as its input.\n",
    "\n",
    "## Categorical value to integer value\n",
    "\n",
    "Use the top N most frequent tokens are used to create the vocabulary. All others will be treated as out-of-vocabulary (OOV). \n",
    "\n",
    "* [StringLookup(max_tokens=N)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup)\n",
    "* [IntegerLookup((max_tokens=N)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup)\n",
    "\n",
    "## Category Encoding (OHE/MHE) Layer in Keras\n",
    "\n",
    "```CategoryEncoding``` layer takes an integer column and produce OHE or MHE encodinged columns. It can NOT accept string, hence string columns or discreet integer columns need to be converted into continuous integers via StringLookup or IntegerLookup.\n",
    "\n",
    "* [CategoryEncoding(num_tokens=None, output_mode=<>)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding)\n",
    "\n",
    "### One Hot Encoding vs Multi Hot Encoding\n",
    "\n",
    "MHE is to save the space. For ```data=['cat', 'dog', 'fish', 'bird', 'ant']```, OHE requires ```N=5``` size array such as ```(1,0,0,0,0)``` for **cat**. MHE uses binary representation hence requires $log_2(N=5)$ size array such as ```[0,0,0]``` for **cat**.\n",
    "\n",
    "\n",
    "* [What exactly is multi-hot encoding and how is it different from one-hot?](https://stats.stackexchange.com/a/467672)\n",
    "\n",
    "> multi-hot-encoding introduces false additive relationships, e.g. ```[0,0,1] + [0,1,0] = [0,1,1]``` that is ```'dog' + 'fish' = 'bird'```. That is the price you pay for the reduced representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc4396",
   "metadata": {},
   "source": [
    "## Keras layer to convert categorical into MHE\n",
    "\n",
    "Convert a TF dataset categorical column (single TF Tensor) into MHE columns (single Tensor having multiple columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0a4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(dataset, name, dtype, max_tokens=None, oov_token=None):\n",
    "    \"\"\"Create a Keras layer to convert a column into Multi Hot Encoding.\n",
    "    The layer function as below.\n",
    "    1. Convert string/integer in the target column (dataset[name]) into indices.\n",
    "       e.g. ['cat', 'dog', 'fish', 'bird', 'ant'] into [0,1,2,3,4]\n",
    "    2. Convert indices in the column into Multi Hot Encoding.\n",
    "    \n",
    "    Args:\n",
    "        dataset: TF Dataset that have the target column against which to create the category_encoding_layer.\n",
    "        name: The name that identifies the target column in the dataset.\n",
    "        max_tokens: \n",
    "            Use the top max_token most frequent tokens are used to create the vocabulary. \n",
    "            All others will be treated as out-of-vocabulary (OOV).\n",
    "\n",
    "    Returns: Keras layer to function as category encoder.\n",
    "    \"\"\"\n",
    "    if dtype == 'string':\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "        oov_token = oov_token if oov_token is not None and isinstance(oov_token, str) else '[UNK]'\n",
    "        lookup = tf.keras.layers.StringLookup(max_tokens=max_tokens, oov_token=oov_token)\n",
    "    else:\n",
    "        # Otherwise, create a layer that turns integer values into integer indices.\n",
    "        oov_token = oov_token if oov_token is not None and isinstance(oov_token, (inf, float)) else -1\n",
    "        lookup = tf.keras.layers.IntegerLookup(max_tokens=max_tokens, oov_token=oov_token)\n",
    "\n",
    "    # Extract the target feature column by \"name\" from the \"dataset\"\n",
    "    feature = dataset.map(lambda features, label: features[name])\n",
    "\n",
    "    # Fit the lookup table (string -> int) to the values in the feature column.\n",
    "    lookup.adapt(feature)\n",
    "\n",
    "    # Encode the integer indices. Multi Hot to save the space.\n",
    "    encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode='multi_hot')\n",
    "\n",
    "    def f(column):\n",
    "        \"\"\"Apply multi-hot encoding\"\"\"\n",
    "        return encoder(lookup(column))\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a99a0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 13:59:56.017142: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Dog'] : [0. 1. 0.]\n",
      "[b'Cat'] : [0. 0. 1.]\n",
      "[b'Dog'] : [0. 1. 0.]\n",
      "[b'Dog'] : [0. 1. 0.]\n",
      "[b'Cat'] : [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Test the string categorical 'Type' column conversion into MHE'\n",
    "tensor_column_categorical_type = tf.constant([\n",
    "    [pet.numpy()] for pet in train_features['Type']\n",
    "])\n",
    "\n",
    "test_type_layer = get_category_encoding_layer(\n",
    "    dataset=train_ds,\n",
    "    name='Type',\n",
    "    dtype='string'\n",
    ")\n",
    "tensor_column_mhe_type = test_type_layer(tensor_column_categorical_type)\n",
    "\n",
    "for i in range(len(tensor_column_categorical_type)):\n",
    "    print(\"{} : {}\".format(\n",
    "    tensor_column_categorical_type[i].numpy(),\n",
    "    tensor_column_mhe_type[i].numpy()\n",
    "))\n",
    "    \n",
    "del test_type_layer, tensor_column_categorical_type, tensor_column_mhe_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc226e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] : [0. 1. 0. 0. 0.]\n",
      "[7] : [1. 0. 0. 0. 0.]\n",
      "[2] : [0. 1. 0. 0. 0.]\n",
      "[1] : [0. 0. 0. 1. 0.]\n",
      "[1] : [0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "tensor_column_categorical_age = tf.constant([\n",
    "    [pet.numpy()] for pet in train_features['Age']\n",
    "])\n",
    "\n",
    "test_age_layer = get_category_encoding_layer(\n",
    "    dataset=train_ds,\n",
    "    name='Age',\n",
    "    dtype='int64',\n",
    "    max_tokens=5\n",
    ")\n",
    "tensor_column_mhe_age = test_age_layer(tensor_column_categorical_age)\n",
    "\n",
    "for i in range(len(tensor_column_categorical_age)):\n",
    "    print(\"{} : {}\".format(\n",
    "    tensor_column_categorical_age[i].numpy(),\n",
    "    tensor_column_mhe_age[i].numpy()\n",
    "))\n",
    "    \n",
    "del test_age_layer, tensor_column_categorical_age, tensor_column_mhe_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f3511",
   "metadata": {},
   "source": [
    "## Keras layer to normalize numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649da93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for the feature.\n",
    "    normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "    # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db88465",
   "metadata": {},
   "source": [
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f332aa",
   "metadata": {},
   "source": [
    "## Split data into training, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e988fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e02199",
   "metadata": {},
   "source": [
    "## Keras model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11e1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e784ab9",
   "metadata": {},
   "source": [
    "## Holizontal Keras preprocessing layers for numerical normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2450898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features.\n",
    "for header in ['PhotoAmt', 'Fee']:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1da937",
   "metadata": {},
   "source": [
    "### Holizontal Keras preprocessing layers for numerical categorical into MHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "425ceb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_input_feature = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "numeric_category_encoding_layer = get_category_encoding_layer(\n",
    "    name='Age',\n",
    "    dataset=train_ds,\n",
    "    dtype='int64',\n",
    "    max_tokens=5\n",
    ")\n",
    "categorically_encoded_feature = numeric_category_encoding_layer(numeric_input_feature)\n",
    "all_inputs.append(numeric_input_feature)\n",
    "encoded_features.append(categorically_encoded_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf9f90",
   "metadata": {},
   "source": [
    "### Holizontal Keras preprocessing layers for String categorical into MHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeaf639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_categorical_columns = [\n",
    "    'Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',  'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1'\n",
    "]\n",
    "\n",
    "for column_name in string_categorical_columns:\n",
    "    string_input_feature = tf.keras.Input(shape=(1,), name=column_name, dtype='string')\n",
    "\n",
    "    # String category encoding layer\n",
    "    string_category_encoding_layer = get_category_encoding_layer(\n",
    "        name=column_name,\n",
    "        dataset=train_ds,\n",
    "        dtype='string',\n",
    "        max_tokens=5,\n",
    "        oov_token='[UNK]'\n",
    "    )\n",
    "    # Categorical encoding\n",
    "    categorically_encoded_feature = string_category_encoding_layer(string_input_feature)\n",
    "\n",
    "    all_inputs.append(string_input_feature)\n",
    "    encoded_features.append(categorically_encoded_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e109748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0da08323",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ba4da",
   "metadata": {},
   "source": [
    "## Keras Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e331c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Use `rankdir='LR'` to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c4c7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 6s 49ms/step - loss: 0.6943 - accuracy: 0.4642 - val_loss: 0.5723 - val_accuracy: 0.6967\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.5991 - accuracy: 0.6475 - val_loss: 0.5453 - val_accuracy: 0.7357\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5710 - accuracy: 0.6698 - val_loss: 0.5323 - val_accuracy: 0.7444\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.5598 - accuracy: 0.6892 - val_loss: 0.5261 - val_accuracy: 0.7426\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 1s 29ms/step - loss: 0.5489 - accuracy: 0.7016 - val_loss: 0.5217 - val_accuracy: 0.7392\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.5415 - accuracy: 0.7067 - val_loss: 0.5184 - val_accuracy: 0.7383\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.5372 - accuracy: 0.7017 - val_loss: 0.5165 - val_accuracy: 0.7409\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5309 - accuracy: 0.7052 - val_loss: 0.5154 - val_accuracy: 0.7418\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.5327 - accuracy: 0.7125 - val_loss: 0.5137 - val_accuracy: 0.7322\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.5284 - accuracy: 0.7173 - val_loss: 0.5126 - val_accuracy: 0.7331\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.5263 - accuracy: 0.7095 - val_loss: 0.5116 - val_accuracy: 0.7331\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5259 - accuracy: 0.7142 - val_loss: 0.5099 - val_accuracy: 0.7340\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.5231 - accuracy: 0.7175 - val_loss: 0.5093 - val_accuracy: 0.7400\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5220 - accuracy: 0.7176 - val_loss: 0.5093 - val_accuracy: 0.7374\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5175 - accuracy: 0.7259 - val_loss: 0.5082 - val_accuracy: 0.7348\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 0.5195 - accuracy: 0.7237 - val_loss: 0.5085 - val_accuracy: 0.7253\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.5175 - accuracy: 0.7229 - val_loss: 0.5074 - val_accuracy: 0.7288\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.5167 - accuracy: 0.7266 - val_loss: 0.5070 - val_accuracy: 0.7279\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.5180 - accuracy: 0.7154 - val_loss: 0.5063 - val_accuracy: 0.7322\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5151 - accuracy: 0.7221 - val_loss: 0.5055 - val_accuracy: 0.7322\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5133 - accuracy: 0.7240 - val_loss: 0.5054 - val_accuracy: 0.7357\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.5136 - accuracy: 0.7300 - val_loss: 0.5055 - val_accuracy: 0.7348\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.5146 - accuracy: 0.7261 - val_loss: 0.5050 - val_accuracy: 0.7366\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.5118 - accuracy: 0.7276 - val_loss: 0.5050 - val_accuracy: 0.7383\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5131 - accuracy: 0.7223 - val_loss: 0.5043 - val_accuracy: 0.7357\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5116 - accuracy: 0.7271 - val_loss: 0.5047 - val_accuracy: 0.7374\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.5092 - accuracy: 0.7312 - val_loss: 0.5043 - val_accuracy: 0.7348\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 2s 40ms/step - loss: 0.5114 - accuracy: 0.7233 - val_loss: 0.5043 - val_accuracy: 0.7357\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 1s 33ms/step - loss: 0.5108 - accuracy: 0.7304 - val_loss: 0.5037 - val_accuracy: 0.7444\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.5107 - accuracy: 0.7292 - val_loss: 0.5036 - val_accuracy: 0.7348\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.5093 - accuracy: 0.7266 - val_loss: 0.5036 - val_accuracy: 0.7340\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 0.5088 - accuracy: 0.7315 - val_loss: 0.5029 - val_accuracy: 0.7322\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5092 - accuracy: 0.7269 - val_loss: 0.5027 - val_accuracy: 0.7374\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5052 - accuracy: 0.7366 - val_loss: 0.5029 - val_accuracy: 0.7296\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.5059 - accuracy: 0.7308 - val_loss: 0.5032 - val_accuracy: 0.7305\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 0.5074 - accuracy: 0.7316 - val_loss: 0.5035 - val_accuracy: 0.7383\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.5079 - accuracy: 0.7300 - val_loss: 0.5030 - val_accuracy: 0.7392\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.5047 - accuracy: 0.7319 - val_loss: 0.5033 - val_accuracy: 0.7383\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5079 - accuracy: 0.7298 - val_loss: 0.5031 - val_accuracy: 0.7357\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.5061 - accuracy: 0.7313 - val_loss: 0.5021 - val_accuracy: 0.7409\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.5042 - accuracy: 0.7349 - val_loss: 0.5025 - val_accuracy: 0.7357\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5091 - accuracy: 0.7310 - val_loss: 0.5022 - val_accuracy: 0.7426\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 1s 30ms/step - loss: 0.5016 - accuracy: 0.7376 - val_loss: 0.5026 - val_accuracy: 0.7374\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 1s 29ms/step - loss: 0.5012 - accuracy: 0.7340 - val_loss: 0.5022 - val_accuracy: 0.7409\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.5044 - accuracy: 0.7373 - val_loss: 0.5022 - val_accuracy: 0.7340\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.5047 - accuracy: 0.7314 - val_loss: 0.5022 - val_accuracy: 0.7383\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 1s 27ms/step - loss: 0.5023 - accuracy: 0.7379 - val_loss: 0.5019 - val_accuracy: 0.7322\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 0.5069 - accuracy: 0.7324 - val_loss: 0.5017 - val_accuracy: 0.7357\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.5013 - accuracy: 0.7390 - val_loss: 0.5010 - val_accuracy: 0.7374\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 1s 34ms/step - loss: 0.5022 - accuracy: 0.7349 - val_loss: 0.5010 - val_accuracy: 0.7357\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 2s 36ms/step - loss: 0.5026 - accuracy: 0.7373 - val_loss: 0.5013 - val_accuracy: 0.7366\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 1s 35ms/step - loss: 0.5036 - accuracy: 0.7380 - val_loss: 0.5017 - val_accuracy: 0.7418\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 0.5004 - accuracy: 0.7391 - val_loss: 0.5012 - val_accuracy: 0.7400\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.5016 - accuracy: 0.7368 - val_loss: 0.5011 - val_accuracy: 0.7340\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.5010 - accuracy: 0.7391 - val_loss: 0.5009 - val_accuracy: 0.7400\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.5055 - accuracy: 0.7364 - val_loss: 0.5008 - val_accuracy: 0.7409\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.5037 - accuracy: 0.7375 - val_loss: 0.5014 - val_accuracy: 0.7392\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 22ms/step - loss: 0.5036 - accuracy: 0.7301 - val_loss: 0.5013 - val_accuracy: 0.7444\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5030 - accuracy: 0.7424 - val_loss: 0.5009 - val_accuracy: 0.7418\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.5024 - accuracy: 0.7417 - val_loss: 0.5016 - val_accuracy: 0.7409\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5018 - accuracy: 0.7363 - val_loss: 0.5012 - val_accuracy: 0.7435\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5009 - accuracy: 0.7422 - val_loss: 0.5010 - val_accuracy: 0.7452\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 0.5021 - accuracy: 0.7375 - val_loss: 0.5010 - val_accuracy: 0.7435\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.5026 - accuracy: 0.7431 - val_loss: 0.5011 - val_accuracy: 0.7357\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.5001 - accuracy: 0.7390 - val_loss: 0.5015 - val_accuracy: 0.7392\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 0.5022 - accuracy: 0.7386 - val_loss: 0.5020 - val_accuracy: 0.7409\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 1s 30ms/step - loss: 0.5012 - accuracy: 0.7375 - val_loss: 0.5012 - val_accuracy: 0.7366\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.4987 - accuracy: 0.7418 - val_loss: 0.5011 - val_accuracy: 0.7418\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.4986 - accuracy: 0.7403 - val_loss: 0.5010 - val_accuracy: 0.7383\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.4998 - accuracy: 0.7408 - val_loss: 0.5010 - val_accuracy: 0.7400\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.4983 - accuracy: 0.7429 - val_loss: 0.5017 - val_accuracy: 0.7444\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.4970 - accuracy: 0.7414 - val_loss: 0.5018 - val_accuracy: 0.7418\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.5006 - accuracy: 0.7325 - val_loss: 0.5014 - val_accuracy: 0.7435\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.5019 - accuracy: 0.7403 - val_loss: 0.5010 - val_accuracy: 0.7452\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4994 - accuracy: 0.7409 - val_loss: 0.5010 - val_accuracy: 0.7400\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.4949 - accuracy: 0.7408 - val_loss: 0.5015 - val_accuracy: 0.7400\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4962 - accuracy: 0.7427 - val_loss: 0.5009 - val_accuracy: 0.7418\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.4970 - accuracy: 0.7402 - val_loss: 0.5010 - val_accuracy: 0.7418\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4956 - accuracy: 0.7428 - val_loss: 0.5010 - val_accuracy: 0.7400\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.5007 - accuracy: 0.7379 - val_loss: 0.5017 - val_accuracy: 0.7409\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.4951 - accuracy: 0.7400 - val_loss: 0.5016 - val_accuracy: 0.7374\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.4960 - accuracy: 0.7416 - val_loss: 0.5017 - val_accuracy: 0.7461\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.4984 - accuracy: 0.7422 - val_loss: 0.5020 - val_accuracy: 0.7470\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.4976 - accuracy: 0.7446 - val_loss: 0.5012 - val_accuracy: 0.7452\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.4963 - accuracy: 0.7481 - val_loss: 0.5016 - val_accuracy: 0.7426\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.5002 - accuracy: 0.7411 - val_loss: 0.5025 - val_accuracy: 0.7418\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.4965 - accuracy: 0.7432 - val_loss: 0.5025 - val_accuracy: 0.7470\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.4971 - accuracy: 0.7474 - val_loss: 0.5025 - val_accuracy: 0.7392\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.4960 - accuracy: 0.7434 - val_loss: 0.5023 - val_accuracy: 0.7435\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.4955 - accuracy: 0.7427 - val_loss: 0.5015 - val_accuracy: 0.7435\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 0.4966 - accuracy: 0.7428 - val_loss: 0.5022 - val_accuracy: 0.7461\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.4963 - accuracy: 0.7418 - val_loss: 0.5025 - val_accuracy: 0.7452\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4957 - accuracy: 0.7426 - val_loss: 0.5026 - val_accuracy: 0.7418\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.4961 - accuracy: 0.7408 - val_loss: 0.5023 - val_accuracy: 0.7435\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.4952 - accuracy: 0.7450 - val_loss: 0.5019 - val_accuracy: 0.7435\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4959 - accuracy: 0.7435 - val_loss: 0.5016 - val_accuracy: 0.7496\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.4959 - accuracy: 0.7469 - val_loss: 0.5031 - val_accuracy: 0.7470\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.4968 - accuracy: 0.7461 - val_loss: 0.5030 - val_accuracy: 0.7470\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4940 - accuracy: 0.7484 - val_loss: 0.5028 - val_accuracy: 0.7470\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.4949 - accuracy: 0.7483 - val_loss: 0.5025 - val_accuracy: 0.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1e93ef2910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae721986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4796 - accuracy: 0.7548\n",
      "Accuracy 0.754766047000885\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02793d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 14:02:09.563731: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) PhotoAmt, Fee, Age, Type, Color1, Color2, Gender, MaturitySize, FurLength, Vaccinated, Sterilized, Health, Breed1 with unsupported characters which will be renamed to photoamt, fee, age, type, color1, color2, gender, maturitysize, furlength, vaccinated, sterilized, health, breed1 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/pet_classifier_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/pet_classifier_model/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p model\n",
    "model.save('model/pet_classifier_model')\n",
    "reloaded_model = tf.keras.models.load_model('model/pet_classifier_model')\n",
    "\n",
    "del train_ds, val_ds, test_ds, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed55ca",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f708f61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This particular pet had a 73.5 percent probability of getting adopted.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 3,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Healthy',\n",
    "    'Fee': 100,\n",
    "    'PhotoAmt': 2,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
