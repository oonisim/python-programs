{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "tf_random_forest_titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "949bbc15"
      },
      "source": [
        "# Tensorflow Categorical Encoding"
      ],
      "id": "949bbc15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba7d6626"
      },
      "source": [
        "---\n",
        "# Setup"
      ],
      "id": "ba7d6626"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On5XVsTmcCNu",
        "outputId": "7b436561-3ca7-4104-f185-f3d843c318be"
      },
      "source": [
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer"
      ],
      "id": "On5XVsTmcCNu",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied: tensorflow~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.12.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (1.41.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.6->tensorflow_decision_forests) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.6->tensorflow_decision_forests) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2018.9)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.7/dist-packages (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "acf80e7f",
        "outputId": "8a6878ad-cd35-4b54-8453-02b8cf711966"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from wurlitzer import sys_pipes\n",
        "\n",
        "\n",
        "tf.__version__"
      ],
      "id": "acf80e7f",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bbcb9db"
      },
      "source": [
        "## undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb\n",
        "\n",
        "* [NotFoundError: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb #65](https://github.com/tensorflow/decision-forests/issues/65)\n",
        "\n",
        "* [Tensorflow: undefined symbol: _ZN10tensorflow11GetNodeAttrERKNS_9AttrSliceEN4absl14lts_2020_09_2311string_viewEPSs\n",
        "](https://stackoverflow.com/questions/68834328/tensorflow-undefined-symbol-zn10tensorflow11getnodeattrerkns-9attrsliceen4abs)  \n",
        "The exact same issue of TFDF following the same steps.\n",
        "\n",
        "> Try to uninstall tensorflow (in mine colab it was 2.6.0) install tf 2.5.0 and then install tensorflow_decision_forests.\n",
        "\n",
        "* [tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.6/dist-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb #385](https://github.com/tensorflow/text/issues/385)"
      ],
      "id": "9bbcb9db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390a9911",
        "outputId": "a6128d7b-e4f7-47e8-d008-ba96422a0f60"
      },
      "source": [
        "import tensorflow_decision_forests as tfdf"
      ],
      "id": "390a9911",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TF Parameter Server distributed training not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjiI0nuAckx-"
      },
      "source": [
        "# Data"
      ],
      "id": "VjiI0nuAckx-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIUKX8N5cjnI",
        "outputId": "dddbce18-8557-44cf-90d6-f0328fcedb65"
      },
      "source": [
        "train, info = tfds.load(\n",
        "    'titanic:2.*.*',              # Name of the dataset\n",
        "    with_info=True,       # Information of the dataset\n",
        "    shuffle_files=True, \n",
        "    split='train[:90%]'\n",
        ")\n",
        "validation = tfds.load(\n",
        "    'titanic:2.*.*',              # Name of the dataset\n",
        "    with_info=False,       # Information of the dataset\n",
        "    shuffle_files=True, \n",
        "    split='train[:10%]'\n",
        ")\n",
        "info"
      ],
      "id": "jIUKX8N5cjnI",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='titanic',\n",
              "    version=2.0.0,\n",
              "    description='Dataset describing the survival status of individual passengers on the Titanic. Missing values in the original dataset are represented using ?. Float and int missing values are replaced with -1, string missing values are replaced with 'Unknown'.',\n",
              "    homepage='https://www.openml.org/d/40945',\n",
              "    features=FeaturesDict({\n",
              "        'features': FeaturesDict({\n",
              "            'age': tf.float32,\n",
              "            'boat': tf.string,\n",
              "            'body': tf.int32,\n",
              "            'cabin': tf.string,\n",
              "            'embarked': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
              "            'fare': tf.float32,\n",
              "            'home.dest': tf.string,\n",
              "            'name': tf.string,\n",
              "            'parch': tf.int32,\n",
              "            'pclass': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
              "            'sex': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "            'sibsp': tf.int32,\n",
              "            'ticket': tf.string,\n",
              "        }),\n",
              "        'survived': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "    }),\n",
              "    total_num_examples=1309,\n",
              "    splits={\n",
              "        'train': 1309,\n",
              "    },\n",
              "    supervised_keys=('features', 'survived'),\n",
              "    citation=\"\"\"@ONLINE {titanic,\n",
              "    author = \"Frank E. Harrell Jr., Thomas Cason\",\n",
              "    title  = \"Titanic dataset\",\n",
              "    month  = \"oct\",\n",
              "    year   = \"2017\",\n",
              "    url    = \"https://www.openml.org/d/40945\"\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv9SSkmZcjq7",
        "outputId": "42e99b9d-106d-4a3a-d4c8-6d13e724ef4f"
      },
      "source": [
        "train = train.map(lambda row: (row['features'], row['survived']))\n",
        "validation = validation.map(lambda row: (row['features'], row['survived']))\n",
        "tf.data.experimental.get_structure(train)"
      ],
      "id": "Zv9SSkmZcjq7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              "  'boat': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              "  'body': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              "  'cabin': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              "  'embarked': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              "  'fare': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              "  'home.dest': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              "  'name': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              "  'parch': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              "  'pclass': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              "  'sex': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              "  'sibsp': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              "  'ticket': TensorSpec(shape=(), dtype=tf.string, name=None)},\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1573a124"
      },
      "source": [
        "## Examin dataset"
      ],
      "id": "1573a124"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85aa9331",
        "outputId": "400aa5d0-4058-4fc9-b0f3-046449ee5da0"
      },
      "source": [
        "[(train_features, label_batch)] = train.batch(5).take(1)\n",
        "print('Features:', list(train_features.keys()))\n",
        "for feature in train_features.keys():\n",
        "    print(f'A batch of {feature}:', train_features[feature])\n",
        "print('A batch of targets:', label_batch )"
      ],
      "id": "85aa9331",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['age', 'boat', 'body', 'cabin', 'embarked', 'fare', 'home.dest', 'name', 'parch', 'pclass', 'sex', 'sibsp', 'ticket']\n",
            "A batch of age: tf.Tensor([30. 37. 28. 18. -1.], shape=(5,), dtype=float32)\n",
            "A batch of boat: tf.Tensor([b'Unknown' b'Unknown' b'9' b'Unknown' b'Unknown'], shape=(5,), dtype=string)\n",
            "A batch of body: tf.Tensor([-1 98 -1 -1 -1], shape=(5,), dtype=int32)\n",
            "A batch of cabin: tf.Tensor([b'Unknown' b'Unknown' b'Unknown' b'Unknown' b'Unknown'], shape=(5,), dtype=string)\n",
            "A batch of embarked: tf.Tensor([2 2 2 2 0], shape=(5,), dtype=int64)\n",
            "A batch of fare: tf.Tensor([13.      7.925  13.     73.5     7.8958], shape=(5,), dtype=float32)\n",
            "A batch of home.dest: tf.Tensor(\n",
            "[b'Sarnia, ON' b'Ruotsinphytaa, Finland New York, NY' b'Spain'\n",
            " b'Lyndhurst, England' b'Unknown'], shape=(5,), dtype=string)\n",
            "A batch of name: tf.Tensor(\n",
            "[b'McCrie, Mr. James Matthew' b'Gustafsson, Mr. Anders Vilhelm'\n",
            " b'Reynaldo, Ms. Encarnacion' b'Davies, Mr. Charles Henry'\n",
            " b'Gheorgheff, Mr. Stanio'], shape=(5,), dtype=string)\n",
            "A batch of parch: tf.Tensor([0 0 0 0 0], shape=(5,), dtype=int32)\n",
            "A batch of pclass: tf.Tensor([1 2 1 1 2], shape=(5,), dtype=int64)\n",
            "A batch of sex: tf.Tensor([0 0 1 0 0], shape=(5,), dtype=int64)\n",
            "A batch of sibsp: tf.Tensor([0 2 0 0 0], shape=(5,), dtype=int32)\n",
            "A batch of ticket: tf.Tensor([b'233478' b'3101276' b'230434' b'S.O.C. 14879' b'349254'], shape=(5,), dtype=string)\n",
            "A batch of targets: tf.Tensor([0 0 1 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0db88465"
      },
      "source": [
        "---\n",
        "# Training"
      ],
      "id": "0db88465"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e988fbf0"
      },
      "source": [
        "batch_size = 32\n",
        "train = train.batch(batch_size).shuffle(buffer_size=32).prefetch(1)\n",
        "validation = validation.batch(batch_size).shuffle(buffer_size=32).prefetch(1)"
      ],
      "id": "e988fbf0",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0e02199"
      },
      "source": [
        "## TFDF RandomForest\n",
        "\n",
        "* [tfdf.keras.RandomForestModel](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel)\n",
        "Training algorithms do not need validation datasets. If a validation dataset is provided, it will only be used to show metrics."
      ],
      "id": "c0e02199"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c11e1130"
      },
      "source": [
        "features = []\n",
        "for feature in ['age', 'boat', 'cabin', 'embarked', 'fare' ,'pclass', 'sex', 'sibsp', 'ticket']:\n",
        "    features.append(tfdf.keras.FeatureUsage(name=feature))\n",
        "\n",
        "model = tfdf.keras.RandomForestModel(\n",
        "    task = tfdf.keras.Task.CLASSIFICATION,\n",
        "    features=features,\n",
        "    exclude_non_specified_features=True  \n",
        ")\n",
        "model.compile(\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "id": "c11e1130",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4c7a7f",
        "outputId": "5b28416e-f721-4fe1-bf4d-48858bceb3ad"
      },
      "source": [
        "with sys_pipes():\n",
        "    model.fit(x=train)"
      ],
      "id": "4c4c7a7f",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 6s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO kernel.cc:736] Start Yggdrasil model training\n",
            "[INFO kernel.cc:737] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 37\n",
            "[INFO kernel.cc:393] Number of examples: 1178\n",
            "[INFO data_spec_inference.cc:290] 8 item(s) have been pruned (i.e. they are considered out of dictionary) for the column boat (20 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:290] 175 item(s) have been pruned (i.e. they are considered out of dictionary) for the column cabin (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:290] 839 item(s) have been pruned (i.e. they are considered out of dictionary) for the column ticket (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:759] Dataset:\n",
            "Number of records: 1178\n",
            "Number of columns: 10\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 6 (60%)\n",
            "\tCATEGORICAL: 4 (40%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 6 (60%)\n",
            "\t0: \"age\" NUMERICAL mean:24.0432 min:-1 max:80 sd:17.9178\n",
            "\t3: \"embarked\" NUMERICAL mean:1.49151 min:0 max:3 sd:0.82017\n",
            "\t4: \"fare\" NUMERICAL mean:33.9159 min:-1 max:512.329 sd:52.8616\n",
            "\t5: \"pclass\" NUMERICAL mean:1.27929 min:0 max:2 sd:0.843991\n",
            "\t6: \"sex\" NUMERICAL mean:0.357385 min:0 max:1 sd:0.47923\n",
            "\t7: \"sibsp\" NUMERICAL mean:0.498302 min:0 max:8 sd:1.04585\n",
            "\n",
            "CATEGORICAL: 4 (40%)\n",
            "\t1: \"boat\" CATEGORICAL has-dict vocab-size:21 num-oods:8 (0.679117%) most-frequent:\"Unknown\" 736 (62.4788%)\n",
            "\t2: \"cabin\" CATEGORICAL has-dict vocab-size:4 num-oods:175 (14.8557%) most-frequent:\"Unknown\" 905 (76.8251%)\n",
            "\t8: \"ticket\" CATEGORICAL has-dict vocab-size:17 num-oods:839 (71.2224%) most-frequent:\"<OOD>\" 839 (71.2224%)\n",
            "\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:762] Configure learner\n",
            "[INFO kernel.cc:787] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"age\"\n",
            "features: \"boat\"\n",
            "features: \"cabin\"\n",
            "features: \"embarked\"\n",
            "features: \"fare\"\n",
            "features: \"pclass\"\n",
            "features: \"sex\"\n",
            "features: \"sibsp\"\n",
            "features: \"ticket\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:790] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:817] Train model\n",
            "[INFO random_forest.cc:315] Training random forest on 1178 example(s) and 9 feature(s).\n",
            "[INFO random_forest.cc:628] Training of tree  1/300 (tree index:0) done accuracy:0.958525 logloss:1.4949\n",
            "[INFO random_forest.cc:628] Training of tree  13/300 (tree index:12) done accuracy:0.963153 logloss:0.830069\n",
            "[INFO random_forest.cc:628] Training of tree  24/300 (tree index:13) done accuracy:0.968591 logloss:0.422659\n",
            "[INFO random_forest.cc:628] Training of tree  34/300 (tree index:37) done accuracy:0.971138 logloss:0.396033\n",
            "[INFO random_forest.cc:628] Training of tree  44/300 (tree index:41) done accuracy:0.971986 logloss:0.285183\n",
            "[INFO random_forest.cc:628] Training of tree  54/300 (tree index:58) done accuracy:0.971986 logloss:0.257424\n",
            "[INFO random_forest.cc:628] Training of tree  64/300 (tree index:64) done accuracy:0.970289 logloss:0.202003\n",
            "[INFO random_forest.cc:628] Training of tree  74/300 (tree index:76) done accuracy:0.970289 logloss:0.200541\n",
            "[INFO random_forest.cc:628] Training of tree  84/300 (tree index:87) done accuracy:0.96944 logloss:0.201065\n",
            "[INFO random_forest.cc:628] Training of tree  94/300 (tree index:96) done accuracy:0.970289 logloss:0.201126\n",
            "[INFO random_forest.cc:628] Training of tree  104/300 (tree index:101) done accuracy:0.96944 logloss:0.201499\n",
            "[INFO random_forest.cc:628] Training of tree  115/300 (tree index:110) done accuracy:0.970289 logloss:0.20154\n",
            "[INFO random_forest.cc:628] Training of tree  125/300 (tree index:122) done accuracy:0.971986 logloss:0.175001\n",
            "[INFO random_forest.cc:628] Training of tree  135/300 (tree index:129) done accuracy:0.971986 logloss:0.175014\n",
            "[INFO random_forest.cc:628] Training of tree  145/300 (tree index:148) done accuracy:0.971986 logloss:0.175614\n",
            "[INFO random_forest.cc:628] Training of tree  155/300 (tree index:158) done accuracy:0.971138 logloss:0.175438\n",
            "[INFO random_forest.cc:628] Training of tree  165/300 (tree index:164) done accuracy:0.971138 logloss:0.175395\n",
            "[INFO random_forest.cc:628] Training of tree  175/300 (tree index:168) done accuracy:0.971138 logloss:0.174932\n",
            "[INFO random_forest.cc:628] Training of tree  185/300 (tree index:186) done accuracy:0.971138 logloss:0.17506\n",
            "[INFO random_forest.cc:628] Training of tree  195/300 (tree index:198) done accuracy:0.971138 logloss:0.17541\n",
            "[INFO random_forest.cc:628] Training of tree  205/300 (tree index:209) done accuracy:0.971138 logloss:0.175562\n",
            "[INFO random_forest.cc:628] Training of tree  215/300 (tree index:217) done accuracy:0.970289 logloss:0.175305\n",
            "[INFO random_forest.cc:628] Training of tree  225/300 (tree index:224) done accuracy:0.971138 logloss:0.175084\n",
            "[INFO random_forest.cc:628] Training of tree  235/300 (tree index:238) done accuracy:0.971138 logloss:0.17477\n",
            "[INFO random_forest.cc:628] Training of tree  245/300 (tree index:246) done accuracy:0.971138 logloss:0.174124\n",
            "[INFO random_forest.cc:628] Training of tree  255/300 (tree index:257) done accuracy:0.971138 logloss:0.174675\n",
            "[INFO random_forest.cc:628] Training of tree  265/300 (tree index:265) done accuracy:0.971138 logloss:0.174604\n",
            "[INFO random_forest.cc:628] Training of tree  275/300 (tree index:277) done accuracy:0.971138 logloss:0.174355\n",
            "[INFO random_forest.cc:628] Training of tree  285/300 (tree index:281) done accuracy:0.971138 logloss:0.174108\n",
            "[INFO random_forest.cc:628] Training of tree  295/300 (tree index:298) done accuracy:0.971138 logloss:0.147473\n",
            "[INFO random_forest.cc:628] Training of tree  300/300 (tree index:299) done accuracy:0.971986 logloss:0.14785\n",
            "[INFO random_forest.cc:696] Final OOB metrics: accuracy:0.971986 logloss:0.14785\n",
            "[INFO kernel.cc:828] Export model in log directory: /tmp/tmp1tz74nkz\n",
            "[INFO kernel.cc:836] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 14886 node(s), and 9 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02793d6e",
        "outputId": "154a1f88-56db-4b91-c339-87392205603b"
      },
      "source": [
        "!mkdir -p model\n",
        "model.save('model/titanic_random_forest_model')\n",
        "reloaded_model = tf.keras.models.load_model('model/titanic_random_forest_model')\n",
        "\n",
        "#del train, model"
      ],
      "id": "02793d6e",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) home.dest with unsupported characters which will be renamed to home_dest in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/titanic_random_forest_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model/titanic_random_forest_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eed55ca"
      },
      "source": [
        "# Evaluation\n",
        "\n"
      ],
      "id": "4eed55ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUhCfXdafoxq",
        "outputId": "859a9646-70a0-448b-c8cb-dbabb7e8545e"
      },
      "source": [
        "evaluation = model.evaluate(validation)\n",
        "print(evaluation)"
      ],
      "id": "PUhCfXdafoxq",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - accuracy: 0.9924\n",
            "[0.0, 0.9923664331436157]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Eb15ZHNfsqz"
      },
      "source": [
        ""
      ],
      "id": "4Eb15ZHNfsqz",
      "execution_count": 11,
      "outputs": []
    }
  ]
}