{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1396eca-0d6b-4dc4-86bf-1af3c4e917fc",
   "metadata": {},
   "source": [
    "# Tensorboard Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990dd569-6d4e-407b-8214-e1db5d3da21d",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "* [Tensorflow Github - tensorboard](https://github.com/tensorflow/tensorboard)\n",
    "\n",
    "> This README gives an overview of key concepts in TensorBoard, as well as how to interpret the visualizations TensorBoard provides.\n",
    "> Make sure you have generated summary data in a log directory by creating a summary writer:\n",
    "> ```\n",
    "> file_writer = tf.summary.FileWriter('/path/to/logs', sess.graph)\n",
    "> ```\n",
    "\n",
    "* [Tensorflow TensorBoard - Visualize your learning](https://jhui.github.io/2017/03/12/TensorBoard-visualize-your-learning/)\n",
    "* [Aladdinpersson - TensorFlow Tutorial 17 - Complete TensorBoard Guide](https://www.youtube.com/watch?v=k7KfYXXrOj0) ([github](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/TensorFlow/Basics/tutorial17-tensorboard))\n",
    "* [Neptune AI - Deep Dive Into TensorBoard: Tutorial With Examples](https://neptune.ai/blog/tensorboard-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08497805-00a5-4196-a305-646b2570a1f1",
   "metadata": {},
   "source": [
    "## Using Tensorboard in Notebook\n",
    "* [Using TensorBoard in Notebooks](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1933c99a-5333-45a6-8646-b01831017052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension for Jupyter Notebooks\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce3cc9-c208-4b9b-845b-eb2e8741538d",
   "metadata": {},
   "source": [
    "---\n",
    "# Views\n",
    "\n",
    "## Metrics\n",
    "\n",
    "* **Scalars** show how the loss and metrics change with every epoch. You can use them to also track training speed, learning rate, and other scalar values. Scalars can be found in the **Time Series** or **Scalars** dashboards.\n",
    "\n",
    "\n",
    "\n",
    "## Parameters (Weight & Bias)\n",
    "* **Distributions** show the distribution of a Tensor over time. This can be useful to visualize **weights and biases** and verify that they are changing in an expected way. Histograms can be found in the **Time Series** or **Histograms** dashboards. Distributions can be found in the **Distributions** dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4fe4f-cd4e-43be-a628-8cb223d412d7",
   "metadata": {},
   "source": [
    "## Graph\n",
    "\n",
    "[Examining the TensorFlow Graph](https://www.tensorflow.org/tensorboard/graphs)\n",
    "\n",
    "**Graphs** visualize your model’s structure and ensure it matches the intended design. And op-level graph to understand how TensorFlow understands your program.\n",
    "\n",
    "By default, TensorBoard displays the **op-level graph**. Note that **the graph is inverted**; data flows from bottom to top, so it’s upside down compared to the code. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19dfc761-155d-440f-8a3c-922bcd17b599",
   "metadata": {},
   "source": [
    "## Image\n",
    "\n",
    "* [Displaying image data in TensorBoard](https://www.tensorflow.org/tensorboard/image_summaries)\n",
    "\n",
    "> TensorFlow Image Summary API let you log tensors and your images (e.g, Confusion Matrix).\n",
    "> 1. Create the Keras TensorBoard callback to log basic metrics\n",
    "> 2. Create a Keras LambdaCallback to log the confusion matrix at the end of every epoch\n",
    "> 3. Train the model using Model.fit(), making sure to pass both callbacks\n",
    "\n",
    "```\n",
    "file_writer_confusion_matrix = tf.summary.create_file_writer(logdir + '/cm')\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "  # Use the model to predict the values from the validation dataset.\n",
    "  test_pred_raw = model.predict(test_images)\n",
    "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "  # Calculate the confusion matrix.\n",
    "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
    "\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "  cm_image = plot_to_image(figure)\n",
    "\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  with file_writer_confusion_matrix.as_default():\n",
    "    tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n",
    "\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cofusion_matrixm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "# Train the classifier.\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    verbose=0, # Suppress chatty output\n",
    "    callbacks=[cofusion_matrixm_callback],\n",
    "    validation_data=(test_images, test_labels),\n",
    ")\n",
    "```\n",
    "\n",
    "<img src=\"image/tensorboard_image.png\" align=\"left\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36f9ea-3a5b-4750-9128-b7afda1909a5",
   "metadata": {},
   "source": [
    "## Hyper Parameters\n",
    "\n",
    "* [Hyperparameter Tuning with the HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)\n",
    "\n",
    "> The HParams dashboard help identifying the best experiment or most promising sets of hyperparameters.\n",
    "> Experiment with three hyperparameters in the model:\n",
    "> 1. Number of units in the first dense layer\n",
    "> 2. Dropout rate in the dropout layer\n",
    "> 3. Optimizer\n",
    ">  \n",
    "> ```\n",
    "> # Load the TensorBoard notebook extension\n",
    "> %load_ext tensorboard\n",
    "> \n",
    "> import tensorflow as tf\n",
    "> from tensorboard.plugins.hparams import api as hp\n",
    ">\n",
    "> HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "> HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "> HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "> \n",
    "> METRIC_ACCURACY = 'accuracy'\n",
    "> \n",
    "> with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    ">   hp.hparams_config(\n",
    ">     hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    ">     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    ">   )\n",
    ">\n",
    "> def train_test_model(hparams):\n",
    ">   model = tf.keras.models.Sequential([\n",
    ">     tf.keras.layers.Flatten(),\n",
    ">     tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    ">     tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    ">     tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    ">   ])\n",
    ">   model.compile(\n",
    ">       optimizer=hparams[HP_OPTIMIZER],\n",
    ">       loss='sparse_categorical_crossentropy',\n",
    ">       metrics=['accuracy'],\n",
    ">   )\n",
    "> \n",
    ">   model.fit(x_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    ">   _, accuracy = model.evaluate(x_test, y_test)\n",
    ">   return accuracy\n",
    ">\n",
    "> def run(run_dir, hparams):\n",
    ">   with tf.summary.create_file_writer(run_dir).as_default():\n",
    ">     hp.hparams(hparams)  # record the values used in this trial\n",
    ">     accuracy = train_test_model(hparams)\n",
    ">     tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    ">\n",
    "> session_num = 0\n",
    "> \n",
    "> for num_units in HP_NUM_UNITS.domain.values:\n",
    ">   for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    ">     for optimizer in HP_OPTIMIZER.domain.values:\n",
    ">       hparams = {\n",
    ">           HP_NUM_UNITS: num_units,\n",
    ">           HP_DROPOUT: dropout_rate,\n",
    ">           HP_OPTIMIZER: optimizer,\n",
    ">       }\n",
    ">       run_name = \"run-%d\" % session_num\n",
    ">       print('--- Starting trial: %s' % run_name)\n",
    ">       print({h.name: hparams[h] for h in hparams})\n",
    ">       run('logs/hparam_tuning/' + run_name, hparams)\n",
    ">       session_num += 1\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315f982-5913-490e-86f0-2116f03b8508",
   "metadata": {},
   "source": [
    "The HParams dashboard has three different views, with various useful information:\n",
    "\n",
    "1. The Table View lists the runs, their hyperparameters, and their metrics.\n",
    "2. The Parallel Coordinates View shows each run as a line going through an axis for each hyperparemeter and metric. Click and drag the mouse on any axis to mark a region which will highlight only the runs that pass through it. This can be useful for identifying which groups of hyperparameters are most important. The axes themselves can be re-ordered by dragging them.\n",
    "3. The Scatter Plot View shows plots comparing each hyperparameter/metric with each metric. This can help identify correlations. Click and drag to select a region in a specific plot and highlight those sessions across the other plots.\n",
    "A table row, a parallel coordinates line, and a scatter plot market can be clicked to see a plot of the metrics as a function of training steps for that session (although in this tutorial only one step is used for each run).\n",
    "\n",
    "```(number of units, dropout rate, optimizer, accuracy) = (128, 0.2, adam, 0.9783)``` gives the best accuracy.\n",
    "\n",
    "<img src=\"image/tensorboard_hdparam.png\" align=\"left\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22199293-eb70-4f3d-a8b1-217c19cbf512",
   "metadata": {},
   "source": [
    "## Embedding Projection\n",
    "\n",
    "> Embedding Projector help visualizing, examining, and understanding your embedding layers. In order to load the data into Tensorboard, we need to save a training checkpoint to that directory, along with metadata that allows for visualization of a specific layer of interest in the model.\n",
    ">\n",
    "> ```\n",
    "> # Create an embedding layer.\n",
    "> embedding_dim = 16\n",
    "> embedding = tf.keras.layers.Embedding(encoder.vocab_size, embedding_dim)\n",
    "> \n",
    "> # Configure the embedding layer as part of a keras model.\n",
    "> model = tf.keras.Sequential(\n",
    ">     [\n",
    ">         embedding, # The embedding layer should be the first layer in a model.\n",
    ">         tf.keras.layers.GlobalAveragePooling1D(),\n",
    ">         tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    ">         tf.keras.layers.Dense(1),\n",
    ">     ]\n",
    "> )\n",
    "> \n",
    "> # Save Labels separately on a line-by-line manner.\n",
    "> with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    ">   for subwords in encoder.subwords:\n",
    ">     f.write(\"{}\\n\".format(subwords))\n",
    ">   # Fill in the rest of the labels with \"unknown\".\n",
    ">   for unknown in range(1, encoder.vocab_size - len(encoder.subwords)):\n",
    ">     f.write(\"unknown #{}\\n\".format(unknown))\n",
    "> \n",
    "> # Save the weights we want to analyze as a variable. Note that the first\n",
    "> # value represents any unknown word, which is not in the metadata, here\n",
    "> # we will remove this value.\n",
    "> weights = tf.Variable(model.layers[0].get_weights()[0][1:])\n",
    "> \n",
    "> # Create a checkpoint from embedding, the filename and key are the\n",
    "> # name of the tensor.\n",
    "> checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "> checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "> \n",
    "> # Set up config.\n",
    "> config = projector.ProjectorConfig()\n",
    "> embedding = config.embeddings.add()\n",
    "> \n",
    "> # The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "> embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "> embedding.metadata_path = 'metadata.tsv'\n",
    "> projector.visualize_embeddings(log_dir, config)\n",
    "> ```\n",
    "\n",
    "<img src=\"image/tensorboard_projector.png\" align=\"left\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eccd88d-ef4e-4965-a84e-528fcc830871",
   "metadata": {},
   "source": [
    "## Debugger V2 - Nan/Inf Detection\n",
    "\n",
    "* [Debugging Numerical Issues](https://www.tensorflow.org/tensorboard/debugger_v2)\n",
    "\n",
    "> TensorBoard 2.3+ (together with TensorFlow 2.3+) provides a specialized dashboard called Debugger to detect errors involving NaNs.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d560b95-c273-4e2a-a1e1-f46460b3f569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
