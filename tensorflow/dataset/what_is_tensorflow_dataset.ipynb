{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2461545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4456132b",
   "metadata": {},
   "source": [
    "# TensorFlow Dataset\n",
    "\n",
    "TF Dataset is a Monad which is a container with interfaces. Cannot directly access internal elements, need to use its I/F.\n",
    "\n",
    "You will not try to access elements in Spark RDD until the transformation is done and reduced to a single row. Because those elements are distributed over nodes.\n",
    "\n",
    "<img src=\"image/what_is_tensorflow_dataset.jpg\" align=\"left\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4bca60",
   "metadata": {},
   "source": [
    "---\n",
    "# Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc46494",
   "metadata": {},
   "source": [
    "## from_tensor_slice\n",
    "\n",
    "tf.constant(x) to Tensor is tf.data.Dataset.from_tensor_slice(y) to Dataset.\n",
    "\n",
    "**Each element in y on axis=0 is a row in a dataset**.\n",
    "\n",
    "* [from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a19a16",
   "metadata": {},
   "source": [
    "x[0] and x[1] will be a respective row in the dataset.\n",
    "\n",
    "```\n",
    "x = [\n",
    "    [                        # <--- x[0]\n",
    "        [ 0,  1,  2,  3],\n",
    "        [ 4,  5,  6,  7],\n",
    "        [ 8,  9, 10, 11]\n",
    "    ],\n",
    "    [                        # <--- x[1]\n",
    "        [12, 13, 14, 15],\n",
    "        [16, 17, 18, 19],\n",
    "        [20, 21, 22, 23]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "834d0bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x: np.ndarray = np.arange(2*3*4).reshape((2,3,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68b3f64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x[0] is the first row\n",
    "dataset: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "list(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9326f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]], shape=(3, 4), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]], shape=(3, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in dataset:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78099",
   "metadata": {},
   "source": [
    "## from_tensors\n",
    "\n",
    "```from_tensors(x)``` combines all in ```x``` into single tensor row. The result dataset has only one row.\n",
    "\n",
    "> from_tensors produces a dataset **containing only a single element/row**. To slice the input tensor into multiple elements, use from_tensor_slices instead.\n",
    "\n",
    "* [from_tensors](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec6b8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_from_tensors = tf.data.Dataset.from_tensors([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b042146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]], shape=(2, 3, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in ds_from_tensors:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cfed9",
   "metadata": {},
   "source": [
    "---\n",
    "# Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1ed4",
   "metadata": {},
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fea420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=(64,3))\n",
    "ds = tf.data.Dataset.from_tensor_slices(x).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2ef542b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = ds._batch_size\n",
    "batch_size.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693da52",
   "metadata": {},
   "source": [
    "## Number of batches in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e45c978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = tf.data.Dataset.cardinality(ds)\n",
    "num_batches.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12ebfb",
   "metadata": {},
   "source": [
    "---\n",
    "# Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edb576",
   "metadata": {},
   "source": [
    "## Extract single record \n",
    "\n",
    "Reduce to a dataset with single record and apply ```get_single_element()```.\n",
    "\n",
    "* [get_single_element](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#get_single_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128bc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int64, numpy=\n",
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde280e",
   "metadata": {},
   "source": [
    "## Aggregate (Reduce)\n",
    "\n",
    "* [reduce](np.arange(2*3*4).reshape((2,3,4)))\n",
    "\n",
    "```\n",
    "reduce(\n",
    "    initial_state, reduce_func, name=None\n",
    ")\n",
    "```\n",
    "\n",
    "```reduce``` is like ```monad.foldLeft(initial)(func)``` in Scala but apply row-wise like SQL LAG.\n",
    "\n",
    "```\n",
    "list.foldLeft(initial=0)(left + right)  # Initial placeholder left value is 0 and continuously add right\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99058bda",
   "metadata": {},
   "source": [
    "## Sum\n",
    "\n",
    "Similar to ```tf.math.reduce_sum(axis=0)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dee7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_fn(previous_row, current_row):\n",
    "    return previous_row + current_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9575436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(3*4).reshape((3,4)).astype(np.float32)\n",
    "print(x)\n",
    "ds = tf.data.Dataset.from_tensor_slices(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7ac455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce result type is <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 10:58:57.297660: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([12., 15., 18., 21.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = ds.reduce(initial_state=0.0, reduce_func=sum_fn)\n",
    "print(f\"reduce result type is {type(sum)}\")\n",
    "sum.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2817c2",
   "metadata": {},
   "source": [
    "## Sum on Tensor of Tuple\n",
    "\n",
    "Sum feature_1 and feature_2 respectively on Tensor(tuple(feature_1, feature_2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b09eadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row0, row1):\n",
    "    return (\n",
    "        row0[0] + row1[0], # feature_1 in (feature_1, feature_2)\n",
    "        row0[1] + row1[1]  # feature_2 in (feature_1, feature_2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a26557",
   "metadata": {},
   "source": [
    "Calculate row-wise sum on:\n",
    "```\n",
    "([1,2,3],1)\n",
    "([4,5,6],2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b365d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 5., 6.], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>)\n"
     ]
    }
   ],
   "source": [
    "feature_1 = np.array([\n",
    "    [1, 2, 3], \n",
    "    [4, 5, 6]\n",
    "]).astype(np.float32)\n",
    "feature_2 = np.array(\n",
    "    [\n",
    "        1, \n",
    "        2\n",
    "    ]\n",
    ").astype(np.float32)                \n",
    " \n",
    "ds_tuple = tf.data.Dataset.from_tensor_slices((feature_1, feature_2))\n",
    "for row in ds_tuple:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f8a3a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5., 7., 9.], dtype=float32), 3.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_1_sum, feature_2_sum = ds_tuple.reduce(initial_state=(0.0,0.0), reduce_func=f)\n",
    "feature_1_sum.numpy(), feature_2_sum.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9b9a2",
   "metadata": {},
   "source": [
    "## Iterate as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67daf1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.07311059 0.01731903 0.77369721]\n",
      "1 [0.1863143  0.90496002 0.51770964]\n",
      "2 [0.204347   0.50955457 0.37652489]\n",
      "3 [0.75352069 0.45518075 0.90753191]\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(np.random.random(size=(4,3)))\n",
    "for index, row in enumerate(ds.as_numpy_iterator()):\n",
    "    print(index, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d3e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
