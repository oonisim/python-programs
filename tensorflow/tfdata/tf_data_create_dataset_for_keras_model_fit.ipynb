{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310e9f2f",
   "metadata": {},
   "source": [
    "# Create Dataset for Keras mode.fit()\n",
    "\n",
    "* [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data) (MUST)\n",
    "* [Load CSV data](https://www.tensorflow.org/tutorials/load_data/csv)\n",
    "* [tf.data.experimental.make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset)\n",
    "\n",
    "\n",
    "## Input format for model.fit()\n",
    "\n",
    "\n",
    "* [How to create the same structure of tf.data.experimental.make_csv_dataset from pandas\n",
    "](https://stackoverflow.com/questions/69777802/how-to-create-the-same-structure-of-tf-data-experimental-make-csv-dataset-from-p/69778344#69778344)\n",
    "\n",
    "> tensorflow.org/api_docs/python/tf/keras/Model#fit defines what should be passed to .fit() \n",
    "\n",
    "When passing TF dataset, it shoudl have ```(features, labels)``` format which is to be created by ```tf.data.Dataset.from_tensor_slices((features, labels))``` where **features** can be either:\n",
    "\n",
    "> * A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).\n",
    "> * A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).\n",
    "> * A dict mapping input names to the corresponding array/tensors, if the model has named inputs.\n",
    "> * A generator or keras.utils.Sequence returning (inputs, targets) or (inputs, targets, sample_weights).\n",
    "\n",
    "* [tf.keras.Model - fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
    "\n",
    "> ```fit(x=None, y=None)```  \n",
    "> ### x: Input data.  \n",
    "> For a tf.data dataset, it should be **a tuple of either (inputs, targets) or (inputs, targets, sample_weights)**.\n",
    "> ###  y: Target data  \n",
    "> either Numpy array(s) or TensorFlow tensor(s). It should be consistent with x (you cannot have Numpy inputs and tensor targets, or inversely). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3d84466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37282a60",
   "metadata": {},
   "source": [
    "# Example CSV\n",
    "\n",
    "Titanic CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c284223",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_file = tf.keras.utils.get_file(\"titanic_train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe563962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\r\n",
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\r\n",
      "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\r\n",
      "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\r\n",
      "1,female,35.0,1,0,53.1,First,C,Southampton,n\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5  ~/.keras/datasets/titanic_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b3d8b",
   "metadata": {},
   "source": [
    "# Dictionary to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb44b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'name': <tf.Tensor: shape=(), dtype=string, numpy=b'hoge'>, 'age': <tf.Tensor: shape=(), dtype=int32, numpy=20>}, {'survived': <tf.Tensor: shape=(), dtype=int32, numpy=0>})\n",
      "({'name': <tf.Tensor: shape=(), dtype=string, numpy=b'tako'>, 'age': <tf.Tensor: shape=(), dtype=int32, numpy=99>}, {'survived': <tf.Tensor: shape=(), dtype=int32, numpy=1>})\n"
     ]
    }
   ],
   "source": [
    "features = {\n",
    "    \"name\": [\"hoge\", \"tako\"],\n",
    "    \"age\": [20, 99]\n",
    "}\n",
    "labels = {\n",
    "    \"survived\": [0, 1]\n",
    "}\n",
    "ds_from_dictionary = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "for record in ds_from_dictionary:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d9f25",
   "metadata": {},
   "source": [
    "# Pandas to Dataset\n",
    "\n",
    "* [How to create the same structure of tf.data.experimental.make_csv_dataset from pandas\n",
    "](https://stackoverflow.com/questions/69777802/how-to-create-the-same-structure-of-tf-data-experimental-make-csv-dataset-from-p/69778344#69778344)\n",
    "\n",
    "If  data fits in memory, ```from_tensor_slices``` method works on dictionaries.\n",
    "\n",
    "```Pandas -> Python dictionary -> from_tensor_slices -> Dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecb2715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 627 entries, 0 to 626\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   survived            627 non-null    int64  \n",
      " 1   sex                 627 non-null    object \n",
      " 2   age                 627 non-null    float64\n",
      " 3   n_siblings_spouses  627 non-null    int64  \n",
      " 4   parch               627 non-null    int64  \n",
      " 5   fare                627 non-null    float64\n",
      " 6   class               627 non-null    object \n",
      " 7   deck                627 non-null    object \n",
      " 8   embark_town         627 non-null    object \n",
      " 9   alone               627 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 49.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(titanic_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fc01e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male']\n",
      "age                 : [22.]\n",
      "n_siblings_spouses  : [1]\n",
      "parch               : [0]\n",
      "fare                : [7.25]\n",
      "class               : [b'Third']\n",
      "deck                : [b'unknown']\n",
      "embark_town         : [b'Southampton']\n",
      "alone               : [b'n']\n",
      "label/survived      : [0]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset of format (features, labels) where \n",
    "# - \"features\" is a dictionary or numpy array or generator.\n",
    "# - \n",
    "titanic_from_pandas = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(df.loc[:, df.columns != 'survived']),   # Multi-column features as dictionary or numpy array or Tensor\n",
    "    df.loc[:, 'survived']                        # Labels format depends on the number of classes.\n",
    "\n",
    "))\n",
    "\n",
    "for row in titanic_from_pandas.batch(1).take(1):  # Take the first batch \n",
    "    features = row[0]        # Diectionary\n",
    "    label = row[1]\n",
    "    \n",
    "    for feature, value in features.items():\n",
    "        print(f\"{feature:20s}: {value}\")\n",
    "    \n",
    "    print(f\"label/survived      : {label}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf97a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-30 18:16:37.932451: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: {survived: (), sex: (), age: (), n_siblings_spouses: (), parch: (), fare: (), class: (), deck: (), embark_town: (), alone: ()}, types: {survived: tf.int64, sex: tf.string, age: tf.float64, n_siblings_spouses: tf.int64, parch: tf.int64, fare: tf.float64, class: tf.string, deck: tf.string, embark_town: tf.string, alone: tf.string}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_from_pandas = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "titanic_from_pandas.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf0482",
   "metadata": {},
   "source": [
    "# Read CSV into Dataset\n",
    "\n",
    "```make_csv_dataset``` method reads the csv and split them into ```(features, label)``` where ```features``` is a diectioay of ```(feature, value)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58094bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file,\n",
    "    label_name=\"survived\",\n",
    "    batch_size=1,   # To compre with the head of CSV\n",
    "    shuffle=False,  # To compre with the head of CSV\n",
    "    header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c2c24d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male']\n",
      "age                 : [22.]\n",
      "n_siblings_spouses  : [1]\n",
      "parch               : [0]\n",
      "fare                : [7.25]\n",
      "class               : [b'Third']\n",
      "deck                : [b'unknown']\n",
      "embark_town         : [b'Southampton']\n",
      "alone               : [b'n']\n",
      "label/survived      : [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-30 18:49:14.543589: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-30 18:49:14.545234: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1996235000 Hz\n"
     ]
    }
   ],
   "source": [
    "for row in titanic.take(1):  # Take the first batch \n",
    "    features = row[0]        # Diectionary\n",
    "    label = row[1]\n",
    "    \n",
    "    for feature, value in features.items():\n",
    "        print(f\"{feature:20s}: {value}\")\n",
    "    \n",
    "    print(f\"label/survived      : {label}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee99656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee4f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9fe6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
