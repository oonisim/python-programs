{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df3f532-40a2-4049-844f-12f0cea1127a",
   "metadata": {},
   "source": [
    "# Nano GPT\n",
    "\n",
    "Nano GPT implementation by Andrej Karpathy.\n",
    "\n",
    "* [nanoGPT](https://github.com/karpathy/nanoGPT)\n",
    "* [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
    "* [nanogpt-lecture](https://github.com/karpathy/ng-video-lecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5710adfc-3fb3-4e3e-857c-331a5ab58489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f507fe2d-3931-491a-a14a-25ba5edb12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import inspect\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from bigram import (\n",
    "    V,\n",
    "    B,\n",
    "    T,\n",
    "    C,\n",
    "    get_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9b0fe-8ac6-4ca3-b237-610999b0b055",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Using tinyshakespeare as the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e53b20-2177-458e-9f98-60ce2135ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-10 10:44:41--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.2’\n",
      "\n",
      "input.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-12-10 10:44:42 (7.24 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13271d1f-2fc5-4632-b867-01988054c251",
   "metadata": {},
   "source": [
    "# Terminologies\n",
    "\n",
    "* B: Batch size\n",
    "* T: Time steps or Sequence length (e.g. 512 for bert input sequence)\n",
    "* C: Channel or Feature (channel perhaps because Andrej is from CNN background?). ```C=2``` two features in each x."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45745a2a-c062-40af-90a2-65d372419312",
   "metadata": {},
   "source": [
    "## Batch Input\n",
    "\n",
    "<img src=\"./image/gpt_batch.jpeg\" align=\"left\" width=750/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a326dbfa-e644-4685-b0b0-263e83bd76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_batch(split):\n",
      "    # generate a small batch of data of inputs x and targets y\n",
      "    data = train_data if split == 'train' else val_data\n",
      "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
      "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
      "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
      "    x, y = x.to(device), y.to(device)\n",
      "    return x, y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(get_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26538e1e-a74e-4e1c-8268-bfa4d86240ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 8 65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(B,T,C)\n",
    "x, y = get_batch('train')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07acdfac-5f13-438e-844b-1d124d115735",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Transformer generates a graph network between position-encoded tokens.\n",
    "\n",
    "1. Get un-connected tokens as a sequence (e.g. sentence)\n",
    "2. Wires connections among tokens by having looked at the co-occurrances of them in billions of sequences.\n",
    "\n",
    "## Q and K (Similarity Score)\n",
    "\n",
    "For every token ```Q``` in a sequence, calculate the relation/communication with other token ```K``` in the sequence (for GPT, only previous tokens). This builds the graph network of Self Attention.\n",
    "\n",
    "## V (Bow/Bag of Words)\n",
    "\n",
    "One way to generate the inter-connections among the tokens to distill their knowledges or relations is ```BoW``` by averaging them feature-wise/axis=-1.\n",
    "\n",
    "<img src=\"./image/self_attention.jpeg\" align=\"left\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf68a276-afe3-4ae7-b8d0-818c4cf36dff",
   "metadata": {},
   "source": [
    "### Similarity Score (Q & K)\n",
    "\n",
    "|Similarity Score (Q & K)| Proabability as Softmax |\n",
    "|---|---|\n",
    "|<img src=\"./image/transformer_dot_product_attention_similarity_score.jpeg\" align=\"left\" width=500/>|<img src=\"./image/transformer_dot_product_attention.png\" align=\"left\" width=175/>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a5274e-3547-449a-a504-46e0829b4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a single Head perform self-attention\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# B: batch size\n",
    "# T: time steps or number of tokens to iterate or sequencee size\n",
    "# C: channels or embedding vector dimension or features\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "head_size = 16\n",
    "    \n",
    "Wk = nn.Linear(C, head_size, bias=False)\n",
    "Wq = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "def calculate_similarity_score(x):\n",
    "    k = Wk(x)   # (B, T, head_size)\n",
    "    q = Wq(x)   # (B, T, head_size)\n",
    "    \n",
    "    # First MatMul: (B, T, head_size) @ (B, head_size, T) ---> (B, T, T)\n",
    "    score =  q @ k.transpose(-2, -1) \n",
    "    \n",
    "    tril = torch.tril(torch.ones(T, T))\n",
    "    score = score.masked_fill(tril == 0, float('-inf'))\n",
    "    score = F.softmax(score, dim=-1)\n",
    "\n",
    "    return score    # shape:(B, T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa79e44-069f-4737-8607-2470f6fd7c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(B,T,C)\n",
    "\n",
    "similarity_score = calculate_similarity_score(x)\n",
    "similarity_score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db83d0-be00-4a74-a1a4-fada4511ce33",
   "metadata": {},
   "source": [
    "### BoW (V)\n",
    "\n",
    "<img src=\"./image/transformer_dot_product_attention_bow.png\" align=\"left\" width=700/>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fc2741-1a1a-46db-a830-5b68b0fd6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wv = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "def calculate_attension_value(score, x):\n",
    "    v = Wv(x)            # (B,T,C) @ (C,head_size) -> (B,T,head_size)\n",
    "    value = score @ v    # (B,T,T) @ (B,T,head_size) -> (B,T,head_size)\n",
    "\n",
    "    return value         # (B,T,head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ed6987-87c3-462b-b793-b457de0b98dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_value = calculate_attension_value(similarity_score, x)\n",
    "attention_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4d7e2-5a63-41d8-a3ea-541a4d1c6a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
