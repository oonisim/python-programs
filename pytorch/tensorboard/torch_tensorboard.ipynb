{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d766612c-cf85-4fd3-be67-3fa2f8417e00",
   "metadata": {
    "id": "d766612c-cf85-4fd3-be67-3fa2f8417e00"
   },
   "source": [
    "# Pytorch Tensorboard\n",
    "\n",
    "* [PyTorch - Visualizing Models, Data, and Training with TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n",
    "* [how-to-use-tensorboard-with-pytorch](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-tensorboard-with-pytorch.md)\n",
    "* [Pytorch TensorBoard Tutorial](https://www.youtube.com/watch?v=RLqsxWaQdHE)\n",
    "* [Using Tensorboard in Pytorch](https://krishansubudhi.github.io/deeplearning/2020/03/24/tensorboard-pytorch.html)\n",
    "* [PyTorch Profiler With TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)\n",
    "\n",
    "> In this tutorial, we will use a simple Resnet model to demonstrate how to use TensorBoard plugin to analyze model performance. Profiler API is capable of recording the CPU side operations as well as the CUDA kernel launches on the GPU side. The profiler can visualize this information in TensorBoard Plugin and provide analysis of the performance bottlenecks.\n",
    "\n",
    "## Training examples\n",
    "\n",
    "[Training with PyTorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)\n",
    "\n",
    "> For this tutorial, weâ€™ll be using the Fashion-MNIST dataset provided by TorchVision. We use torchvision.transforms.Normalize() to zero-center and normalize the distribution of the image tile content, and download both training and validation data splits.\n",
    "\n",
    "* [Kaggle - Fashion MNIST with Pytorch](https://www.kaggle.com/code/pankajj/fashion-mnist-with-pytorch-93-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ubPej8RQxX41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubPej8RQxX41",
    "outputId": "bce0e258-9868-412d-ba27-0b4877ce800f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "uOw8v8ecxX7s",
   "metadata": {
    "id": "uOw8v8ecxX7s"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'/content/gdrive/MyDrive/home/repository/git/oonisim/lib/code/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34059c8d-7d09-4e51-b819-d2889c285cdf",
   "metadata": {
    "id": "34059c8d-7d09-4e51-b819-d2889c285cdf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import (\n",
    "    product\n",
    ")\n",
    "from typing import (\n",
    "    List,\n",
    "    Union,\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import (\n",
    "    SummaryWriter,\n",
    ")\n",
    "# https://discuss.pytorch.org/t/error-while-multiprocessing-in-dataloader/46845/19\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89039171-97ab-425f-9121-b2730c52feb1",
   "metadata": {
    "id": "89039171-97ab-425f-9121-b2730c52feb1"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c311e96-df11-47fd-9465-61bb7f9426d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c311e96-df11-47fd-9465-61bb7f9426d8",
    "outputId": "f086406a-5937-4725-e863-dab28f190bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib.util_torch import (    # PYTHONPATH points to the library parent.\n",
    "    get_image_data_mean_std,\n",
    "    get_accuracy_multi_labels,\n",
    "    tensorboard_write_histogram,\n",
    "    tensorboard_write_graph,\n",
    "    tensorboard_write_image,\n",
    "    tensorboard_write_scalar,\n",
    "    tensorboard_write_scalars,\n",
    "    plot_confusion_matrix,\n",
    "    tensorboard_write_confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b66c4-7478-4ce3-8aed-adabe4d10424",
   "metadata": {
    "id": "8a6b66c4-7478-4ce3-8aed-adabe4d10424"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b8639-5210-41cb-b410-d1cac00857ba",
   "metadata": {
    "id": "9e8b8639-5210-41cb-b410-d1cac00857ba"
   },
   "source": [
    "## Train & Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ce2c7-864b-4376-b83c-d9383373c6c0",
   "metadata": {
    "id": "a24ce2c7-864b-4376-b83c-d9383373c6c0"
   },
   "source": [
    "### Calculate the mean and std of the pixels (features) per each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d24155-9d18-45b9-a2f5-c0aaf01173a6",
   "metadata": {
    "id": "23d24155-9d18-45b9-a2f5-c0aaf01173a6"
   },
   "outputs": [],
   "source": [
    "dataset_train = FashionMNIST(\n",
    "    os.getcwd(),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "mean, std = get_image_data_mean_std(\n",
    "    loader=torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=16)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7f144-70dd-48b8-800f-f15a666af25e",
   "metadata": {
    "id": "64b7f144-70dd-48b8-800f-f15a666af25e"
   },
   "source": [
    "### Normalize the image pixels (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "238ebb87-ac1a-4cbc-8058-ad59d1dd4995",
   "metadata": {
    "id": "238ebb87-ac1a-4cbc-8058-ad59d1dd4995"
   },
   "outputs": [],
   "source": [
    "dataset_train = FashionMNIST(\n",
    "    os.getcwd(),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a311e8c-7357-416c-9db3-20041ae0d7cf",
   "metadata": {
    "id": "0a311e8c-7357-416c-9db3-20041ae0d7cf"
   },
   "source": [
    "### Verify the std/mean of normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a62dd-626a-4b47-85c7-ba57f1e339ef",
   "metadata": {
    "id": "ac6a62dd-626a-4b47-85c7-ba57f1e339ef"
   },
   "outputs": [],
   "source": [
    "mean, std = get_image_data_mean_std(\n",
    "    loader=torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=16)\n",
    ")\n",
    "print(f\"(mean, std)={mean, std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8ed9c-520a-4fe1-b2b1-0a24cb0bd00b",
   "metadata": {
    "id": "a2a8ed9c-520a-4fe1-b2b1-0a24cb0bd00b"
   },
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88332e0d-4251-49ed-9c0d-12e950e34d28",
   "metadata": {
    "id": "88332e0d-4251-49ed-9c0d-12e950e34d28"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset_train))\n",
    "val_size = len(dataset_train) - train_size\n",
    "training_data, val_data = torch.utils.data.random_split(dataset_train, [train_size, val_size])\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(training_data, batch_size=8, shuffle=True, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=val_size,  shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6f467-92be-4066-9c24-26d3cbb6c297",
   "metadata": {
    "id": "ffd6f467-92be-4066-9c24-26d3cbb6c297"
   },
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da970e-84de-4c64-81e4-ed31a7de45ed",
   "metadata": {
    "id": "a4da970e-84de-4c64-81e4-ed31a7de45ed"
   },
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8deaa01e-8e7c-4d29-942a-6024ff0f659c",
   "metadata": {
    "id": "8deaa01e-8e7c-4d29-942a-6024ff0f659c"
   },
   "outputs": [],
   "source": [
    "dataset_test = FashionMNIST(\n",
    "    os.getcwd(),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    ")\n",
    "test_size: int = len(dataset_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=test_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04316f-0c34-42ac-bc18-683170ac35be",
   "metadata": {
    "id": "aa04316f-0c34-42ac-bc18-683170ac35be"
   },
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55e63a25-5cca-4f8e-a02a-e8c7a6d06c3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55e63a25-5cca-4f8e-a02a-e8c7a6d06c3c",
    "outputId": "1eb48eb7-c4a6-4b07-9cf3-90220b50f139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-Shirt',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle Boot']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "list(id_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a419293-4603-458e-a68c-a0540f67620b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7a419293-4603-458e-a68c-a0540f67620b",
    "outputId": "2e32c306-9706-4fa9-c2b6-74ef69e53936"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'T-Shirt'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label.get(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e029c38-4e64-40be-a73f-ebbf4f20d16c",
   "metadata": {
    "id": "3e029c38-4e64-40be-a73f-ebbf4f20d16c"
   },
   "source": [
    "## Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e52059bf-52bc-4fa3-b9fe-e0d49cbb06cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e52059bf-52bc-4fa3-b9fe-e0d49cbb06cb",
    "outputId": "60651149-b76a-41ea-e75e-3b551a570eec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = next(iter(val_loader))\n",
    "x = X[0]\n",
    "y = Y[0]\n",
    "\n",
    "channels: int = x.shape[0]\n",
    "width: int = x.shape[1]\n",
    "height: int = x.shape[2]\n",
    "(channels, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "048f13a9-6fe9-4dc7-9b15-0e564c58b753",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "048f13a9-6fe9-4dc7-9b15-0e564c58b753",
    "outputId": "640696d6-1dd1-442b-9511-8e3583912d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d21890184c0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(id_to_label.get(y.item()))\n",
    "plt.imshow(x.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053d8c2-f0e2-40b0-b77c-44c0e799fe02",
   "metadata": {
    "id": "0053d8c2-f0e2-40b0-b77c-44c0e799fe02"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f14595-b937-46b0-a81f-bd9355c23126",
   "metadata": {
    "id": "81f14595-b937-46b0-a81f-bd9355c23126"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5525d8ed-1e35-42ad-9a7e-f2e36b3ffead",
   "metadata": {
    "id": "5525d8ed-1e35-42ad-9a7e-f2e36b3ffead"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(channels, 16, kernel_size=3, padding=\"same\"),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(16, 32, kernel_size=3, padding=\"same\"),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(p=0.2, inplace=False),\n",
    "      nn.Linear(width * height * 32 // 16, 64),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 10)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65c73c67-a1cb-4404-9012-118770503f88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65c73c67-a1cb-4404-9012-118770503f88",
    "outputId": "dc6bd602-2bc0-4566-d27b-a1c76dc2bf97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): ReLU()\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Dropout(p=0.2, inplace=False)\n",
       "    (10): Linear(in_features=1568, out_features=64, bias=True)\n",
       "    (11): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd57da0-b866-4bf1-b17a-196dcaac6d55",
   "metadata": {
    "id": "1cd57da0-b866-4bf1-b17a-196dcaac6d55"
   },
   "source": [
    "---\n",
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c988ef-a029-4d44-9df5-d48b22114042",
   "metadata": {
    "id": "a2c988ef-a029-4d44-9df5-d48b22114042"
   },
   "source": [
    "## Model Grapph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4fba9735-7593-4714-88a3-c299e7a497b2",
   "metadata": {
    "id": "4fba9735-7593-4714-88a3-c299e7a497b2"
   },
   "outputs": [],
   "source": [
    "# tensorboard_write_graph(writer=writer, model=ConvNet(), x=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb3952-1d51-4b51-bc61-cf853a8ce781",
   "metadata": {
    "id": "c3cb3952-1d51-4b51-bc61-cf853a8ce781"
   },
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce240eae-1c9e-41f2-9c8c-003b67dd56a4",
   "metadata": {
    "id": "ce240eae-1c9e-41f2-9c8c-003b67dd56a4"
   },
   "outputs": [],
   "source": [
    "batch_sizes: List[int] = [\n",
    "    8, 16, 32, 64\n",
    "]\n",
    "learning_rates: List[float] = [\n",
    "    1e-3, 1e-4, 1e-5\n",
    "]\n",
    "beta1s: List[float] = [\n",
    "    0.85, 0.9, 0.95\n",
    "]\n",
    "beta2s: List[float] = [\n",
    "    0.9985, 0.999, 0.9995\n",
    "]\n",
    "decays: List[float] = [\n",
    "    0.005, 0.01, 0.015\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389290c5-bc33-416c-8038-f1f297485e0e",
   "metadata": {
    "id": "389290c5-bc33-416c-8038-f1f297485e0e"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fT0yURf670Ds",
   "metadata": {
    "id": "fT0yURf670Ds"
   },
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "gVF7YjJI7zYf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVF7YjJI7zYf",
    "outputId": "cc122b84-f414-48bd-a98e-2fe61a8e3300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Oy3mpvoo8B9S",
   "metadata": {
    "id": "Oy3mpvoo8B9S"
   },
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac6f08-c246-477f-897b-bda98afb4599",
   "metadata": {
    "id": "d6ac6f08-c246-477f-897b-bda98afb4599"
   },
   "outputs": [],
   "source": [
    "%rm -rf ./logs\n",
    "# writer = SummaryWriter(\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd062b-008c-444d-8a82-8e49d67430c7",
   "metadata": {
    "id": "c7dd062b-008c-444d-8a82-8e49d67430c7"
   },
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCHS: int = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b2482-38b1-40a8-adae-03742348e036",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c5b2482-38b1-40a8-adae-03742348e036",
    "outputId": "8be2cf75-b5d2-442e-bdfc-4804f5ea8dc8",
    "scrolled": true
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size:128 lr:0.001 beta1:0.85 beta2:0.9985 decay:0.005\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.287\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d218b5cd5d0>\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.873 val_loss  0.354\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.404\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d218b383fa0>\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.899 val_loss  0.281\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21867193c0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.895 val_loss  0.285\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d2188c42770>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.900 val_loss  0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d2184b1fa00>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc 0.276 test_loss  2.803\n",
      "\n",
      "max test accuracy:[0.2757] with batch:128 lr:0.001 beta1:0.85 beta2:0.9985 decay:0.005\n",
      "saving the model as model.pth...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size:128 lr:0.001 beta1:0.85 beta2:0.9985 decay:0.01\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d2188d89360>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.883 val_loss  0.326\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21843a5a50>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.894 val_loss  0.295\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21dd8973d0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.898 val_loss  0.285\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21862118a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.906 val_loss  0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d2186c605b0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc 0.230 test_loss  2.165\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size:128 lr:0.001 beta1:0.85 beta2:0.9985 decay:0.015\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21869c09a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.878 val_loss  0.338\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21de7580a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.899 val_loss  0.285\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d2189abbfd0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.900 val_loss  0.278\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d21de895060>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.900 val_loss  0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d2189445300>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc 0.250 test_loss  3.270\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "batch_size:128 lr:0.001 beta1:0.85 beta2:0.999 decay:0.005\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x7d22432e3e20>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc 0.884 val_loss  0.332\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.286\n"
     ]
    }
   ],
   "source": [
    "max_test_acc: float = 0.0\n",
    "writer = None\n",
    "\n",
    "for batch_size, lr, beta1, beta2, decay in product(batch_sizes, learning_rates, beta1s, beta2s, decays):\n",
    "    run_name: str = f\"./logs/batch{batch_size}_lr{lr}_beta1{beta1}_beta2{beta2}_decay{decay}\"\n",
    "\n",
    "    print()\n",
    "    print('-' * 80)\n",
    "    print(f\"batch_size:{batch_size} lr:{lr} beta1:{beta1} beta2:{beta2} decay:{decay}\")\n",
    "    print('-' * 80)\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Initialize at new parameter combination.\n",
    "    # --------------------------------------------------------------------------------\n",
    "    prev_loss: float = float(sys.maxsize)\n",
    "    early_stop_tolerance: int = 3\n",
    "\n",
    "    if isinstance(writer, SummaryWriter):\n",
    "        writer.close()\n",
    "\n",
    "    writer = SummaryWriter(run_name)\n",
    "\n",
    "    # num_workers=0 to avoid the issue in https://discuss.pytorch.org/t/error-while-multiprocessing-in-dataloader/46845/19\n",
    "    train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    model: nn.Module = ConvNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(beta1, beta2), weight_decay=decay)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='mean')   # normalized by batch size\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Train for each parameter combination.\n",
    "    # --------------------------------------------------------------------------------\n",
    "    for epoch in range(0, NUM_EPOCHS):\n",
    "        print(f'Starting epoch:[{epoch}].')\n",
    "        tensorboard_write_histogram(writer=writer, model=model, step=epoch)\n",
    "\n",
    "\n",
    "        _cumulative_loss: float = 0.0    # Reset cumulative training loss during an epoch\n",
    "        _train_loss: float = 0.0         # Reset training loss during an epoch\n",
    "        model.train(True)\n",
    "        for index, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            _batch_size: int = len(inputs)\n",
    "\n",
    "            # Write an image at every batch 0\n",
    "            if index == 0:\n",
    "                tensorboard_write_image(\n",
    "                    writer=writer, tag=\"image\", image=inputs[0], step=epoch, dataformats=\"CHW\"\n",
    "                )\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = model(inputs.to(device))\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, labels.to(device))\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            _cumulative_loss += loss.item()\n",
    "            _train_loss = _cumulative_loss / (index + 1)\n",
    "\n",
    "            if index % 1000 == 0:\n",
    "                print(f'training loss at batch:[{index:05d}]: {_train_loss:.03f}')\n",
    "\n",
    "            # if index > 209: break\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        # Reports per epoch\n",
    "        # --------------------------------------------------------------------------------\n",
    "        model.eval()\n",
    "\n",
    "        # Accuracy & confusion matrix\n",
    "        inputs = labels = predictions = None\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = next(iter(val_loader))\n",
    "\n",
    "            predictions = model(inputs.to(device))\n",
    "            val_loss = loss_fn(predictions, labels.to(device))\n",
    "\n",
    "        val_acc = get_accuracy_multi_labels(predictions=predictions.cpu(), labels=labels)\n",
    "\n",
    "        # Loss\n",
    "        tensorboard_write_scalars(\n",
    "            writer=writer,\n",
    "            tag=\"loss\",\n",
    "            tag_scalar_dict={\n",
    "                \"training\" : _train_loss,\n",
    "                \"validation\" : val_loss\n",
    "            },\n",
    "            step=epoch\n",
    "        )\n",
    "        tensorboard_write_scalar(\n",
    "            writer=writer, tag=\"validation accuracy/epoch\", value=val_acc, step=epoch\n",
    "        )\n",
    "        tensorboard_write_confusion_matrix(\n",
    "            writer=writer,\n",
    "            tag=\"validation confusion matrix\",\n",
    "            predictions=torch.argmax(predictions.cpu(), axis=-1),\n",
    "            truth=labels,\n",
    "            class_names=list(id_to_label.values()),\n",
    "            step=epoch\n",
    "        )\n",
    "        print(f'val_acc {val_acc:.03f} val_loss {val_loss: .03f}')\n",
    "        writer.flush()\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        # Early stop\n",
    "        # --------------------------------------------------------------------------------\n",
    "        if val_loss > prev_loss:\n",
    "            early_stop_tolerance -= 1\n",
    "        else:\n",
    "            prev_loss = val_loss\n",
    "\n",
    "        if early_stop_tolerance <= 0:\n",
    "            print(\"early stop\")\n",
    "            break\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Test\n",
    "    # --------------------------------------------------------------------------------\n",
    "    inputs = labels = predictions = None\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = next(iter(test_loader))\n",
    "        predictions = model(inputs.to(device))\n",
    "\n",
    "    test_loss = loss_fn(predictions, labels.to(device))\n",
    "    test_acc = get_accuracy_multi_labels(predictions=predictions.cpu(), labels=labels)\n",
    "    print(f'test_acc {test_acc:.03f} test_loss {test_loss: .03f}')\n",
    "\n",
    "    # Report test results\n",
    "    tensorboard_write_scalar(\n",
    "        writer=writer, tag=\"loss\", value=test_loss, step=epoch\n",
    "    )\n",
    "    tensorboard_write_scalar(\n",
    "        writer=writer, tag=\"accuracy\", value=test_acc, step=epoch\n",
    "    )\n",
    "    tensorboard_write_confusion_matrix(\n",
    "        writer=writer,\n",
    "        tag=\"test confusion matrix\",\n",
    "        predictions=torch.argmax(predictions.cpu(), axis=-1),\n",
    "        truth=labels,\n",
    "        class_names=list(id_to_label.values()),\n",
    "        step=epoch\n",
    "    )\n",
    "    writer.add_hparams(\n",
    "        hparam_dict={\"batch\": batch_size, \"lr\": lr, \"beta1\": beta1, \"beta2\": beta2, \"decay\": decay},\n",
    "        metric_dict={\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "        },\n",
    "        run_name=run_name,\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "    # Save model if the accuracy is better\n",
    "    if max_test_acc < test_acc:\n",
    "        print()\n",
    "        print(f\"max test accuracy:[{test_acc}] with batch:{batch_size} lr:{lr} beta1:{beta1} beta2:{beta2} decay:{decay}\")\n",
    "        max_test_acc = test_acc\n",
    "\n",
    "        print(f\"saving the model as model.pth...\")\n",
    "        torch.save(model, 'model.pth')\n",
    "\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b6784-644f-4104-8fb4-0638f5d9765c",
   "metadata": {
    "id": "2b2b6784-644f-4104-8fb4-0638f5d9765c"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6e5e9-ee9a-4aeb-9a89-d4068cd223d1",
   "metadata": {
    "id": "83b6e5e9-ee9a-4aeb-9a89-d4068cd223d1"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    predictions = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f287e3d-2c11-4af3-b981-378398c91d6d",
   "metadata": {
    "id": "9f287e3d-2c11-4af3-b981-378398c91d6d"
   },
   "outputs": [],
   "source": [
    "labels = labels.numpy()\n",
    "predictions = np.argmax(predictions.numpy(), axis=-1).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb111cbe-1d52-41ea-8f07-8248a99c6a73",
   "metadata": {
    "id": "eb111cbe-1d52-41ea-8f07-8248a99c6a73"
   },
   "source": [
    "matrix = confusion_matrix(y_true=labels, y_pred=predictions)\n",
    "fig = plot_confusion_matrix(matrix=matrix, class_names=list(id_to_label.values()))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d288c-5574-4ab5-822b-c23e531202ad",
   "metadata": {
    "id": "7a0d288c-5574-4ab5-822b-c23e531202ad"
   },
   "outputs": [],
   "source": [
    "tensorboard_write_confusion_matrix(\n",
    "    writer=writer,\n",
    "    tag=\"confusion matrix\",\n",
    "    predictions=predictions,\n",
    "    truth=labels,\n",
    "    class_names=list(id_to_label.values()),\n",
    "    step=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f31978-e40b-4857-8adb-a2c986b4fca3",
   "metadata": {
    "id": "e0f31978-e40b-4857-8adb-a2c986b4fca3"
   },
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae47d8ff-8122-40ca-a34f-f6353141c639",
   "metadata": {
    "id": "ae47d8ff-8122-40ca-a34f-f6353141c639",
    "outputId": "c052e9c0-8c44-4b84-b8ee-b159c44fae59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7aaf3248975c789a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7aaf3248975c789a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb4ce9-8e89-4333-9682-dab7e138ce7a",
   "metadata": {
    "id": "e5cb4ce9-8e89-4333-9682-dab7e138ce7a"
   },
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cd9b7-d1e8-4054-92e2-09151246b763",
   "metadata": {
    "id": "668cd9b7-d1e8-4054-92e2-09151246b763"
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172bda5-e104-4432-a334-2d01593e275d",
   "metadata": {
    "id": "6172bda5-e104-4432-a334-2d01593e275d"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
