{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d766612c-cf85-4fd3-be67-3fa2f8417e00",
   "metadata": {},
   "source": [
    "# Pytorch Tensorboard\n",
    "\n",
    "* [how-to-use-tensorboard-with-pytorch](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-tensorboard-with-pytorch.md)\n",
    "* [Pytorch TensorBoard Tutorial](https://www.youtube.com/watch?v=RLqsxWaQdHE)\n",
    "* [Using Tensorboard in Pytorch](https://krishansubudhi.github.io/deeplearning/2020/03/24/tensorboard-pytorch.html)\n",
    "\n",
    "## Training examples\n",
    "\n",
    "[Training with PyTorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)\n",
    "\n",
    "> For this tutorial, weâ€™ll be using the Fashion-MNIST dataset provided by TorchVision. We use torchvision.transforms.Normalize() to zero-center and normalize the distribution of the image tile content, and download both training and validation data splits.\n",
    "\n",
    "* [Kaggle - Fashion MNIST with Pytorch](https://www.kaggle.com/code/pankajj/fashion-mnist-with-pytorch-93-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34059c8d-7d09-4e51-b819-d2889c285cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import (\n",
    "    product\n",
    ")\n",
    "from typing import (\n",
    "    List,\n",
    "    Union,\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix\n",
    ")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import (\n",
    "    SummaryWriter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89039171-97ab-425f-9121-b2730c52feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c311e96-df11-47fd-9465-61bb7f9426d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main import (\n",
    "    tensorboard_write_histogram,\n",
    "    tensorboard_write_graph,\n",
    "    tensorboard_write_image,\n",
    "    tensorboard_write_scalar,\n",
    "    plot_confusion_matrix,\n",
    "    tensorboard_write_confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e78926a-c19a-49a5-8dd1-fcd96a186603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data_mean_std(\n",
    "        loader: DataLoader\n",
    "):\n",
    "    \"\"\"Compute the mean and standard deviation of all pixels in the dataset.\n",
    "    Args:\n",
    "        loader: data loader\n",
    "\n",
    "    Returns: (mean, std) where mean and std has shape:(num_channels,).\n",
    "    \"\"\"\n",
    "    count: int = 0\n",
    "    mean: float = 0.0\n",
    "    std: float = 0.0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        assert images.ndim == 4\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        # --------------------------------------------------------------------------------\n",
    "        # Compute the mean and standard deviation for each channel separately\n",
    "        # (e.g., one value for each of the RGB channels) by specifying axis=(0, 2, 3),\n",
    "        # as the mean and standard deviation are computed across the batch, height,\n",
    "        # and width dimensions, but not across the channel dimension.\n",
    "        # --------------------------------------------------------------------------------\n",
    "        count += 1\n",
    "        mean += images.mean(axis=(0, 2, 3))\n",
    "        std += images.std(axis=(0, 2, 3))\n",
    "\n",
    "    mean /= count\n",
    "    std /= count\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db02dacd-23e9-4d0c-b263-0bbbb9ba163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions: torch.Tensor, truth: torch.Tensor) -> float:\n",
    "    \"\"\"Calculate prediction accuracy\n",
    "    Returns: accuracy as float\n",
    "    \"\"\"\n",
    "    assert isinstance(predictions, torch.Tensor) and isinstance(truth, torch.Tensor)\n",
    "    predictions = torch.argmax(predictions, axis=-1)\n",
    "    assert predictions.shape == truth.shape\n",
    "    return float((predictions == truth).sum().numpy().item()) / float(predictions.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b66c4-7478-4ce3-8aed-adabe4d10424",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b8639-5210-41cb-b410-d1cac00857ba",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ce2c7-864b-4376-b83c-d9383373c6c0",
   "metadata": {},
   "source": [
    "### Calculate the mean and std of the pixels (features) per each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d24155-9d18-45b9-a2f5-c0aaf01173a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FashionMNIST(\n",
    "    os.getcwd(), \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "mean, std = get_image_data_mean_std(\n",
    "    loader=torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7f144-70dd-48b8-800f-f15a666af25e",
   "metadata": {},
   "source": [
    "### Normalize the image pixels (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238ebb87-ac1a-4cbc-8058-ad59d1dd4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FashionMNIST(\n",
    "    os.getcwd(), \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a311e8c-7357-416c-9db3-20041ae0d7cf",
   "metadata": {},
   "source": [
    "### Verify the std/mean of normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6a62dd-626a-4b47-85c7-ba57f1e339ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mean, std)=(tensor([4.1406e-07]), tensor([1.0001]))\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_image_data_mean_std(\n",
    "    loader=torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=1)\n",
    ")\n",
    "print(f\"(mean, std)={mean, std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8ed9c-520a-4fe1-b2b1-0a24cb0bd00b",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88332e0d-4251-49ed-9c0d-12e950e34d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset_train))\n",
    "val_size = len(dataset_train) - train_size\n",
    "training_data, val_data = torch.utils.data.random_split(dataset_train, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=16, shuffle=True, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=val_size,  shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6f467-92be-4066-9c24-26d3cbb6c297",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da970e-84de-4c64-81e4-ed31a7de45ed",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8deaa01e-8e7c-4d29-942a-6024ff0f659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = FashionMNIST(\n",
    "    os.getcwd(), \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    ")\n",
    "test_size: int = len(dataset_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=test_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04316f-0c34-42ac-bc18-683170ac35be",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e63a25-5cca-4f8e-a02a-e8c7a6d06c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-Shirt',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle Boot']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "list(id_to_label.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e029c38-4e64-40be-a73f-ebbf4f20d16c",
   "metadata": {},
   "source": [
    "## Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52059bf-52bc-4fa3-b9fe-e0d49cbb06cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = next(iter(train_loader))\n",
    "x = X[0]\n",
    "\n",
    "channels: int = x.shape[0]\n",
    "width: int = x.shape[1]\n",
    "height: int = x.shape[2]\n",
    "(channels, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048f13a9-6fe9-4dc7-9b15-0e564c58b753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29a7a5db0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac727ff9-f81b-48d0-a8b2-259083a15505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 0, 2, 9, 8, 0, 8, 1, 1, 3, 2, 8, 0, 2, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f14595-b937-46b0-a81f-bd9355c23126",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5525d8ed-1e35-42ad-9a7e-f2e36b3ffead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(channels, 16, kernel_size=3, padding=\"same\"),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(16, 32, kernel_size=3, padding=\"same\"),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(p=0.2, inplace=False),\n",
    "      nn.Linear(width * height * 32 // 16, 64),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 10)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd57da0-b866-4bf1-b17a-196dcaac6d55",
   "metadata": {},
   "source": [
    "# Tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ac6f08-c246-477f-897b-bda98afb4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf ./logs\n",
    "# writer = SummaryWriter(\"./logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c988ef-a029-4d44-9df5-d48b22114042",
   "metadata": {},
   "source": [
    "## Model Grapph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fba9735-7593-4714-88a3-c299e7a497b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard_write_graph(writer=writer, model=ConvNet(), x=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb3952-1d51-4b51-bc61-cf853a8ce781",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce240eae-1c9e-41f2-9c8c-003b67dd56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes: List[int] = [\n",
    "    8, 16, 32, 64\n",
    "]\n",
    "learning_rates: List[float] = [\n",
    "    1e-3, 1e-4, 1e-5\n",
    "]\n",
    "beta1s: List[float] = [\n",
    "    0.85, 0.9, 0.95\n",
    "]\n",
    "beta2s: List[float] = [\n",
    "    0.9985, 0.999, 0.9995\n",
    "]\n",
    "decays: List[float] = [\n",
    "    0.005, 0.01, 0.015\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b0a09a2-3511-4b8e-b908-8c2d9f666f66",
   "metadata": {},
   "source": [
    "learning_rates: List[float] = [\n",
    "    1e-4\n",
    "]\n",
    "beta1s: List[float] = [\n",
    "    0.9, 0.95\n",
    "]\n",
    "beta2s: List[float] = [\n",
    "    0.9985, 0.999\n",
    "]\n",
    "decays: List[float] = [\n",
    "    0.01\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389290c5-bc33-416c-8038-f1f297485e0e",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7dd062b-008c-444d-8a82-8e49d67430c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCHS: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b2482-38b1-40a8-adae-03742348e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.9985 decay:0.005\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.261\n",
      "training loss at batch:[01000]: 0.537\n",
      "training loss at batch:[02000]: 0.462\n",
      "val_acc 0.886 val_loss  0.315\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.206\n",
      "training loss at batch:[01000]: 0.319\n",
      "training loss at batch:[02000]: 0.316\n",
      "val_acc 0.903 val_loss  0.273\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.210\n",
      "training loss at batch:[01000]: 0.283\n",
      "training loss at batch:[02000]: 0.280\n",
      "val_acc 0.900 val_loss  0.274\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.209\n",
      "training loss at batch:[01000]: 0.258\n",
      "training loss at batch:[02000]: 0.260\n",
      "val_acc 0.905 val_loss  0.260\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.212\n",
      "training loss at batch:[01000]: 0.236\n",
      "training loss at batch:[02000]: 0.239\n",
      "val_acc 0.916 val_loss  0.230\n",
      "test_acc 0.389 test_loss  2.335\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.9985 decay:0.01\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.316\n",
      "training loss at batch:[01000]: 0.549\n",
      "training loss at batch:[02000]: 0.466\n",
      "val_acc 0.887 val_loss  0.315\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.270\n",
      "training loss at batch:[01000]: 0.319\n",
      "training loss at batch:[02000]: 0.318\n",
      "val_acc 0.903 val_loss  0.278\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.105\n",
      "training loss at batch:[01000]: 0.275\n",
      "training loss at batch:[02000]: 0.277\n",
      "val_acc 0.904 val_loss  0.259\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.315\n",
      "training loss at batch:[01000]: 0.254\n",
      "training loss at batch:[02000]: 0.256\n",
      "val_acc 0.898 val_loss  0.274\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.058\n",
      "training loss at batch:[01000]: 0.236\n",
      "training loss at batch:[02000]: 0.240\n",
      "val_acc 0.914 val_loss  0.242\n",
      "test_acc 0.409 test_loss  1.825\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.9985 decay:0.015\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.338\n",
      "training loss at batch:[01000]: 0.540\n",
      "training loss at batch:[02000]: 0.466\n",
      "val_acc 0.894 val_loss  0.304\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.627\n",
      "training loss at batch:[01000]: 0.319\n",
      "training loss at batch:[02000]: 0.311\n",
      "val_acc 0.899 val_loss  0.278\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.280\n",
      "training loss at batch:[01000]: 0.273\n",
      "training loss at batch:[02000]: 0.274\n",
      "val_acc 0.899 val_loss  0.273\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.290\n",
      "training loss at batch:[01000]: 0.247\n",
      "training loss at batch:[02000]: 0.250\n",
      "val_acc 0.914 val_loss  0.245\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.068\n",
      "training loss at batch:[01000]: 0.228\n",
      "training loss at batch:[02000]: 0.235\n",
      "val_acc 0.916 val_loss  0.233\n",
      "test_acc 0.394 test_loss  2.060\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.999 decay:0.005\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.293\n",
      "training loss at batch:[01000]: 0.532\n",
      "training loss at batch:[02000]: 0.468\n",
      "val_acc 0.894 val_loss  0.303\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.566\n",
      "training loss at batch:[01000]: 0.320\n",
      "training loss at batch:[02000]: 0.314\n",
      "val_acc 0.900 val_loss  0.279\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.503\n",
      "training loss at batch:[01000]: 0.279\n",
      "training loss at batch:[02000]: 0.280\n",
      "val_acc 0.906 val_loss  0.265\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.206\n",
      "training loss at batch:[01000]: 0.253\n",
      "training loss at batch:[02000]: 0.255\n",
      "val_acc 0.904 val_loss  0.269\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.238\n",
      "training loss at batch:[01000]: 0.236\n",
      "training loss at batch:[02000]: 0.241\n",
      "val_acc 0.904 val_loss  0.271\n",
      "test_acc 0.603 test_loss  1.283\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.999 decay:0.01\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.288\n",
      "training loss at batch:[01000]: 0.548\n",
      "training loss at batch:[02000]: 0.467\n",
      "val_acc 0.890 val_loss  0.305\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.100\n",
      "training loss at batch:[01000]: 0.324\n",
      "training loss at batch:[02000]: 0.316\n",
      "val_acc 0.905 val_loss  0.266\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.041\n",
      "training loss at batch:[01000]: 0.284\n",
      "training loss at batch:[02000]: 0.279\n",
      "val_acc 0.902 val_loss  0.264\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.436\n",
      "training loss at batch:[01000]: 0.259\n",
      "training loss at batch:[02000]: 0.255\n",
      "val_acc 0.903 val_loss  0.265\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.032\n",
      "training loss at batch:[01000]: 0.236\n",
      "training loss at batch:[02000]: 0.244\n",
      "val_acc 0.911 val_loss  0.243\n",
      "test_acc 0.407 test_loss  1.851\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.999 decay:0.015\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.330\n",
      "training loss at batch:[01000]: 0.545\n",
      "training loss at batch:[02000]: 0.465\n",
      "val_acc 0.893 val_loss  0.298\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.274\n",
      "training loss at batch:[01000]: 0.322\n",
      "training loss at batch:[02000]: 0.317\n",
      "val_acc 0.894 val_loss  0.296\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.619\n",
      "training loss at batch:[01000]: 0.283\n",
      "training loss at batch:[02000]: 0.284\n",
      "val_acc 0.909 val_loss  0.254\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.444\n",
      "training loss at batch:[01000]: 0.261\n",
      "training loss at batch:[02000]: 0.260\n",
      "val_acc 0.908 val_loss  0.253\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.081\n",
      "training loss at batch:[01000]: 0.234\n",
      "training loss at batch:[02000]: 0.239\n",
      "val_acc 0.910 val_loss  0.249\n",
      "test_acc 0.518 test_loss  1.590\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.9995 decay:0.005\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.338\n",
      "training loss at batch:[01000]: 0.540\n",
      "training loss at batch:[02000]: 0.461\n",
      "val_acc 0.886 val_loss  0.312\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.420\n",
      "training loss at batch:[01000]: 0.322\n",
      "training loss at batch:[02000]: 0.315\n",
      "val_acc 0.898 val_loss  0.278\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.113\n",
      "training loss at batch:[01000]: 0.277\n",
      "training loss at batch:[02000]: 0.280\n",
      "val_acc 0.904 val_loss  0.268\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.079\n",
      "training loss at batch:[01000]: 0.253\n",
      "training loss at batch:[02000]: 0.258\n",
      "val_acc 0.906 val_loss  0.262\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.358\n",
      "training loss at batch:[01000]: 0.240\n",
      "training loss at batch:[02000]: 0.240\n",
      "val_acc 0.907 val_loss  0.252\n",
      "test_acc 0.203 test_loss  3.168\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.9995 decay:0.01\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.251\n",
      "training loss at batch:[01000]: 0.549\n",
      "training loss at batch:[02000]: 0.469\n",
      "val_acc 0.893 val_loss  0.317\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.662\n",
      "training loss at batch:[01000]: 0.333\n",
      "training loss at batch:[02000]: 0.324\n",
      "val_acc 0.901 val_loss  0.282\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.378\n",
      "training loss at batch:[01000]: 0.294\n",
      "training loss at batch:[02000]: 0.288\n",
      "val_acc 0.897 val_loss  0.281\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.522\n",
      "training loss at batch:[01000]: 0.251\n",
      "training loss at batch:[02000]: 0.259\n",
      "val_acc 0.908 val_loss  0.260\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.214\n",
      "training loss at batch:[01000]: 0.245\n",
      "training loss at batch:[02000]: 0.247\n",
      "val_acc 0.914 val_loss  0.236\n",
      "test_acc 0.358 test_loss  2.658\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.85 beta2:0.9995 decay:0.015\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.225\n",
      "training loss at batch:[01000]: 0.540\n",
      "training loss at batch:[02000]: 0.462\n",
      "val_acc 0.896 val_loss  0.297\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.344\n",
      "training loss at batch:[01000]: 0.311\n",
      "training loss at batch:[02000]: 0.309\n",
      "val_acc 0.891 val_loss  0.298\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.217\n",
      "training loss at batch:[01000]: 0.280\n",
      "training loss at batch:[02000]: 0.273\n",
      "val_acc 0.913 val_loss  0.254\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.288\n",
      "training loss at batch:[01000]: 0.257\n",
      "training loss at batch:[02000]: 0.257\n",
      "val_acc 0.902 val_loss  0.273\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.303\n",
      "training loss at batch:[01000]: 0.242\n",
      "training loss at batch:[02000]: 0.241\n",
      "val_acc 0.914 val_loss  0.238\n",
      "test_acc 0.399 test_loss  1.674\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.9 beta2:0.9985 decay:0.005\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.472\n",
      "training loss at batch:[01000]: 0.548\n",
      "training loss at batch:[02000]: 0.468\n",
      "val_acc 0.894 val_loss  0.298\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.410\n",
      "training loss at batch:[01000]: 0.313\n",
      "training loss at batch:[02000]: 0.311\n",
      "val_acc 0.905 val_loss  0.263\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.177\n",
      "training loss at batch:[01000]: 0.278\n",
      "training loss at batch:[02000]: 0.280\n",
      "val_acc 0.903 val_loss  0.273\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.110\n",
      "training loss at batch:[01000]: 0.253\n",
      "training loss at batch:[02000]: 0.255\n",
      "val_acc 0.890 val_loss  0.283\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.056\n",
      "training loss at batch:[01000]: 0.238\n",
      "training loss at batch:[02000]: 0.238\n",
      "val_acc 0.911 val_loss  0.250\n",
      "test_acc 0.474 test_loss  1.714\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.9 beta2:0.9985 decay:0.01\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.311\n",
      "training loss at batch:[01000]: 0.547\n",
      "training loss at batch:[02000]: 0.473\n",
      "val_acc 0.874 val_loss  0.333\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.230\n",
      "training loss at batch:[01000]: 0.328\n",
      "training loss at batch:[02000]: 0.318\n",
      "val_acc 0.889 val_loss  0.308\n",
      "Starting epoch:[2].\n",
      "training loss at batch:[00000]: 0.152\n",
      "training loss at batch:[01000]: 0.279\n",
      "training loss at batch:[02000]: 0.278\n",
      "val_acc 0.907 val_loss  0.254\n",
      "Starting epoch:[3].\n",
      "training loss at batch:[00000]: 0.338\n",
      "training loss at batch:[01000]: 0.256\n",
      "training loss at batch:[02000]: 0.256\n",
      "val_acc 0.908 val_loss  0.249\n",
      "Starting epoch:[4].\n",
      "training loss at batch:[00000]: 0.567\n",
      "training loss at batch:[01000]: 0.238\n",
      "training loss at batch:[02000]: 0.237\n",
      "val_acc 0.914 val_loss  0.237\n",
      "test_acc 0.531 test_loss  1.158\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "lr:0.001 beat1:0.9 beta2:0.9985 decay:0.015\n",
      "--------------------------------------------------------------------------------\n",
      "Starting epoch:[0].\n",
      "training loss at batch:[00000]: 2.298\n",
      "training loss at batch:[01000]: 0.561\n",
      "training loss at batch:[02000]: 0.472\n",
      "val_acc 0.881 val_loss  0.326\n",
      "Starting epoch:[1].\n",
      "training loss at batch:[00000]: 0.127\n",
      "training loss at batch:[01000]: 0.328\n",
      "training loss at batch:[02000]: 0.321\n"
     ]
    }
   ],
   "source": [
    "for lr, beta1, beta2, decay in product(learning_rates, beta1s, beta2s, decays):\n",
    "    print()\n",
    "    print('-' * 80)\n",
    "    print(f\"lr:{lr} beat1:{beta1} beta2:{beta2} decay:{decay}\")\n",
    "    print('-' * 80)\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Initialize for each parameter combination.\n",
    "    # --------------------------------------------------------------------------------\n",
    "    prev_loss: float = float(sys.maxsize)\n",
    "    early_stop_tolerance: int = 3\n",
    "\n",
    "    run_name: str = f\"./logs/lr{lr}_beat1{beta1}_beta2{beta2}_decay{decay}\"\n",
    "    writer = SummaryWriter(run_name)\n",
    "\n",
    "    model: nn.Module = ConvNet()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(beta1, beta2), weight_decay=decay)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='mean')   # normalized by batch size\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Train for each parameter combination.\n",
    "    # --------------------------------------------------------------------------------\n",
    "    for epoch in range(0, NUM_EPOCHS):   # epochs at maximum\n",
    "        tensorboard_write_histogram(writer=writer, model=model, step=epoch)\n",
    "    \n",
    "        # Print epoch\n",
    "        print(f'Starting epoch:[{epoch}].')\n",
    "    \n",
    "        # Reset current loss value at eacch epoch\n",
    "        _current_loss: float = 0.0\n",
    "        _num_records: int = 0\n",
    "    \n",
    "        # Iterate over the DataLoader for training data\n",
    "        model.train(True)\n",
    "        for index, data in enumerate(train_loader, 0):\n",
    "            inputs, targets = data\n",
    "            _batch_size: int = len(inputs)\n",
    "    \n",
    "            # Write an image at every batch 0\n",
    "            if index == 0:\n",
    "                tensorboard_write_image(\n",
    "                    writer=writer, tag=\"image\", image=inputs[0], step=epoch, dataformats=\"CHW\"\n",
    "                )\n",
    "    \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Perform forward pass\n",
    "            outputs = model(inputs)\n",
    "    \n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, targets)\n",
    "    \n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "    \n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Print statistics\n",
    "            _current_loss += loss.item()\n",
    "    \n",
    "            if index % 1000 == 0:\n",
    "                print(f'training loss at batch:[{index:05d}]: {_current_loss / (index + 1):.03f}')\n",
    "\n",
    "            # if index > 209: break\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        # Reports per epoch\n",
    "        # --------------------------------------------------------------------------------\n",
    "        model.eval()\n",
    "\n",
    "        # Loss\n",
    "        tensorboard_write_scalar(\n",
    "            writer=writer, tag=\"training loss/epoch\", value=_current_loss / (index + 1), step=epoch\n",
    "        )\n",
    "    \n",
    "        # Validation accuracy & confusion matrix\n",
    "        inputs = labels = predictions = None\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = next(iter(val_loader))\n",
    "            # predictions = torch.argmax(model(inputs), axis=-1) # No need to argmax\n",
    "            predictions = model(inputs)\n",
    "            # val_loss = loss_fn(predictions.to(torch.float), labels.to(torch.float)) / len(labels)\n",
    "            val_loss = loss_fn(predictions, labels)\n",
    "\n",
    "        val_acc = get_accuracy(predictions=predictions, truth=labels)\n",
    "    \n",
    "        tensorboard_write_scalar(\n",
    "            writer=writer, tag=\"validation loss/epoch\", value=val_loss, step=epoch\n",
    "        )\n",
    "        tensorboard_write_scalar(\n",
    "            writer=writer, tag=\"validation accuracy/epoch\", value=val_acc, step=epoch\n",
    "        )\n",
    "        tensorboard_write_confusion_matrix(\n",
    "            writer=writer,\n",
    "            tag=\"validation confusion matrix\",\n",
    "            predictions=torch.argmax(predictions, axis=-1),\n",
    "            truth=labels,\n",
    "            class_names=list(id_to_label.values()),\n",
    "            step=epoch\n",
    "        )\n",
    "        print(f'val_acc {val_acc:.03f} val_loss {val_loss: .03f}')\n",
    "        writer.flush()\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        # Early stop\n",
    "        # --------------------------------------------------------------------------------\n",
    "        if val_loss > prev_loss:\n",
    "            early_stop_tolerance -= 1\n",
    "        else:\n",
    "            prev_loss = val_loss\n",
    "    \n",
    "        if early_stop_tolerance <= 0:\n",
    "            print(\"early stop\")\n",
    "            break\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Test\n",
    "    # --------------------------------------------------------------------------------\n",
    "    inputs = labels = predictions = None\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = next(iter(test_loader))\n",
    "        predictions = model(inputs)\n",
    "\n",
    "    test_loss = loss_fn(predictions, labels)\n",
    "    test_acc = get_accuracy(predictions=predictions, truth=labels)\n",
    "    print(f'test_acc {test_acc:.03f} test_loss {test_loss: .03f}')\n",
    "\n",
    "    tensorboard_write_scalar(\n",
    "        writer=writer, tag=\"test loss/epoch\", value=test_loss, step=epoch\n",
    "    )\n",
    "    tensorboard_write_scalar(\n",
    "        writer=writer, tag=\"test accuracy/epoch\", value=test_acc, step=epoch\n",
    "    )\n",
    "    tensorboard_write_confusion_matrix(\n",
    "        writer=writer,\n",
    "        tag=\"test confusion matrix\",\n",
    "        predictions=torch.argmax(predictions, axis=-1),\n",
    "        truth=labels,\n",
    "        class_names=list(id_to_label.values()),\n",
    "        step=epoch\n",
    "    )\n",
    "    writer.add_hparams(\n",
    "        hparam_dict={\"lr\": lr, \"beta1\": beta1, \"beta2\": beta2, \"decay\": decay},\n",
    "        metric_dict={\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "        },\n",
    "        run_name=run_name,\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b6784-644f-4104-8fb4-0638f5d9765c",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6e5e9-ee9a-4aeb-9a89-d4068cd223d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    predictions = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f287e3d-2c11-4af3-b981-378398c91d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.numpy()\n",
    "predictions = np.argmax(predictions.numpy(), axis=-1).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb111cbe-1d52-41ea-8f07-8248a99c6a73",
   "metadata": {},
   "source": [
    "matrix = confusion_matrix(y_true=labels, y_pred=predictions)\n",
    "fig = plot_confusion_matrix(matrix=matrix, class_names=list(id_to_label.values()))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d288c-5574-4ab5-822b-c23e531202ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_write_confusion_matrix(\n",
    "    writer=writer,\n",
    "    tag=\"confusion matrix\",\n",
    "    predictions=predictions,\n",
    "    truth=labels,\n",
    "    class_names=list(id_to_label.values()),\n",
    "    step=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f31978-e40b-4857-8adb-a2c986b4fca3",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae47d8ff-8122-40ca-a34f-f6353141c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d88095-f3ac-4f27-b11b-5bec21dea481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
