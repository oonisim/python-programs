{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebf894d-f6bd-403b-81e8-053678ca766f",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "* [Pytorch TensorBoard Tutorial](https://www.youtube.com/watch?v=RLqsxWaQdHE&t=3s)\n",
    "\n",
    "* [Visualizing Models, Data, and Training with TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74013915-a28d-4967-b4e5-94e23cf55dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn.init import (\n",
    "    xavier_normal_,\n",
    "    kaiming_normal_,\n",
    "    zeros_,\n",
    ")\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import (\n",
    "    SGD\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aeed5-8158-446b-8c39-1895f7fe42e0",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1acd4c-9b54-4ef5-9ffa-0fe5a0cc8950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c96d0-b28f-4b81-9201-5bb7248a3563",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c754ff97-b42e-433e-8614-9ab0e4ca1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12504413-16e4-4606-8727-b1b4b6191a68",
   "metadata": {},
   "source": [
    "# dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7004b187-9556-4897-9b34-ac82f5fa81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8dbdd-d9c3-4f54-8859-73031ece9bd3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad158aa-35f8-44fb-824d-ff20fa217d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        kaiming_normal_(self.fc1.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        zeros_(self.fc1.bias)\n",
    "        kaiming_normal_(self.fc2.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        zeros_(self.fc2.bias)\n",
    "        xavier_normal_(self.fc3.weight)\n",
    "        zeros_(self.fc3.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563cb296-b5fc-4717-822f-0079e96d225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c38545-bdb2-418d-a43f-47128c250bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "LR: float = 1e-3\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18f0a9-c47b-4bab-8fe9-a935e551a05e",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ee4956-160d-4266-a6fd-fc5298b69bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a988cfd-9152-4cf6-814a-2b0121328658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a82a6e-076f-4833-b932-23f35a1fd87c",
   "metadata": {},
   "source": [
    "## Add Model to the Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5bda250-42e2-4561-8193-a612689c6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, images)    # <--- Model to show in \"Graph\" view\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0adb2-e0b0-469a-aa34-72fc0b359852",
   "metadata": {},
   "source": [
    "## Add image embeddings\n",
    "\n",
    "“Projector” tab of TensorBoard shows the images - each of which is 784 dimensional - projected down into three dimensional space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6886118-3489-4a4e-a329-7b2c71a9de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f0bad-ce34-44b0-84d0-72d9a1bb2de1",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16b84516-d820-49bf-ab6b-8ff3985cac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "LR: float = 1e-3\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012f1f6-7675-4e14-95b7-9874bb4fd431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad40268-f2f3-4d2a-af7c-cc63d7dbbafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(model, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = model(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(model, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(model, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3159fff2-3262-4a96-ae51-d5e6d29586f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(model, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2b6f7-e7cc-4c8e-8917-ccd2cbdde8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
