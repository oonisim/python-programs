{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25dc93aa",
   "metadata": {},
   "source": [
    "# Auto Class\n",
    "\n",
    "* [Auto Classes](https://huggingface.co/docs/transformers/model_doc/auto) \n",
    "\n",
    "> In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model to the from_pretrained() method. Instantiating one of AutoConfig, AutoModel, and AutoTokenizer will directly create a class of the relevant architecture. For instance\n",
    "\n",
    "NOTE: ```AutoModel``` is for PyTorch. because Huggingface started its implementation with PyTorch and later added TensorFlow support.\n",
    "\n",
    "* [How to load a pretrained TF model using AutoModel? #2773](https://github.com/huggingface/transformers/issues/2773)\n",
    "\n",
    "> It seems that ```AutoModel``` defaultly loads the pretrained PyTorch models, but how can I use it to load a pretrained TF model?  \n",
    "> you should use ```TFAutoModel``` instead\n",
    "\n",
    "```\n",
    "# For PyTorch\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# For TensorFlow\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Auto Tokenizer\n",
    "\n",
    "You can use ```AutoTokenizer``` for **both** PyTorch and TensorFlow. Use **Fast** tokenizer wherever possible, not the Python tokenizers.\n",
    "\n",
    "\n",
    "* [AutoTokenizer](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer)\n",
    "\n",
    "> This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when created with the AutoTokenizer.from_pretrained() class method.\n",
    "\n",
    "* [AutoTokenizer.from_pretrained](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer.from_pretrained)\n",
    "\n",
    "> ```\n",
    "> from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfe8e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df079ce174a8427ca75cded771280dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805afa72aae4930ad4c3539a2441908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a322afcfee44e5a4114f37c8792417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path='bigscience/bloom-560m', \n",
    "    use_fast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09af0de",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839491b1",
   "metadata": {},
   "source": [
    "## call\n",
    "\n",
    "[```__call__```](https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase.__call__) method or ```tokenizer(input)``` geneates the ```token ids``` and ```attention masks``` to feed into the model.\n",
    "\n",
    "Attention Masks are the flags to tell the model if the token should be used or ignored.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2fb0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "{'input_ids': [36, 31346, 13502, 632, 361, 17817, 461, 105814, 368, 59499, 613, 267, 5550, 17], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\"A tokenizer is in charge of preparing the inputs for a model.\")\n",
    "print(type(tokenized))\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c423884",
   "metadata": {},
   "source": [
    "## encode\n",
    "\n",
    "[encode](https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode) method generates the ```token ids``` without the Attention Masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d80072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 31346, 13502, 632, 361, 17817, 461, 105814, 368, 59499, 613, 267, 5550, 17]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(\"A tokenizer is in charge of preparing the inputs for a model.\")\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1693590",
   "metadata": {},
   "source": [
    "## decode\n",
    "\n",
    "* [decode](https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase.decode) methods reverts the ```ids``` back to strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67bcb1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A tokenizer is in charge of preparing the inputs for a model.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18691f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
