{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cde2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d095ea",
   "metadata": {},
   "source": [
    "# Language (Model)\n",
    "\n",
    "Language class has its default rules defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47519ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07940d",
   "metadata": {},
   "source": [
    "# Prefix, Infix, Suffix\n",
    "\n",
    "Tokenizer extract prefix, infix, and suffix chracters from text as a token. The rules are defined in the Language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a30780",
   "metadata": {},
   "source": [
    "* [Tokenization](https://spacy.io/usage/linguistic-features#tokenization)\n",
    "\n",
    "> During processing, spaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off ‚Äì whereas ‚ÄúU.K.‚Äù should remain one token. \n",
    "> \n",
    "> The prefixes, suffixes and infixes mostly define punctuation rules ‚Äì for example, when to split off periods (at the end of a sentence), and when to leave tokens containing periods intact (abbreviations like ‚ÄúU.S.‚Äù).\n",
    "> \n",
    "> * Prefix: Character(s) at the beginning, e.g. ```$, (, ‚Äú, ¬ø```\n",
    "> * Infix: Character(s) in between, e.g. ```-, --, /, ‚Ä¶```\n",
    "> * Suffix: Character(s) at the end, e.g. ```km, ), ‚Äù, !```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecd347",
   "metadata": {},
   "source": [
    "## Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a68117e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¬ß', '%', '=', '‚Äî', '‚Äì', '\\\\+(?![0-9])', '‚Ä¶', '‚Ä¶‚Ä¶', ',', ':']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.islice(nlp.Defaults.prefixes, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403a349",
   "metadata": {},
   "source": [
    "## infixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b23fab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\.\\\\.+'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.infixes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcb959",
   "metadata": {},
   "source": [
    "## Suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb281fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚Ä¶', '‚Ä¶‚Ä¶', ',', ':', ';', '\\\\!', '\\\\?', '¬ø', 'ÿü', '¬°']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.islice(nlp.Defaults.suffixes, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20c2d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "cool\n",
      "100\n",
      "-\n",
      "150\n",
      "km\n",
      "(\n",
      "üò≥\n",
      ")\n",
      "run\n",
      "omg\n",
      "...\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"#cool 100-150km (üò≥) run omg... !\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8b36c",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "* ```#```, ```(``` are tokenized by the prefix rules.\n",
    "* ```-```, ```...``` are tokenized by the infix rules.\n",
    "* ```)```, ```!``` are tokenized by the suffix rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357e51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
