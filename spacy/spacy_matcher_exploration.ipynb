{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea49b73-b43b-4245-9cd4-eed9fe8c6d29",
   "metadata": {},
   "source": [
    "# Spacy Matcher\n",
    "\n",
    "* [Rule-based matching](https://spacy.io/usage/rule-based-matching)\n",
    "* [Matcher](https://spacy.io/api/matcher)\n",
    "* [Rule-based Matcher Explorer](https://demos.explosion.ai/matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57220627-74a8-4f9b-b4ef-b46c4271458a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea865b1e-e456-4b6b-a635-cd2c55bde280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    List, \n",
    "    Dict,\n",
    "    Tuple\n",
    ")\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.symbols import (\n",
    "    nsubj, nsubjpass, dobj, iobj, pobj\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5c689-f7a3-4f91-92ac-65339cd7a655",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ce345d-e9e5-4920-b125-e42e9497832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "vocabulrary: spacy.vocab.Vocab = nlp.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2fd2f-1f90-4483-ae8c-bc87ddfbc12e",
   "metadata": {},
   "source": [
    "# Matcher\n",
    "\n",
    "The matcher must always share the same ```vocab``` of the documents it will operate on. Use the vocabulrary of the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd967ee5-bdf1-426f-9b28-68829c18de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(vocabulrary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b8220-d1d6-41ba-8177-f6e324db7624",
   "metadata": {},
   "source": [
    "## Pattern (Token Sequence)\n",
    "\n",
    "Pattern is to find a sequence of token**s** whose [attributes](https://spacy.io/api/attributes) match the rules defined. \n",
    "\n",
    "* each **pattern** is a list of rules sequenced as ```AND``` logic.\n",
    "* each **rule** is a dictionary listing one or more expression ```{expression+}```.\n",
    "* each **expression** can have ```token-attribute : value [: operator]``` where ```operator``` is a regular expression repetition operator.\n",
    "\n",
    "```\n",
    "pattern=[\n",
    "    {expression},\n",
    "    {expression},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "### Operator\n",
    "\n",
    "To match exactly once, omit the OP.\n",
    "\n",
    "\n",
    "| OP     |                                                                     |\n",
    "|:-------|:--------------------------------------------------------------------|\n",
    "| !      | Negate the pattern, by requiring it to match exactly 0 times.       |\n",
    "| ?      | Make the pattern optional, by allowing it to match 0 or 1 times.    |\n",
    "| +      | Require the pattern to match 1 or more times.                       |\n",
    "| *      | Allow the pattern to match zero or more times.                      |\n",
    "| {n}    | Require the pattern to match exactly n times.                       |\n",
    "| {n,m}  | Require the pattern to match at least n but not more than m times.  |\n",
    "| {n,}   | Require the pattern to match at least n times.                      |\n",
    "| {,m}   | Require the pattern to match at most m times.                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14efe28-890f-49d1-96bf-e2d6ac866b53",
   "metadata": {},
   "source": [
    "### Single Token Match \n",
    "Example to find one token whose ```POS``` is **noun**, ```lemma``` is **match**, in ```LOWER``` case as **matches**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91669be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str = \"\"\"\n",
    "A match starts a fire. Modern matches are small wooden sticks.\n",
    "Regex \\w+es matches plurals.\n",
    "Little Girl Selling Matches is about a girl selling matches dying.\n",
    "\"\"\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138a007d-7fe1-45af-827f-19c26532ce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"POS\": \"NOUN\",\n",
      "        \"LEMMA\": \"match\",\n",
      "        \"LOWER\": \"matches\",\n",
      "        \"OP\": \"?\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "rule = {\n",
    "    'POS': 'NOUN', \n",
    "    'LEMMA': 'match',\n",
    "    'LOWER': 'matches',\n",
    "    'OP': '?',\n",
    "}\n",
    "\n",
    "pattern: List[Dict[str, str]] = [\n",
    "    rule    \n",
    "]\n",
    "print(json.dumps(pattern, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f01b3c-7caf-4dc2-9855-6db16498d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\n",
    "    \"find_noun_matches\", \n",
    "    [\n",
    "        pattern\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc426e-df66-40b5-998e-a7bdf2592fe7",
   "metadata": {},
   "source": [
    "#### as_span\n",
    "\n",
    "Find the matches. Matcher returns spans with ```as_spans=True```, otherwise ```(match_id, start, end)```. Stick to spans so that later tools like [util.filter_spans](https://spacy.io/api/top-level#util.filter_spans) can be applied to remove duplicates.\n",
    "\n",
    "* [Matcher.__call__(doclike, as_spans)](https://spacy.io/api/matcher#call)\n",
    "\n",
    "> ```as_spans```:  Instead of tuples, return a list of Span objects of the matches, with the match_id assigned as the span label. Defaults to False.\n",
    "\n",
    "\n",
    "```Span``` class gives character indices with ```start_char``` and ```end_char``` attributes.\n",
    "\n",
    "* [Spacy2 Matcher receiving position of match entity from text](https://github.com/explosion/spaCy/issues/2544)\n",
    "\n",
    "```\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start: end]\n",
    "    print(span.text, span.start_char, span.end_char)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce76f605-1b4c-43ae-ae28-00136045b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doclike=doc, as_spans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26fbc683-e807-4a62-b7e7-43b01b95886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start token: 8:31 end token: 9:38 match: matches\n",
      "start token: 30:145 end token: 31:152 match: matches\n",
      "token: '\\n'\n",
      "token: A           \n",
      "token: match       \n",
      "token: starts      \n",
      "token: a           \n",
      "token: fire        \n",
      "token: .           \n",
      "token: Modern      \n",
      "token: matches      <----- found\n",
      "token: are         \n",
      "token: small       \n",
      "token: wooden      \n",
      "token: sticks      \n",
      "token: .           \n",
      "token: '\\n'\n",
      "token: Regex       \n",
      "token: \\w+es       \n",
      "token: matches     \n",
      "token: plurals     \n",
      "token: .           \n",
      "token: '\\n'\n",
      "token: Little      \n",
      "token: Girl        \n",
      "token: Selling     \n",
      "token: Matches     \n",
      "token: is          \n",
      "token: about       \n",
      "token: a           \n",
      "token: girl        \n",
      "token: selling     \n",
      "token: matches      <----- found\n",
      "token: dying       \n",
      "token: .           \n",
      "token: '\\n'\n"
     ]
    }
   ],
   "source": [
    "matched_token_span_locations: List[Tuple] = []\n",
    "# for match_id, start, end in matches:\n",
    "for match in matches:\n",
    "    matched_token_span_locations.append((match.start, match.end, match.start_char, match.end_char))\n",
    "\n",
    "for start, end, start_char, end_char in matched_token_span_locations:\n",
    "    print(f\"start token: {start}:{start_char} end token: {end}:{end_char} match: {doc[start:end]}\")\n",
    "\n",
    "mached: int = 0\n",
    "for token in doc:\n",
    "    if matched_token_span_locations[mached][0] <= token.i < matched_token_span_locations[mached][1]:\n",
    "        print(f\"token: {token.text:12} <----- found\")        \n",
    "    elif token.is_space:\n",
    "        print(f\"token: {repr(token.text)}\") \n",
    "    else:\n",
    "        print(f\"token: {token.text:12}\")        \n",
    "\n",
    "    if token.i >= matched_token_span_locations[mached][1]:\n",
    "        if mached < len(matched_token_span_locations) -1:\n",
    "            mached += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06802670-8345-42cc-8a73-da564f18d8a9",
   "metadata": {},
   "source": [
    "### Multi Token Match\n",
    "\n",
    "Listing multiple rules defines ```AND``` pattern to match a specific token sequence. Example to find a token sequence ```hello, world``` or ```hello! world```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c93dbdc6-3f88-4d75-9af2-346638ecbc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str = \"Start learning with hello! world is from The C Programming Language.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625c03b1-cfc0-4de5-a24b-8d7e72a414d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"LOWER\": \"hello\"},    # AND\n",
    "    {\"IS_PUNCT\": True},    # AND\n",
    "    {\"LOWER\": \"world\"}\n",
    "]\n",
    "matcher.add(\n",
    "    \"find_hello_punctuation_world\", \n",
    "    [\n",
    "        pattern\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee4cd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doclike=doc, as_spans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e84d1dd4-cad5-407f-8d5f-a234fdc9a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: Start       \n",
      "token: learning    \n",
      "token: with        \n",
      "token: hello        <----- found\n",
      "token: !            <----- found\n",
      "token: world        <----- found\n",
      "token: is          \n",
      "token: from        \n",
      "token: The         \n",
      "token: C           \n",
      "token: Programming \n",
      "token: Language    \n",
      "token: .           \n"
     ]
    }
   ],
   "source": [
    "matched_token_span_locations: List[Tuple] = []\n",
    "# for match_id, start, end in matches:\n",
    "for match in matches:\n",
    "    matched_token_span_locations.append((match.start, match.end))\n",
    "\n",
    "mached: int = 0\n",
    "for token in doc:\n",
    "    if matched_token_span_locations[mached][0] <= token.i < matched_token_span_locations[mached][1]:\n",
    "        print(f\"token: {token.text:12} <----- found\")        \n",
    "    elif token.is_space:\n",
    "        print(f\"token: {repr(token.text)}\") \n",
    "    else:\n",
    "        print(f\"token: {token.text:12}\")        \n",
    "\n",
    "    if token.i >= matched_token_span_locations[mached][1]:\n",
    "        if mached < len(matched_token_span_locations) -1:\n",
    "            mached += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c119c6e",
   "metadata": {},
   "source": [
    "---\n",
    "# Handle duplicates\n",
    "\n",
    "A pattern can have multiple overlapping spans (including the same word at the same position). To reduce to the longest span, use [util.filter_spans](https://spacy.io/api/top-level#util.filter_spans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536fc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str = \"He has his multiple guitars and beautiful old pianos.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93963702",
   "metadata": {},
   "source": [
    "Noun phrase ```(ADJ*, NOUN)``` pattern matches multiple spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764345ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"POS\": \"ADJ\", \"OP\": '*'},{\"POS\": \"NOUN\", \"OP\": \"{1}\"}\n",
    "]\n",
    "matcher.add(\n",
    "    \"find_noun_phrases\",\n",
    "    [\n",
    "        pattern\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c474d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple guitars               start:[3   ] end:[5   ]\n",
      "guitars                        start:[4   ] end:[5   ]\n",
      "beautiful old pianos           start:[6   ] end:[9   ]\n",
      "old pianos                     start:[7   ] end:[9   ]\n",
      "pianos                         start:[8   ] end:[9   ]\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doclike=doc, as_spans=True)\n",
    "for match in matches:\n",
    "    print(f\"{match.text:30} start:[{match.start:<4}] end:[{match.end:<4}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bc3b5",
   "metadata": {},
   "source": [
    "### Limit to the longest span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4a46fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3   5   multiple guitars\n",
      "6   9   beautiful old pianos\n"
     ]
    }
   ],
   "source": [
    "for span in spacy.util.filter_spans(matches):\n",
    "    print(f\"{span.start:<4}{span.end:<4}{span.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d77fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Noun Phrase\n",
    "\n",
    "## Using Spacy ```spacy.doc.noun_chunks```\n",
    "\n",
    "Spacy has doc.noun_chunks to extract noun phrases instead of using a matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0c17067",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"He has multiple guitar and five beautiful pianos in his collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32c371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "multiple guitar\n",
      "five beautiful pianos\n",
      "his collection\n"
     ]
    }
   ],
   "source": [
    "for n in doc.noun_chunks:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3518c9f",
   "metadata": {},
   "source": [
    "## Using Spacy syntactic context\n",
    "\n",
    "* [Noun phrases with spacy](https://stackoverflow.com/a/33512175/4281353)\n",
    "\n",
    "> the best way is to iterate over the words of the sentence and consider the syntactic context to determine whether the word governs the phrase-type you want. If it does, yield its subtree\n",
    "> ```\n",
    "> from spacy.symbols import *\n",
    "> \n",
    "> np_labels = set([nsubj, nsubjpass, dobj, iobj, pobj]) # Probably others too\n",
    "> def iter_nps(doc):\n",
    ">     for word in doc:\n",
    ">         if word.dep in np_labels:\n",
    ">             yield word.subtree\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38ec5435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple guitar and five beautiful piano in his collection\n",
      "his collection\n"
     ]
    }
   ],
   "source": [
    "np_labels = {\n",
    "    nsubjpass, dobj, iobj, pobj\n",
    "}\n",
    "\n",
    "for word in doc:\n",
    "    if word.dep in np_labels:\n",
    "        print(' '.join([token.lemma_ for token in word.subtree]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13028a31",
   "metadata": {},
   "source": [
    "### Using matcher pattern\n",
    "\n",
    "* [Noun phrases with spacy](https://stackoverflow.com/a/33512175/4281353)\n",
    "\n",
    ">  to specify more exactly which kind of noun phrase you want to extract, you can use textacy's matches function. You can pass any combination of POS tags.  \n",
    "> ```\n",
    "> textacy.extract.matches(doc, \"POS:ADP POS:DET:? POS:ADJ:? POS:NOUN:+\")\n",
    "> ```\n",
    "\n",
    "Textacty is just a wrapper of Spacy. Use Spacy matcher pattern is equivalent. For example, to get nouns that are preceded by a preposition and optionally by a determiner and/or adjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20c56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"He hit at the old guitar case  twice.\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"LOWER\": \"hello\"},    # AND\n",
    "    {\"IS_PUNCT\": True},    # AND\n",
    "    {\"LOWER\": \"world\"}\n",
    "]\n",
    "pattern = [\n",
    "    {\"POS\":\"ADP\"}, \n",
    "    {\"POS\": \"DET\", \"OP\":\"?\"}, \n",
    "    {\"POS\":\"ADJ\", \"OP\":\"?\"}, \n",
    "    {\"POS\":\"NOUN\", \"OP\":\"+\"}\n",
    "]\n",
    "matcher.add(\n",
    "    \"find_complex\", \n",
    "    [\n",
    "        pattern\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1d3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the old guitar case\n"
     ]
    }
   ],
   "source": [
    "matches = spacy.util.filter_spans(matcher(doclike=doc, as_spans=True))\n",
    "for span in matches:\n",
    "    print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b5111-0879-44a6-84fb-c6a6816cf025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
