{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba8a8f1",
   "metadata": {},
   "source": [
    "# Spacy Wordnet\n",
    "\n",
    "* [spacy-wordnet](https://spacy.io/universe/project/spacy-wordnet)\n",
    "\n",
    "> spacy-wordnet creates annotations that easily allow the use of WordNet and [WordNet Domains](http://wndomains.fbk.eu/) by using the [NLTK WordNet interface](http://www.nltk.org/howto/wordnet.html).\n",
    "\n",
    "* [PyPi spaCy WordNet](https://pypi.org/project/spacy-wordnet/)\n",
    "\n",
    "> You also need to install the following NLTK wordnet data:\n",
    "> ```\n",
    "> python -m nltk.downloader wordnet\n",
    "> python -m nltk.downloader omw\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922cf604",
   "metadata": {},
   "source": [
    "!python -m nltk.downloader wordnet\n",
    "!python -m nltk.downloader omw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0840b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.symbols import nsubj, dobj, iobj, VERB\n",
    "import spacy_wordnet\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc4fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_text(tokens, sep=',') -> str:\n",
    "    return sep.join(map(str, list(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d443b3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a071796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_wordnet.wordnet_annotator.WordnetAnnotator at 0x1038c5d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b9e45",
   "metadata": {},
   "source": [
    "# Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94094176",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51cfcb",
   "metadata": {},
   "source": [
    "# Finding Subject Noun Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d4b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   Autonomous cars                         NOUN   nsubj\n",
      "['politics']\n",
      "1   shifted                                 VERB   ROOT\n",
      "['basketball', 'earth', 'computer_science', 'earth', 'railway']\n",
      "2   insurance                               NOUN   compound\n",
      "['book_keeping', 'money', 'finance', 'economy', 'tax']\n",
      "3   liability                               NOUN   dobj\n",
      "['finance', 'tax', 'money', 'book_keeping', 'finance']\n",
      "4   to                                      ADP    prep\n",
      "[]\n",
      "5   manufacturers                           NOUN   pobj\n",
      "['industry', 'economy', 'exchange', 'commerce', 'enterprise']\n",
      "6   .                                       PUNCT  punct\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Autonomous cars shifted insurance liability to manufacturers.\n",
    "\"\"\"\n",
    "doc = nlp(' '.join(text.split()))\n",
    "\n",
    "subjects = []\n",
    "for candidate in doc:\n",
    "    if candidate.dep == nsubj and candidate.head.pos == VERB:\n",
    "        subjects.append(candidate)\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    for subject in subjects:\n",
    "        span = doc[subject.left_edge.i : subject.right_edge.i+1]\n",
    "        retokenizer.merge(span)\n",
    "        \n",
    "for token in doc:\n",
    "    print(f\"{token.i:<4}{token.text:40}{token.pos_:7}{token.dep_}\")\n",
    "    print(token._.wordnet.wordnet_domains()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afd812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet object links spaCy token with NLTK WordNet interface by giving access to synsets and lemmas \n",
    "print(token._.wordnet.synsets())\n",
    "print(token._.wordnet.lemmas())\n",
    "\n",
    "# And automatically add info about WordNet domains\n",
    "token._.wordnet.wordnet_domains()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
