{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad268e9",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [PyDeequ](https://github.com/awslabs/python-deequ)\n",
    "\n",
    "> PyDeequ is a Python API for Deequ, a library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets. PyDeequ is written to support usage of Deequ in Python.\n",
    "\n",
    "> <img src=\"image/pydeequ_architecture.jpg\" align=\"left\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5bb0b",
   "metadata": {},
   "source": [
    "\n",
    "* [Test data quality at scale with Deequ](https://aws.amazon.com/blogs/big-data/test-data-quality-at-scale-with-deequ/)\n",
    "\n",
    ">  Deequ, an open source tool developed and used at Amazon. Deequ allows you to calculate data quality metrics on your dataset, define and verify data quality constraints, and be informed about changes in the data distribution. Instead of implementing checks and verification algorithms on your own, you can focus on describing how your data should look. Deequ supports you by suggesting checks for you. Deequ is implemented on top of Apache Spark and is designed to scale with large datasets (think billions of rows) that typically live in a distributed filesystem or a data warehouse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
