{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3148652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import (\n",
    "    Word2Vec\n",
    ")\n",
    "from gensim.models.word2vec import (\n",
    "    LineSentence    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723029e",
   "metadata": {},
   "source": [
    "# Train Word2Vec on PTB Dataset\n",
    "\n",
    "* [Penn Treebank Dataset](https://deepai.org/dataset/penn-treebank)\n",
    "\n",
    "> Penn Treebank (PTB) dataset, is widely used in machine learning for NLP (Natural Language Processing) research. Word-level PTB does not contain capital letters, numbers, and punctuations, and the vocabulary is capped at 10k unique words, which is relatively small in comparison to most modern datasets which can result in a larger number of out of vocabulary tokens.\n",
    "\n",
    "* https://raw.githubusercontent.com/tomsercu/lstm/master/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbcf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence(source=\"~/.keras/datasets/ptb.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3392e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    sg=0,\n",
    "    window=5, \n",
    "    negative=5,\n",
    "    vector_size=100, \n",
    "    min_count=1, \n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036e7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861854e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save(\"./model/gensim_w2v_vecsize_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7024eb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amount', 0.9150373935699463),\n",
       " ('debt', 0.8811702132225037),\n",
       " ('value', 0.8553045392036438),\n",
       " ('payment', 0.8456965088844299),\n",
       " ('denominations', 0.8313669562339783),\n",
       " ('dividend', 0.828631579875946),\n",
       " ('face', 0.8225265741348267),\n",
       " ('minimum', 0.8147336840629578),\n",
       " ('assets', 0.8144380450248718),\n",
       " ('dividends', 0.8115537762641907)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('cash', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e567685",
   "metadata": {},
   "source": [
    "# Use pre-trained Google News dataset model\n",
    "\n",
    "* [Word2Vec Demo](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#word2vec-demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a35bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb40dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7300517559051514),\n",
       " ('monarch', 0.645466148853302),\n",
       " ('princess', 0.6156251430511475)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king = wv['king']\n",
    "man = wv['man']\n",
    "woman = wv['woman']\n",
    "\n",
    "candidates: list = []\n",
    "for key, probability in wv.most_similar(king - man + woman):\n",
    "    if key.lower() not in [\"king\", \"man\", \"woman\"]:\n",
    "        candidates.append((key, probability))\n",
    "        \n",
    "candidates[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "733d4284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('juventus', 0.6757157444953918),\n",
       " ('juve', 0.6393407583236694),\n",
       " ('mancini', 0.6235371828079224)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spain = wv['spain']\n",
    "real_madrid = wv['real_madrid']\n",
    "italy = wv['italy']\n",
    "\n",
    "candidates: list = []\n",
    "for key, probability in wv.most_similar(real_madrid -spain + italy):\n",
    "    if key.lower() not in [\"spain\", \"real_madrid\", \"italy\"]:\n",
    "        candidates.append((key, probability))\n",
    "        \n",
    "candidates[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f3d7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
