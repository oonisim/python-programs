{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bVXqEoG5LkjJ"
      },
      "source": [
        "## Copy your notebook version\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Building-ML-Pipelines/building-machine-learning-pipelines/blob/master/chapters/adv_tfx/Custom_TFX_Components.ipynb)\n",
        "\n",
        "Bit.ly: https://bit.ly/custom_TFX_components\n",
        "\n",
        "Colab: https://colab.research.google.com/github/Building-ML-Pipelines/building-machine-learning-pipelines/blob/master/chapters/adv_tfx/Custom_TFX_Components.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NIkC2_9RxtTi"
      },
      "source": [
        "# Workshop - Developing TensorFlow Extended Components\n",
        "\n",
        "TLDR: TensorFlow Extended (TFX) allows data scientists to assemble production pipelines for model updates and then run the pipelines of a variety of orchestration tools.\n",
        "\n",
        "TFX provide basic components to ingest, validate and transform data, as well as for model training, tuning, validation and deployments. \n",
        "\n",
        "![TFX Pipeline](https://drive.google.com/uc?export=view&id=1yOPZTcIgF6arI7CLeWR1gTxrL1_MfQpL)\n",
        "\n",
        "Figure taken from \"Building Machine Learning Pipelines\", O'Reilly July 2020, Hapke, Nelson\n",
        "\n",
        "One of the strengths of TFX is the extensibility of the framework by building custom components.\n",
        "\n",
        "### Applications for custom components can:\n",
        "\n",
        "* Ingestion of user specific data (e.g. images or custom database tables)\n",
        "* Compiling specific pipeline reports\n",
        "* Communicating pipeline results (e.g. via Slack or MS Teams)\n",
        "* Generating additional pipeline artifacts, e.g. model and data cards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20edwgX_Q5Gl"
      },
      "source": [
        "## Workshop Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aj5qUAi-Q7q0"
      },
      "source": [
        "In this workshop, we'll introduce two ways of building your TFX components for your ML pipelines. In particular, we'll focus on:\n",
        "\n",
        "* Brief overview of TFX and pipelines\n",
        "* Presentation how to build a component from scratch\n",
        "* Workshop how to extend existing components \n",
        "\n",
        "In this workshop we are implementing a TFX component to ingest images directly into the ML pipeline and generate labels for each image instead of converting the images to TFRecord representations outside of the pipeline.\n",
        "\n",
        "What are the benefits of the implementation?\n",
        "\n",
        "* Conversion is tracked in the ML Metadata store\n",
        "* Component output can be cached\n",
        "* No \"glue code\" required to connect the images to the pipeline\n",
        "\n",
        "![TFX **Component**](https://drive.google.com/uc?export=view&id=1zyPDzXH7V-wY-AHcmOsUGpgkyPYYm2iG)\n",
        "\n",
        "Figure taken from \"Building Machine Learning Pipelines\", O'Reilly July 2020, Hapke, Nelson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K9-KiDB6QjZZ"
      },
      "source": [
        "## TFX - Quick Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qMRQ2TWuQpfj"
      },
      "source": [
        "TFX provides a variety of stand-alone tools and pipeline components.\n",
        "\n",
        "\n",
        "![TFX Components](https://drive.google.com/uc?export=view&id=15ftktZN2o1MBim4sN29GTRW3hoUWzwfR)\n",
        "Figure taken from \"Building Machine Learning Pipelines\", O'Reilly July 2020, Hapke, Nelson\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m5e76kJGQro4"
      },
      "source": [
        "## TFX Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xqeLOVLlQvsc"
      },
      "source": [
        "TFX components consists of 3 parts: \n",
        "\n",
        "*   Component driver\n",
        "*   Component executor\n",
        "*   Component publisher\n",
        "\n",
        "The driver and publisher communicate with the ML metadata store and they retrieve the ML artifacts. Components pass data references from component to component and not the actual data!\n",
        "\n",
        "The action happens in the component executor. More later about that ...\n",
        "\n",
        "![TFX **Component**](https://drive.google.com/uc?export=view&id=1TopCi6XjouwJyVho0PEDIZl9fvEOA1UB)\n",
        "\n",
        "## How can you implement custom components?\n",
        "\n",
        "### Python-implementation based components\n",
        "\n",
        "* Easiest way of building TFX components \n",
        "* Newly added `@component` decorator\n",
        "* Function defines the executor behavior of a component\n",
        "\n",
        "More info: https://github.com/tensorflow/tfx/blob/master/docs/guide/custom_function_component.md\n",
        "\n",
        "Example from the TFX docs\n",
        "\n",
        "```\n",
        "@component\n",
        "def MyValidationComponent(\n",
        "    model: InputArtifact[Model],\n",
        "    blessing: OutputArtifact[Model],\n",
        "    accuracy_threshold: Parameter[int] = 10,\n",
        "    ) -> OutputDict(accuracy=float):\n",
        "  '''My simple custom model validation component.'''\n",
        "\n",
        "  accuracy = evaluate_model(model)\n",
        "  if accuracy >= accuracy_threshold:\n",
        "    write_output_blessing(blessing)\n",
        "\n",
        "  return {\n",
        "    'accuracy': accuracy\n",
        "  }\n",
        "```\n",
        "\n",
        "### Container-based components\n",
        "\n",
        "* Language independent \n",
        "* Docker image required\n",
        "* Execute container via `create_container_component` with inputs, outputs and parameters defined\n",
        "* Great for including non-Python code in your pipeline\n",
        "\n",
        "More info: https://github.com/tensorflow/tfx/blob/master/docs/guide/container_component.md\n",
        "\n",
        "### Fully implemented components\n",
        "\n",
        "* Best for reusing existing components\n",
        "\n",
        "More details below ...\n",
        "\n",
        "\n",
        "\n",
        "## How to implement a component?\n",
        "\n",
        "![TFX **Component** Implementation Details](https://drive.google.com/uc?export=view&id=1nDYwHpNFyY3r2GrylD8qiuPE2xM60RHI)\n",
        "\n",
        "Figures taken from \"Building Machine Learning Pipelines\", O'Reilly July 2020, Hapke, Nelson\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A7bkQIAVQxH8"
      },
      "source": [
        "## Extending existing TFX components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u_JgTpdhQ0p4"
      },
      "source": [
        "![TFX **Component**](https://drive.google.com/uc?export=view&id=1Hg-iUp8UF5Jh3dpdL-htG-Cw5g7GKqF3)\n",
        "\n",
        "### Benefits\n",
        "\n",
        "* Less boiler plate code\n",
        "* Reuse of existing component drivers and publishers\n",
        "* Faster implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0oqVb65hJEF5"
      },
      "source": [
        "## Where to find more details?\n",
        "\n",
        "If you are interested in a detailed introduction to TensorFlow Extended and other TensorFlow libraries, check out:\n",
        "\n",
        "* [TensorFlow and TFX documentation](https://www.tensorflow.org/tfx)\n",
        "* O'Reilly publication on machine learning pipelines with TFX\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=17Rtpso9UrE6HmhxCmtyd0aETr3WKSZ0e\" width=\"450\">\n",
        "\n",
        "* [Amazon.com](https://www.amazon.com/dp/1492053198/)\n",
        "* [Powells.com](https://www.powells.com/book/building-machine-learning-pipelines-9781492053194)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PD0G9msgQ3XX"
      },
      "source": [
        "## Code Outline\n",
        "\n",
        "* Download example dataset\n",
        "* Install required Python packages\n",
        "* Restart notebook kernel\n",
        "* Import required packages & modules\n",
        "* Define helper functions\n",
        "* Walk through a component implementation from scratch\n",
        "* Implement a component by overwriting the component executor\n",
        "* Create a pipeline with the component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8rxGlI475jTh"
      },
      "source": [
        "## Download example dataset\n",
        "\n",
        "For this workshop we'll be using the public cats & dogs dataset created by Microsoft. The data set contains two folders: \"Dog\" and \"Cat\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-buPbpyo5lgm"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/PetImages/\n",
        "!rm *.zip\n",
        "\n",
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "!unzip -q -d /content/ /content/kagglecatsanddogs_3367a.zip\n",
        "\n",
        "!echo \"Count images\"\n",
        "!ls -U /content/PetImages/Cat | wc -l\n",
        "!ls -U /content/PetImages/Dog | wc -l\n",
        "\n",
        "!echo \"Reduce images for demo purposes\"\n",
        "!cd /content/PetImages/Cat && ls -U | head -12000 | xargs rm \n",
        "!cd /content/PetImages/Dog && ls -U | head -12000 | xargs rm \n",
        "\n",
        "!echo \"Count images after removal\"\n",
        "!ls -U /content/PetImages/Cat | wc -l\n",
        "!ls -U /content/PetImages/Dog | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSOJwdKVPuR7"
      },
      "source": [
        "## Install required Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e_HLg5-j5v29"
      },
      "outputs": [],
      "source": [
        "!pip install -qU tfx\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "79kKPWzKPzKe"
      },
      "source": [
        "## Restart notebook kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SVjaCJ6PP1lp"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hWVmbxJJI_M-"
      },
      "source": [
        "## Import required packages & modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fAlDXeya7f-a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "from typing import Any, Dict, List, Text\n",
        "\n",
        "import apache_beam as beam\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "from absl import logging\n",
        "from tfx import v1 as tfx\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uk30idMCd-Jh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%skip_for_export` not found.\n"
          ]
        }
      ],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zd9XyDkBQJBx"
      },
      "source": [
        "## Define helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jrKzooGT8Km0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%skip_for_export` not found.\n"
          ]
        }
      ],
      "source": [
        "%%skip_for_export\n",
        "%%writefile {\"helpers.py\"}\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
        "    if not isinstance(value, list):\n",
        "        value = [value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def get_label_from_filename(filename):\n",
        "    \"\"\" Function to set the label for each image. In our case, we'll use the file \n",
        "    path of a label indicator. Based on your initial data \n",
        "    Args:\n",
        "      filename: string, full file path\n",
        "    Returns:\n",
        "      int - label\n",
        "    Raises:\n",
        "      NotImplementedError if not label category was detected\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    lowered_filename = filename.lower()\n",
        "    if \"dog\" in lowered_filename:\n",
        "        label = 0\n",
        "    elif \"cat\" in lowered_filename:\n",
        "        label = 1\n",
        "    else:\n",
        "        raise NotImplementedError(\"Found unknown image\")\n",
        "    return label\n",
        "    \n",
        "\n",
        "def _convert_to_example(image_buffer, label):\n",
        "    \"\"\"Function to convert image byte strings and labels into tf.Example structures\n",
        "      Args:\n",
        "        image_buffer: byte string representing the image\n",
        "        label: int\n",
        "      Returns:\n",
        "        TFExample data structure containing the image (byte string) and the label (int encoded)\n",
        "    \"\"\"\n",
        "\n",
        "    example = tf.train.Example(\n",
        "        features=tf.train.Features(\n",
        "            feature={\n",
        "                'image/raw': _bytes_feature(image_buffer),\n",
        "                'label': _int64_feature(label)\n",
        "            }))\n",
        "    return example\n",
        "\n",
        "\n",
        "def get_image_data(filename):\n",
        "    \"\"\"Process a single image file.\n",
        "    Args:\n",
        "      filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
        "    Returns:\n",
        "      TFExample data structure containing the image (byte string) and the label (int encoded)\n",
        "    \"\"\"\n",
        "    label = get_label_from_filename(filename)\n",
        "    byte_content = tf.io.read_file(filename)\n",
        "    rs = _convert_to_example(byte_content.numpy(), label)\n",
        "    return rs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GWyopU1Q-5c2"
      },
      "source": [
        "## Walk through a component implementation from scratch\n",
        "\n",
        "![TFX **Component** Implementation Details](https://drive.google.com/uc?export=view&id=1nDYwHpNFyY3r2GrylD8qiuPE2xM60RHI)\n",
        "\n",
        "### Thinks to know:\n",
        "\n",
        "* Component channels: https://github.com/tensorflow/tfx/blob/master/tfx/types/channel.pystandard_artifacts.py\n",
        "* ChannelsParameters vs ExecutionParameters\n",
        "* TFX `standard_artifacts`: https://github.com/tensorflow/tfx/blob/master/tfx/types/standard_artifacts.py\n",
        "* TFX `base_driver.BaseDriver`: https://github.com/tensorflow/tfx/blob/master/tfx/components/base/base_driver.py\n",
        "\n",
        "## 4 Steps\n",
        "\n",
        "1. Define the component specifications\n",
        "2. Define the custom executor\n",
        "3. Define the custom driver\n",
        "4. Put the entire component together\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XHn3GHAm--B0"
      },
      "source": [
        "### Custom Component Specifications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LKjZ_QvArnl1"
      },
      "source": [
        "https://github.com/tensorflow/tfx/blob/master/tfx/types/standard_artifacts.py\n",
        "\n",
        "Difference between ChannelParameter and ExecutionParameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zmxjmr4p-1nW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%skip_for_export` not found.\n"
          ]
        }
      ],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "from tfx.types import standard_artifacts\n",
        "from tfx.types.component_spec import ChannelParameter\n",
        "from tfx.types.component_spec import ComponentSpec\n",
        "from tfx.types.component_spec import ExecutionParameter\n",
        "\n",
        "class CustomIngestionComponentSpec(ComponentSpec):\n",
        "    \"\"\"ComponentSpec for Custom Ingestion Component.\"\"\"\n",
        "    \n",
        "    PARAMETERS = {\n",
        "        'name': ExecutionParameter(type=Text),\n",
        "        'input_base': ExecutionParameter(type=Text),\n",
        "    }\n",
        "    INPUTS = {}\n",
        "    OUTPUTS = {\n",
        "        'examples': ChannelParameter(type=standard_artifacts.Examples),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yvpcpzhB_JO-"
      },
      "source": [
        "### Custom Component Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7FEMWVdP_GhR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%skip_for_export` not found.\n"
          ]
        }
      ],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from helpers import get_image_data\n",
        "from tfx.components.base import base_executor\n",
        "from tfx.types import standard_artifacts, artifact_utils\n",
        "\n",
        "\n",
        "class CustomIngestionExecutor(base_executor.BaseExecutor):\n",
        "    \"\"\"Executor for CustomIngestionComponent.\"\"\"\n",
        "\n",
        "    def Do(self, \n",
        "           input_dict: Dict[Text, List[standard_artifacts.Artifact]],\n",
        "           output_dict: Dict[Text, List[standard_artifacts.Artifact]],\n",
        "           exec_properties: Dict[Text, Any]) -> None:\n",
        "\n",
        "        input_base = exec_properties['input_base']\n",
        "        image_files = tf.io.gfile.listdir(input_base)\n",
        "        random.shuffle(image_files)\n",
        "\n",
        "        train_images, eval_images = image_files[100:], image_files[:100]\n",
        "        splits = [('train', train_images), ('eval', eval_images)]\n",
        "\n",
        "        examples_artifact = output_dict['examples'][0]\n",
        "        examples_artifact.split_names = artifact_utils.encode_split_names([\"train\", \"eval\"])\n",
        "\n",
        "        for split_name, images in splits:\n",
        "\n",
        "            output_dir = artifact_utils.get_split_uri(\n",
        "                output_dict['examples'], split_name)\n",
        "            \n",
        "            tf.io.gfile.mkdir(output_dir)\n",
        "            tfrecords_filename = os.path.join(output_dir, 'images.tfrecords')\n",
        "          \n",
        "            options = tf.io.TFRecordOptions(compression_type=None)\n",
        "            writer = tf.io.TFRecordWriter(tfrecords_filename, options=options)\n",
        "\n",
        "            for image_filename in images:\n",
        "                image_path = os.path.join(input_base, image_filename)\n",
        "                example = get_image_data(image_path)\n",
        "                writer.write(example.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6iKbYwCE_bZR"
      },
      "source": [
        "### Component Setup \n",
        "\n",
        "Putting all pieces together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qooyPE9X_agc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%skip_for_export` not found.\n"
          ]
        }
      ],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "from tfx.components.base import base_component, executor_spec\n",
        "from tfx.types import artifact_utils, channel_utils, channel\n",
        "\n",
        "\n",
        "\n",
        "class CustomIngestionComponent(base_component.BaseComponent):\n",
        "    \"\"\"CustomIngestion Component.\"\"\"\n",
        "    SPEC_CLASS = CustomIngestionComponentSpec\n",
        "    EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(CustomIngestionExecutor)\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_data: standard_artifacts.ExternalArtifact = None,\n",
        "                 output_data: channel.Channel = None,\n",
        "                 input_base: Text = None,\n",
        "                 name: Text = None):\n",
        "        \n",
        "      if not output_data:\n",
        "          examples_artifact = standard_artifacts.Examples()\n",
        "          output_data = channel_utils.as_channel([examples_artifact])\n",
        "      \n",
        "      spec = CustomIngestionComponentSpec(input_base=input_base,\n",
        "                                          examples=output_data, \n",
        "                                          name=name)\n",
        "      \n",
        "      super(CustomIngestionComponent, self).__init__(spec=spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hPsN9SQN_muf"
      },
      "source": [
        "## Basic Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MiPWvcY4_g_w"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "test_context = InteractiveContext()\n",
        "\n",
        "data_root = os.path.join(\"/content/\", 'PetImages', 'Dog')\n",
        "\n",
        "ingest_images = CustomIngestionComponent(\n",
        "    input_base=data_root, \n",
        "    name='ImageIngestionComponent'\n",
        ")\n",
        "test_context.run(ingest_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rUL5vJh0_uyl"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "statistics_gen = tfx.components.StatisticsGen(\n",
        "    examples=ingest_images.outputs['examples'])\n",
        "test_context.run(statistics_gen)\n",
        "\n",
        "test_context.show(statistics_gen.outputs['statistics'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Go6dW3AeQpM"
      },
      "source": [
        "## Implement a component by overwriting the component executor\n",
        "\n",
        "![TFX **Component**](https://drive.google.com/uc?export=view&id=1Hg-iUp8UF5Jh3dpdL-htG-Cw5g7GKqF3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IVtoSoBma8h"
      },
      "source": [
        "### Thinks to know:\n",
        "\n",
        "* Decorator `@beam.ptransform_fn`: https://github.com/apache/beam/blob/master/sdks/python/apache_beam/transforms/ptransform.py\n",
        "* `BaseExampleGenExecutor` class: https://github.com/tensorflow/tfx/blob/v0.22.1/tfx/components/example_gen/base_example_gen_executor.py#L90-L243"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mNVTLErTx7B9"
      },
      "outputs": [],
      "source": [
        "from helpers import get_image_data\n",
        "\n",
        "\n",
        "@beam.ptransform_fn \n",
        "def ImageToExample(\n",
        "      pipeline: beam.Pipeline,\n",
        "      input_dict: Dict[Text, List[types.Artifact]],\n",
        "      exec_properties: Dict[Text, Any],\n",
        "    ) -> beam.pvalue.PCollection:\n",
        "    \"\"\"Read jpeg files and transform to TF examples.\n",
        "\n",
        "    Note that each input split will be transformed by this function separately.\n",
        "\n",
        "    Args:\n",
        "        pipeline: beam pipeline.\n",
        "        input_dict: Input dict from input key to a list of Artifacts.\n",
        "          - input_base: input dir that contains the image data.\n",
        "        exec_properties: A dict of execution properties.\n",
        "\n",
        "    Returns:\n",
        "        PCollection of TF examples.\n",
        "    \"\"\"\n",
        "    image_pattern = os.path.join(input_dict['input_base'], exec_properties)\n",
        "    absl.logging.info(\n",
        "        'Processing input image data {} to TFExample.'.format(image_pattern))\n",
        "\n",
        "    image_files = tf.io.gfile.glob(image_pattern)\n",
        "    if not image_files:\n",
        "        raise RuntimeError(\n",
        "            'Split pattern {} does not match any files.'.format(image_pattern))\n",
        "\n",
        "    return (\n",
        "        pipeline\n",
        "        | beam.Create(image_files)\n",
        "        | 'ConvertImagesToBase64' >> beam.Map(lambda file: get_image_data(file))\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Kwk_iZXdyA8N"
      },
      "outputs": [],
      "source": [
        "from tfx.components.example_gen.base_example_gen_executor import BaseExampleGenExecutor\n",
        "\n",
        "\n",
        "class ImageExampleGenExecutor(BaseExampleGenExecutor):\n",
        "    \"\"\"TFX example gen executor for processing jpeg format.\n",
        "\n",
        "    Example usage:\n",
        "\n",
        "      from tfx.components.example_gen.component import FileBasedExampleGen\n",
        "\n",
        "\n",
        "      example_gen = FileBasedExampleGen(\n",
        "          input_base=\"/content/PetImages/\",\n",
        "          input_config=input_config,\n",
        "          output_config=output,\n",
        "          custom_executor_spec=executor_spec.ExecutorClassSpec(_Executor))\n",
        "    \"\"\"\n",
        "\n",
        "    def GetInputSourceToExamplePTransform(self) -> beam.PTransform:\n",
        "        \"\"\"Returns PTransform for image to TF examples.\"\"\"\n",
        "        return ImageToExample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bzWHV-LbesyZ"
      },
      "source": [
        "## Building your ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AlAmd4aSj03V"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "pipeline_name = \"dogs_cats_pipeline\"\n",
        "\n",
        "context = InteractiveContext(pipeline_name=pipeline_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hpUFbbLzyHpm"
      },
      "outputs": [],
      "source": [
        "from tfx.proto import example_gen_pb2\n",
        "from tfx.components.example_gen.component import FileBasedExampleGen\n",
        "\n",
        "\n",
        "input_config = example_gen_pb2.Input(splits=[\n",
        "    example_gen_pb2.Input.Split(name='images', pattern='*/*.jpg'),\n",
        "])\n",
        "\n",
        "output = example_gen_pb2.Output(\n",
        "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
        "                 example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=4),\n",
        "                 example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
        "             ]))\n",
        "\n",
        "\n",
        "example_gen = FileBasedExampleGen(\n",
        "    input_base=\"/content/PetImages/\",\n",
        "    input_config=input_config,\n",
        "    output_config=output,\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(ImageExampleGenExecutor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P4WKPHrCbzlT"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(example_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Z5acSHe-yQaa"
      },
      "outputs": [],
      "source": [
        "statistics_gen = tfx.components.StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cNNuYiKXbfnR"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_vg7UVCi8f9y"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.show(statistics_gen.outputs['statistics'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qsqm7TUsTrrJ"
      },
      "outputs": [],
      "source": [
        "schema_gen = tfx.components.SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O80haHARb-PE"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(schema_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VIbnThIOHsXM"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.show(schema_gen.outputs['schema'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sHear9cQU-yM"
      },
      "outputs": [],
      "source": [
        "example_validator = tfx.components.ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dV_I5At2cIjL"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(example_validator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6C19JFcpVNHJ"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "%%writefile constants.py\n",
        "\n",
        "from typing import Text\n",
        "\n",
        "def transformed_name(key: Text) -> Text:\n",
        "  \"\"\"Generate the name of the transformed feature from original name.\"\"\"\n",
        "  return key + '_xf'\n",
        "\n",
        "# Keys\n",
        "LABEL_KEY = 'label'\n",
        "INPUT_KEY = 'image/raw'\n",
        "\n",
        "# Feature keys\n",
        "RAW_FEATURE_KEYS = [INPUT_KEY]\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 160"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S3V04th4YEV1"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "%%writefile transform.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "import logging\n",
        "\n",
        "from typing import Union, Dict\n",
        "\n",
        "import constants\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def convert_image(raw_image: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "    if tf.io.is_jpeg(raw_image):\n",
        "        image = tf.io.decode_jpeg(raw_image, channels=3)\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image = (image / 127.5) - 1 \n",
        "        image = tf.image.resize(image, [constants.IMG_SIZE, constants.IMG_SIZE])\n",
        "    else:\n",
        "        image = tf.constant(np.zeros((constants.IMG_SIZE, constants.IMG_SIZE, 3)), tf.float32)\n",
        "    return image  \n",
        "\n",
        "def fill_in_missing(x: Union[tf.Tensor, tf.SparseTensor]) -> tf.Tensor:\n",
        "    \"\"\"Replace missing values in a SparseTensor.\n",
        "\n",
        "    Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "\n",
        "    Args:\n",
        "      x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "        in the second dimension.\n",
        "\n",
        "    Returns:\n",
        "      A rank 1 tensor where missing values of `x` have been filled in.\n",
        "    \"\"\"\n",
        "    if isinstance(x, tf.sparse.SparseTensor):\n",
        "        default_value = \"\" if x.dtype == tf.string else 0\n",
        "        x = tf.sparse.to_dense(\n",
        "            tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "            default_value,\n",
        "        )\n",
        "    return tf.squeeze(x, axis=1)\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs: Dict[str, Union[tf.Tensor, tf.SparseTensor]]) -> Dict[str, tf.Tensor]:\n",
        "    \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "    \"\"\"\n",
        "    outputs = {}\n",
        "\n",
        "    for key in constants.RAW_FEATURE_KEYS:\n",
        "        image = fill_in_missing(inputs[key])\n",
        "        outputs[constants.transformed_name(key)] = tf.map_fn(convert_image, image, dtype=tf.float32)\n",
        "  \n",
        "    outputs[constants.transformed_name(constants.LABEL_KEY)] = inputs[constants.LABEL_KEY]\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YnCPhVR6YZM8"
      },
      "outputs": [],
      "source": [
        "transform = tfx.components.Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(\"transform.py\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1oxli-mEcOrk"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-5xD809NYkVK"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "%%writefile {\"trainer.py\"}\n",
        "\n",
        "from typing import List, Text, Dict\n",
        "\n",
        "import os\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from datetime import datetime\n",
        "\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "\n",
        "import constants\n",
        "\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "    \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "  \n",
        "\n",
        "def _get_label_for_image(model, tf_transform_output):\n",
        "    \"\"\"Returns a function that parses a raw byte image and applies TFT.\"\"\"\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "      \n",
        "    @tf.function\n",
        "    def serve_images_fn(image_raw):\n",
        "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "\n",
        "        image_raw = tf.reshape(image_raw, [-1, 1])\n",
        "        parsed_features = {'image': image_raw}\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "        return model(transformed_features)\n",
        "\n",
        "    return serve_images_fn\n",
        "\n",
        "\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "    \"\"\"Returns a function that parses a serialized tf.Example and applies TFT.\"\"\"\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "        \n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "        feature_spec.pop(constants.LABEL_KEY)\n",
        "\n",
        "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "        return model(transformed_features)\n",
        "\n",
        "    return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[Text], \n",
        "              tf_transform_output: tft.TFTransformOutput, \n",
        "              batch_size: int = 32, \n",
        "              is_train: bool = False) -> tf.data.Dataset:\n",
        "    \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "    Args:\n",
        "      file_pattern: input tfrecord file pattern.\n",
        "      tf_transform_output: A TFTransformOutput.\n",
        "      batch_size: representing the number of consecutive elements of returned\n",
        "        dataset to combine in a single batch\n",
        "\n",
        "    Returns:\n",
        "      A dataset that contains (features, indices) tuple where features is a\n",
        "        dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "    \"\"\"\n",
        "    transformed_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transformed_feature_spec,\n",
        "        reader=_gzip_reader_fn,\n",
        "        label_key=constants.transformed_name(constants.LABEL_KEY))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_model() -> tf.keras.Model:\n",
        "    \"\"\"Creates a CNN Keras model based on transfer learning for classifying image data.\n",
        "\n",
        "    Returns:\n",
        "      A keras Model.\n",
        "    \"\"\"\n",
        "    img_shape = (constants.IMG_SIZE, constants.IMG_SIZE, 3)\n",
        "\n",
        "    # Create the base model from the pre-trained model MobileNet V2\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=img_shape,\n",
        "                                                    include_top=False,\n",
        "                                                    weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "    base_model.summary()\n",
        "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "      \n",
        "    output = tf.keras.layers.Dense(1)\n",
        "      \n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=img_shape, name=constants.transformed_name(constants.INPUT_KEY)),\n",
        "        base_model,\n",
        "        global_average_layer,\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        output\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.optimizers.RMSprop(lr=0.01),\n",
        "        loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "        metrics=[tf.metrics.BinaryAccuracy(name='accuracy')])\n",
        "    model.summary()\n",
        "      \n",
        "    return model\n",
        "\n",
        "\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "    \"\"\"Train the model based on given args.\n",
        "\n",
        "    Args:\n",
        "      fn_args: Holds args used to train the model as name/value pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "    train_dataset = _input_fn(fn_args.train_files, tf_transform_output,\n",
        "                              TRAIN_BATCH_SIZE, is_train = True)\n",
        "    eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output,\n",
        "                             EVAL_BATCH_SIZE)\n",
        "\n",
        "    model = get_model()\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=fn_args.train_steps,\n",
        "        validation_data=eval_dataset,\n",
        "        validation_steps=fn_args.eval_steps,\n",
        "    )\n",
        "\n",
        "    signatures = {\n",
        "        'serving_default':\n",
        "            _get_serve_tf_examples_fn(model,\n",
        "                                      tf_transform_output).get_concrete_function(\n",
        "                                          tf.TensorSpec(\n",
        "                                              shape=[None],\n",
        "                                              dtype=tf.string,\n",
        "                                              name='examples')),\n",
        "\n",
        "    }\n",
        "    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d9oWjqJ6eFyH"
      },
      "outputs": [],
      "source": [
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "trainer = tfx.components.Trainer(\n",
        "    module_file=os.path.abspath(\"trainer.py\"),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=160),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pVkNAMGlc5n1"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sJgCzXERexin"
      },
      "outputs": [],
      "source": [
        "model_resolver = tfx.dsl.Resolver(\n",
        "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
        "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
        "      model_blessing=tfx.dsl.Channel(type=tfx.types.standard_artifacts.ModelBlessing),\n",
        ")\n",
        "context.run(model_resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W3dEs7shc91f"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(model_resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Eo0OFYFnqfLM"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        tfma.ModelSpec(label_key='label')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='AUC'),\n",
        "            ]\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        tfma.SlicingSpec()\n",
        "    ])\n",
        "\n",
        "evaluator = tfx.components.Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    eval_config=eval_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W3q2vnLldB0h"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BEIC8jk_q5wB"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.show(evaluator.outputs['evaluation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jKUercE3rcJ8"
      },
      "outputs": [],
      "source": [
        "from tfx.proto import pusher_pb2\n",
        "\n",
        "_serving_model_dir = \"/content/exported_model\"\n",
        "\n",
        "pusher = tfx.components.Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3EH5qXOQdHrg"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "context.run(pusher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sqIUuLXwsiwG"
      },
      "outputs": [],
      "source": [
        "!ls /tmp/tfx-dogs_cats_pipeline-5n22n4m3/Pusher/pushed_model/9 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sDE7dW57dM3t"
      },
      "source": [
        "---\n",
        "## Export Pipeline to use with Apache Beam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O_J4jJwB5QD4"
      },
      "outputs": [],
      "source": [
        "components = [\n",
        "    example_gen,\n",
        "    statistics_gen,\n",
        "    schema_gen,\n",
        "    example_validator,\n",
        "    transform,\n",
        "    trainer,\n",
        "    model_resolver,\n",
        "    evaluator,\n",
        "    pusher,\n",
        "]\n",
        "\n",
        "_pipeline_name = \"dogs_cats_pipeline\"\n",
        "\n",
        "# pipeline inputs\n",
        "_base_dir = os.getcwd()\n",
        "_pipeline_dir = os.path.join(_base_dir, \"pipeline\")\n",
        "\n",
        "# pipeline outputs\n",
        "_output_base = os.path.join(_pipeline_dir, \"output\", _pipeline_name)\n",
        "_pipeline_root = os.path.join(_output_base, \"pipeline_root\")\n",
        "_metadata_path = os.path.join(_pipeline_root, \"metadata.sqlite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zNkVYvh_e0P8"
      },
      "outputs": [],
      "source": [
        " %%skip_for_export\n",
        "\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RnGmm3_NdS_W"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "notebook_filepath = (\n",
        "    '/content/drive/My Drive/Colab Notebooks/Beam Summit Workshop - Creating Custom TFX Components.ipynb')\n",
        "pipeline_export_filepath = 'exported_pipeline_{}.py'.format(pipeline_name)\n",
        "\n",
        "context.export_to_pipeline(notebook_filepath=notebook_filepath,\n",
        "                           export_filepath=pipeline_export_filepath,\n",
        "                           runner_type=\"beam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "T8E3tRvcmi8E"
      },
      "outputs": [],
      "source": [
        "%%skip_for_export\n",
        "\n",
        "!python3 {pipeline_export_filepath}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Beam Summit Workshop - Creating Custom TFX Components.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
