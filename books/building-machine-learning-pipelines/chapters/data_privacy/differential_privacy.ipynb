{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of complaints_model_dp_20Apr.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke3Z3T-DPLMu",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 14: Data Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94oXR---PLMv",
        "colab_type": "text"
      },
      "source": [
        "### NOTE as of September 2020, tf-privacy relies on the updated Keras optimizer which will be part of the TensorFlow 2.4 release\n",
        "\n",
        "Until the release of a stable 2.4 version, this notebook requires the TensorFlow's nightly builds. Due to the unstable nature of the nightly builds, this notebook might fail intermittently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5GVnk0RPLMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "outputId": "bf7cb24f-c6fd-41ee-e598-b314c3c3ffdd"
      },
      "source": [
        "!pip install tensorflow_privacy\n",
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_privacy in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow_privacy) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from tensorflow_privacy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.17->tensorflow_privacy) (1.18.5)\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2f/410f5153862dc461c8c1d1bafc0be6e5942eafaffc1764e71ce284b4034e/tf_nightly-2.4.0.dev20200909-cp36-cp36m-manylinux2010_x86_64.whl (389.9MB)\n",
            "\u001b[K     |████████████████████████████████| 389.9MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Collecting tb-nightly<3.0.0a0,>=2.4.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/8f/8195d11bc8e6e1945fab68f85ced31f8ff60f88d856867dd310c31b34c22/tb_nightly-2.4.0a20200909-py3-none-any.whl (9.2MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 51.0MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/4c/b8c1af2d1a2a8e0ca7b07287e2be948addf7e3884d022e62e37e72232dea/tf_estimator_nightly-2.4.0.dev2020090901-py2.py3-none-any.whl (460kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 57.1MB/s \n",
            "\u001b[?25hCollecting flatbuffers>=1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.31.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (49.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.8)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, flatbuffers, tf-nightly\n",
            "Successfully installed flatbuffers-1.12 tb-nightly-2.4.0a20200909 tf-estimator-nightly-2.4.0.dev2020090901 tf-nightly-2.4.0.dev20200909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4N10jj3R47Sj",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvieVVCNPLM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6682e680-6222-4bb2-93bf-f3fe19546f76"
      },
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "repo_dir = Path.cwd().parents[1]\n",
        "data_file_path = os.path.join(repo_dir, 'data/consumer_complaints_with_narrative.csv')\n",
        "print(data_file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/reduced_consumer_complaints_with_narrative.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pakq9qGqQXdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e6c2168-683d-4884-bc05-89db9a4a863e"
      },
      "source": [
        "!ls /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep69FHWVPLM3",
        "colab_type": "text"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5lDj1OJCWfTy",
        "colab": {}
      },
      "source": [
        "ONE_HOT_FEATURES = {\n",
        "    \"product\": None,\n",
        "    \"sub_product\": None,\n",
        "    \"company_response\": None, \n",
        "    \"state\": None,\n",
        "    \"issue\": None\n",
        "}\n",
        "\n",
        "# feature name, bucket count\n",
        "BUCKET_FEATURES = {\n",
        "    \"zip_code\": 10\n",
        "}\n",
        "\n",
        "# feature name, value is unused\n",
        "TEXT_FEATURES = {\n",
        "    \"consumer_complaint_narrative\": None\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3o-EurrDk7Fi",
        "colab": {}
      },
      "source": [
        "feature_names = [\"product\", \"sub_product\", \"issue\", \"sub_issue\", \"consumer_complaint_narrative\", \"company\", \"state\", \"zip_code\", \"company_response\", \"timely_response\", \"consumer_disputed\"]\n",
        "df = pd.read_csv(data_file_path, usecols=feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nH5SAgmOOL6K",
        "colab": {}
      },
      "source": [
        "def make_one_hot(df):\n",
        "    one_hot_array = []\n",
        "    for feature_name in ONE_HOT_FEATURES.keys():\n",
        "        temp_array = pd.np.asarray(tf.keras.utils.to_categorical(df[feature_name].values))\n",
        "        ONE_HOT_FEATURES[feature_name] = temp_array.shape[1]\n",
        "        one_hot_array.append(temp_array)\n",
        "\n",
        "    return one_hot_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jxbSJIw3lDOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "a889dfe6-98f5-4d6e-823f-08aef87b3ec2"
      },
      "source": [
        "for feature in ONE_HOT_FEATURES.keys():\n",
        "    df[feature] = df[feature].astype(\"category\").cat.codes\n",
        "\n",
        "one_hot_x = make_one_hot(df)\n",
        "\n",
        "embedding_x = [pd.np.asarray(df[feature_name].values).reshape(-1) for feature_name in TEXT_FEATURES.keys()]\n",
        "\n",
        "df['zip_code'] = df['zip_code'].str.replace('X', '0', regex=True)\n",
        "df['zip_code'] = df['zip_code'].str.replace(r'\\[|\\*|\\+|\\-|`|\\.|\\ |\\$|\\/|!|\\(', '0', regex=True)\n",
        "df['zip_code'] = df['zip_code'].fillna(0)\n",
        "df['zip_code'] = df['zip_code'].astype('int32')\n",
        "# one bucket per 10k\n",
        "df['zip_code'] = df['zip_code'].apply(lambda x: x//10000)\n",
        "numeric_x = [df['zip_code'].values]\n",
        "\n",
        "X = one_hot_x + numeric_x + embedding_x\n",
        "y = np.asarray(df[\"consumer_disputed\"], dtype=np.uint8).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9Eo3zrCVRPm"
      },
      "source": [
        "## Adding DP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yto8Cmn7VErQ",
        "colab": {}
      },
      "source": [
        "# DP parameters\n",
        "NOISE_MULTIPLIER = 1.1\n",
        "NUM_MICROBATCHES = 32\n",
        "LEARNING_RATE = 0.1\n",
        "POPULATION_SIZE = 1000\n",
        "L2_NORM_CLIP = 1.0\n",
        "BATCH_SIZE = 32 \n",
        "EPOCHS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u0JJ_EnmVTk6",
        "colab": {}
      },
      "source": [
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n",
        "\n",
        "optimizer = DPGradientDescentGaussianOptimizer(\n",
        "    l2_norm_clip=L2_NORM_CLIP,\n",
        "    noise_multiplier=NOISE_MULTIPLIER,\n",
        "    num_microbatches=NUM_MICROBATCHES,\n",
        "    learning_rate=LEARNING_RATE)\n",
        "    \n",
        "loss = tf.keras.losses.BinaryCrossentropy(\n",
        "        from_logits=True, reduction=tf.losses.Reduction.NONE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoQHOGsh5Anr"
      },
      "source": [
        "The model is unchanged, we just pass in the differentially private optimizer and loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZ7Z1LHd4-kb",
        "colab": {}
      },
      "source": [
        "def transformed_name(key):\n",
        "    return key + '_xf'\n",
        "\n",
        "def get_model(dp_optimizer, dp_loss, show_summary=True):\n",
        "    \"\"\"\n",
        "    This function defines a Keras model and returns the model as a Keras object.\n",
        "    \"\"\"\n",
        "    \n",
        "    # one-hot categorical features\n",
        "    input_features = []\n",
        "    for key, dim in ONE_HOT_FEATURES.items():\n",
        "        input_features.append(tf.keras.Input(shape=(dim), name=transformed_name(key)))\n",
        "\n",
        "    # adding bucketized features \n",
        "    for key, dim in BUCKET_FEATURES.items():\n",
        "        input_features.append(tf.keras.Input(1, name=transformed_name(key)))\n",
        "\n",
        "    # adding text input features\n",
        "    input_texts = []\n",
        "    for key in TEXT_FEATURES.keys():\n",
        "        input_texts.append(tf.keras.Input(shape=(1,), name=transformed_name(key), dtype=tf.string))\n",
        "\n",
        "    # embed text features\n",
        "    MODULE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "    embed = hub.KerasLayer(MODULE_URL)\n",
        "    reshaped_narrative = tf.reshape(input_texts[0], [-1])\n",
        "    embed_narrative = embed(reshaped_narrative) \n",
        "    deep_ff = tf.keras.layers.Reshape((512, ), input_shape=(1, 512))(embed_narrative)\n",
        "    \n",
        "    deep = tf.keras.layers.Dense(256, activation='relu')(deep_ff)\n",
        "    deep = tf.keras.layers.Dense(64, activation='relu')(deep)\n",
        "    deep = tf.keras.layers.Dense(16, activation='relu')(deep)\n",
        "\n",
        "    wide_ff = tf.keras.layers.concatenate(input_features)\n",
        "    wide = tf.keras.layers.Dense(16, activation='relu')(wide_ff)\n",
        "\n",
        "    both = tf.keras.layers.concatenate([deep, wide])\n",
        "\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(both) \n",
        "\n",
        "    inputs = input_features + input_texts\n",
        "\n",
        "    keras_model = tf.keras.models.Model(inputs, output)\n",
        "    keras_model.compile(optimizer=dp_optimizer,\n",
        "                        loss=dp_loss,  \n",
        "                        metrics=[\n",
        "                            tf.keras.metrics.BinaryAccuracy(),\n",
        "                            tf.keras.metrics.TruePositives()\n",
        "                        ])\n",
        "    if show_summary:\n",
        "        keras_model.summary()\n",
        "\n",
        "    return keras_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y4TTGI9glD_M",
        "colab": {}
      },
      "source": [
        "model = get_model(show_summary=False, dp_optimizer=optimizer, dp_loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yAmaGolZl4cX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f5161960-ada8-4717-bf8d-cfa0551ad358"
      },
      "source": [
        "model.fit(x=X, y=y, batch_size=32, validation_split=0.1, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 [==============================] - 4s 67ms/step - loss: 0.7254 - binary_accuracy: 0.7596 - true_positives: 0.0000e+00 - val_loss: 0.6942 - val_binary_accuracy: 0.7400 - val_true_positives: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbb85c9ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1gtS5tFfZau"
      },
      "source": [
        "### Calculate Epsilon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q6u5MIUkMrpS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "68bf00b6-1bbc-4529-82a9-50479772522c"
      },
      "source": [
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "\n",
        "\n",
        "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=POPULATION_SIZE, \n",
        "                                              batch_size=BATCH_SIZE, \n",
        "                                              noise_multiplier=NOISE_MULTIPLIER, \n",
        "                                              epochs=EPOCHS, \n",
        "                                              delta=1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DP-SGD with sampling rate = 3.2% and noise_multiplier = 1.1 iterated over 32 steps satisfies differential privacy with eps = 1.38 and delta = 0.001.\n",
            "The optimal RDP order is 7.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3845887532963042, 7.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gBzK9bK1gBab",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}