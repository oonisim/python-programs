{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "\n",
    "## About the Data\n",
    "In this notebook, we will be working with two data sources: \n",
    "- 2018 stock data for Facebook, Apple, Amazon, Netflix, and Google (obtained using the [`stock_analysis`](https://github.com/stefmolin/stock-analysis) package)\n",
    "- European Centre for Disease Prevention and Control's (ECDC) [daily number of new reported cases of COVID-19 by country worldwide dataset](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide) collected on September 19, 2020 via [this link](https://opendata.ecdc.europa.eu/covid19/casedistribution/csv)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "We want to look at data for the FAANG stocks (Facebook, Apple, Amazon, Netflix, and Google), but we were given each as a separate CSV file. Make them into a single file and store the dataframe of the FAANG data as `faang`:\n",
    "1. Read each file in.\n",
    "2. Add a column to each dataframe indicating the ticker it is for.\n",
    "3. Append them together into a single dataframe.\n",
    "4. Save the result to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.DataFrame()\n",
    "for ticker in ['fb', 'aapl', 'amzn', 'nflx', 'goog']:\n",
    "    df = pd.read_csv(f'../../ch_03/exercises/{ticker}.csv')\n",
    "    # make the ticker the first column\n",
    "    df.insert(0, 'ticker', ticker.upper())\n",
    "    faang = faang.append(df)\n",
    "\n",
    "faang.to_csv('faang.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "With `faang`, use type conversion to change the `date` column to datetime and the `volume` column to integers. Then, sort by `date` and `ticker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>102223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1170.510010</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>1189.010010</td>\n",
       "      <td>2694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>181.580002</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>177.679993</td>\n",
       "      <td>181.419998</td>\n",
       "      <td>18151900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1066.939941</td>\n",
       "      <td>1045.229980</td>\n",
       "      <td>1048.339966</td>\n",
       "      <td>1065.000000</td>\n",
       "      <td>1237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>201.649994</td>\n",
       "      <td>195.419998</td>\n",
       "      <td>196.100006</td>\n",
       "      <td>201.070007</td>\n",
       "      <td>10966900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date         high          low         open        close  \\\n",
       "0   AAPL 2018-01-02    43.075001    42.314999    42.540001    43.064999   \n",
       "0   AMZN 2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   \n",
       "0     FB 2018-01-02   181.580002   177.550003   177.679993   181.419998   \n",
       "0   GOOG 2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000   \n",
       "0   NFLX 2018-01-02   201.649994   195.419998   196.100006   201.070007   \n",
       "\n",
       "      volume  \n",
       "0  102223600  \n",
       "0    2694500  \n",
       "0   18151900  \n",
       "0    1237600  \n",
       "0   10966900  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang = faang.assign(\n",
    "    date=lambda x: pd.to_datetime(x.date),\n",
    "    volume=lambda x: x.volume.astype(int)\n",
    ").sort_values(\n",
    "    ['date', 'ticker']\n",
    ")\n",
    "\n",
    "faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Find the 7 rows with the lowest value for `volume`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1100.020020</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1102.890015</td>\n",
       "      <td>679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1037.589966</td>\n",
       "      <td>1022.398987</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1023.880005</td>\n",
       "      <td>691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>1080.469971</td>\n",
       "      <td>1066.150024</td>\n",
       "      <td>1079.000000</td>\n",
       "      <td>1079.239990</td>\n",
       "      <td>766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>1159.589966</td>\n",
       "      <td>1149.589966</td>\n",
       "      <td>1156.979980</td>\n",
       "      <td>1152.839966</td>\n",
       "      <td>798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>1255.541992</td>\n",
       "      <td>1246.010010</td>\n",
       "      <td>1249.900024</td>\n",
       "      <td>1249.099976</td>\n",
       "      <td>848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1194.625977</td>\n",
       "      <td>1205.020020</td>\n",
       "      <td>1207.770020</td>\n",
       "      <td>870800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>1211.839966</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1207.329956</td>\n",
       "      <td>887400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker       date         high          low         open        close  \\\n",
       "126   GOOG 2018-07-03  1135.819946  1100.020020  1135.819946  1102.890015   \n",
       "226   GOOG 2018-11-23  1037.589966  1022.398987  1030.000000  1023.880005   \n",
       "99    GOOG 2018-05-24  1080.469971  1066.150024  1079.000000  1079.239990   \n",
       "130   GOOG 2018-07-10  1159.589966  1149.589966  1156.979980  1152.839966   \n",
       "152   GOOG 2018-08-09  1255.541992  1246.010010  1249.900024  1249.099976   \n",
       "159   GOOG 2018-08-20  1211.000000  1194.625977  1205.020020  1207.770020   \n",
       "161   GOOG 2018-08-22  1211.839966  1199.000000  1200.000000  1207.329956   \n",
       "\n",
       "     volume  \n",
       "126  679000  \n",
       "226  691500  \n",
       "99   766800  \n",
       "130  798400  \n",
       "152  848600  \n",
       "159  870800  \n",
       "161  887400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang.nsmallest(7, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Right now, the data is somewhere between long and wide format. Use `melt()` to make it completely long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>42.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>1172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>177.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>1048.339966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>196.100006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date variable        value\n",
       "0   AAPL 2018-01-02     open    42.540001\n",
       "1   AMZN 2018-01-02     open  1172.000000\n",
       "2     FB 2018-01-02     open   177.679993\n",
       "3   GOOG 2018-01-02     open  1048.339966\n",
       "4   NFLX 2018-01-02     open   196.100006"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_faang = faang.melt(\n",
    "    id_vars=['ticker', 'date'], \n",
    "    value_vars=['open', 'high', 'low', 'close', 'volume']\n",
    ")\n",
    "melted_faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Suppose we found out there was a glitch in how the data was recorded on July 26, 2018. How should we handle this?\n",
    "\n",
    "> Given that this is a large data set (~ 1 year), we would be tempted to just drop that date and interpolate. However, some preliminary research on that date for the FAANG stocks reveals that FB took a huge tumble that day. If we had interpolated, we would have missed the magnitude of the drop.\n",
    "\n",
    "## Exercise 6\n",
    "The European Centre for Disease Prevention and Control (ECDC) provides an open dataset on COVID-19 cases called, [*daily number of new reported cases of COVID-19 by country worldwide*](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide). This dataset is updated daily, but we will use a snapshot that contains data from January 1, 2020 through September 18, 2020. Clean and pivot the data so that it is in wide format:\n",
    "\n",
    "1. Read in the `covid19_cases.csv` file.\n",
    "2. Create a `date` column using the data in the `dateRep` column and the `pd.to_datetime()` function.\n",
    "3. Set the `date` column as the index and sort the index.\n",
    "4. Replace occurrences of `United_States_of_America` and `United_Kingdom` with `USA` and `UK`, respectively.\n",
    "5. Using the `countriesAndTerritories` column, filter the data down to Argentina, Brazil, China, Colombia, India, Italy, Mexico, Peru, Russia, Spain, Turkey, the UK, and the USA.\n",
    "6. Pivot the data so that the index contains the dates, the columns contain the country names, and the values are the case counts in the `cases` column. Be sure to fill in `NaN` values with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>China</th>\n",
       "      <th>Colombia</th>\n",
       "      <th>India</th>\n",
       "      <th>Italy</th>\n",
       "      <th>Mexico</th>\n",
       "      <th>Peru</th>\n",
       "      <th>Russia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Turkey</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>10778.0</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7355.0</td>\n",
       "      <td>92071.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>4408.0</td>\n",
       "      <td>6787.0</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>27404.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>33871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>9056.0</td>\n",
       "      <td>15155.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>83809.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>4241.0</td>\n",
       "      <td>5509.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>34841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>9908.0</td>\n",
       "      <td>36653.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6698.0</td>\n",
       "      <td>90123.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>11193.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>51473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-17</th>\n",
       "      <td>11893.0</td>\n",
       "      <td>36820.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7787.0</td>\n",
       "      <td>97894.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>11291.0</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>24598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-18</th>\n",
       "      <td>11674.0</td>\n",
       "      <td>36303.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7568.0</td>\n",
       "      <td>96424.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>5698.0</td>\n",
       "      <td>5762.0</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>3395.0</td>\n",
       "      <td>43567.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "countriesAndTerritories  Argentina   Brazil  China  Colombia    India   Italy  \\\n",
       "date                                                                            \n",
       "2020-01-01                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
       "2020-01-02                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
       "2020-01-03                     0.0      0.0   17.0       0.0      0.0     0.0   \n",
       "2020-01-04                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
       "2020-01-05                     0.0      0.0   15.0       0.0      0.0     0.0   \n",
       "...                            ...      ...    ...       ...      ...     ...   \n",
       "2020-09-14                 10778.0  14768.0   29.0    7355.0  92071.0  1456.0   \n",
       "2020-09-15                  9056.0  15155.0   22.0    5573.0  83809.0  1008.0   \n",
       "2020-09-16                  9908.0  36653.0   24.0    6698.0  90123.0  1229.0   \n",
       "2020-09-17                 11893.0  36820.0    7.0    7787.0  97894.0  1452.0   \n",
       "2020-09-18                 11674.0  36303.0   44.0    7568.0  96424.0  1583.0   \n",
       "\n",
       "countriesAndTerritories  Mexico    Peru  Russia    Spain  Turkey      UK  \\\n",
       "date                                                                       \n",
       "2020-01-01                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-02                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-03                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-04                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-05                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "...                         ...     ...     ...      ...     ...     ...   \n",
       "2020-09-14               4408.0  6787.0  5449.0  27404.0  1527.0  3330.0   \n",
       "2020-09-15               3335.0  4241.0  5509.0   9437.0  1716.0  2621.0   \n",
       "2020-09-16               4771.0  4160.0  5529.0  11193.0  1742.0  3103.0   \n",
       "2020-09-17               4444.0  6380.0  5670.0  11291.0  1771.0  3991.0   \n",
       "2020-09-18               3182.0  5698.0  5762.0  14389.0  1648.0  3395.0   \n",
       "\n",
       "countriesAndTerritories      USA  \n",
       "date                              \n",
       "2020-01-01                   0.0  \n",
       "2020-01-02                   0.0  \n",
       "2020-01-03                   0.0  \n",
       "2020-01-04                   0.0  \n",
       "2020-01-05                   0.0  \n",
       "...                          ...  \n",
       "2020-09-14               33871.0  \n",
       "2020-09-15               34841.0  \n",
       "2020-09-16               51473.0  \n",
       "2020-09-17               24598.0  \n",
       "2020-09-18               43567.0  \n",
       "\n",
       "[262 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid = pd.read_csv('../../ch_03/exercises/covid19_cases.csv').assign(\n",
    "    date=lambda x: pd.to_datetime(x.dateRep, format='%d/%m/%Y')\n",
    ").set_index('date').replace(\n",
    "    'United_States_of_America', 'USA'\n",
    ").replace('United_Kingdom', 'UK').sort_index()\n",
    "\n",
    "covid[\n",
    "    covid.countriesAndTerritories.isin([\n",
    "        'Argentina', 'Brazil', 'China', 'Colombia', 'India', 'Italy', \n",
    "        'Mexico', 'Peru', 'Russia', 'Spain', 'Turkey', 'UK', 'USA'\n",
    "    ])\n",
    "].reset_index().pivot(index='date', columns='countriesAndTerritories', values='cases').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "In order to determine the case totals per country efficiently, we need the aggregation skills we will learn in *Chapter 4, Aggregating DataFrames*, so the ECDC data in the `covid19_cases.csv` file has been aggregated for us and saved in the `covid19_total_cases.csv` file. It contains the total number of case per country. Use this data to find the 20 countries with the largest COVID-19 case totals. Hints:\n",
    "\n",
    "- When reading in the CSV file, pass in `index_col='cases'`.\n",
    "- Note that it will be helpful to transpose the data before isolating the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>6724667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>5308014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>4495183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>1091186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>756412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>750471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>688954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South_Africa</th>\n",
       "      <td>657627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>640040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>442827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>428696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iran</th>\n",
       "      <td>416198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>345805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saudi_Arabia</th>\n",
       "      <td>328720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>311690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pakistan</th>\n",
       "      <td>305031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>299810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>294932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "index           cases\n",
       "USA           6724667\n",
       "India         5308014\n",
       "Brazil        4495183\n",
       "Russia        1091186\n",
       "Peru           756412\n",
       "Colombia       750471\n",
       "Mexico         688954\n",
       "South_Africa   657627\n",
       "Spain          640040\n",
       "Argentina      601700\n",
       "Chile          442827\n",
       "France         428696\n",
       "Iran           416198\n",
       "UK             385936\n",
       "Bangladesh     345805\n",
       "Saudi_Arabia   328720\n",
       "Iraq           311690\n",
       "Pakistan       305031\n",
       "Turkey         299810\n",
       "Italy          294932"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../../ch_03/exercises/covid19_total_cases.csv', index_col='index')\\\n",
    "    .T.nlargest(20, 'cases').sort_values('cases', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div>\n",
    "    <a href=\"../../ch_03/5-handling_data_issues.ipynb\">\n",
    "        <button>&#8592; Chapter 3</button>\n",
    "    </a>\n",
    "    <a href=\"../../ch_04/1-querying_and_merging.ipynb\">\n",
    "        <button style=\"float: right;\">Chapter 4 &#8594;</button>\n",
    "    </a>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
