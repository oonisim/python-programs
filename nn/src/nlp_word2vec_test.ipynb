{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from itertools import islice\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook setups\n",
    "\n",
    "Auto reolaod causes an error in Jupyter notebooks. Restart the Jupyter kernel for the error:\n",
    "```TypeError: super(type, obj): obj must be an instance or subtype of type```\n",
    "See\n",
    "- https://stackoverflow.com/a/52927102/4281353\n",
    "- http://thomas-cokelaer.info/blog/2011/09/382/\n",
    "\n",
    "> The problem resides in the mechanism of reloading modules.\n",
    "> Reloading a module often changes the internal object in memory which\n",
    "> makes the isinstance test of super return False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "import function.fileio as fileio\n",
    "import function.text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.constant import (\n",
    "    TYPE_INT,\n",
    "    TYPE_FLOAT,\n",
    "    TYPE_LABEL,\n",
    "    TYPE_TENSOR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TEXT8 = True\n",
    "USE_PTB = not USE_TEXT8\n",
    "USE_CBOW = False\n",
    "USE_SGRAM = not USE_CBOW\n",
    "\n",
    "CORPUS_FILE = \"text8_512\" if USE_TEXT8 else \"ptb_train\"\n",
    "CORPUS_URL = \"https://data.deepai.org/text8.zip\" \\\n",
    "    if USE_TEXT8 else f'https://raw.githubusercontent.com/tomsercu/lstm/master/data/ptb.train.txt'\n",
    "\n",
    "TARGET_SIZE = 1   # Size of the target event (word)\n",
    "CONTEXT_SIZE = 10  # Size of the context.\n",
    "WINDOW_SIZE = TARGET_SIZE + CONTEXT_SIZE\n",
    "SAMPLE_SIZE = 5   # Size of the negative samples\n",
    "VECTOR_SIZE = 100  # Number of features in the event vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_FILE_PTB_C10_S5_WND_V100_LR5 = \"../models/word2vec_sgram_ptb_train_E1_C10_S5_Wnormal_std_0.01_V100_LR5.0_N10.pkl\"\n",
    "STATE_FILE_PTB_C10_S5_WND_V100_LR20 = \"../models/word2vec_sgram_ptb_train_E1_C10_S5_Wnormal_std_0.01_V100_LR20.0_N10.pkl\"\n",
    "STATE_FILE_TEXT8_C10_S5_WND_v100_LR20 =\"../models/word2vec_sgram_text8_512_E1_C10_S5_Wnormal_std_0.01_V100_LR20.0_N1.pkl\"\n",
    "STATE_FILE_TEXT8_C6_S6_WND_V100_LR20 = \"../models/word2vec_sgram_text8_512_E1_C6_S6_Wnormal_std_0.01_V100_LR20.0_N1.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oonisim/.keras/datasets/text8_512\n"
     ]
    }
   ],
   "source": [
    "path_to_corpus = f\"~/.keras/datasets/{CORPUS_FILE}\"\n",
    "if fileio.Function.is_file(path_to_corpus):\n",
    "    pass\n",
    "else:\n",
    "    # text8, run \"cat text8 | xargs -n 512 > text8_512\" after download\n",
    "    path_to_corpus = tf.keras.utils.get_file(\n",
    "        fname=CORPUS_FILE,\n",
    "        origin=CORPUS_URL,\n",
    "        extract=True\n",
    "    )\n",
    "corpus = fileio.Function.read_file(path_to_corpus)\n",
    "print(path_to_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society in place of what are regarded as authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic zeno of citium according to kropotkin zeno repudiated the omnipotence of the state its intervention and regimentation and proclaimed the sovereignty of the moral law of the individual the anabaptists of one six th century europe are sometimes considered to be religious forerunners of modern anarchism bertrand russell in his history of western philosophy writes that the anabaptists repudiated all law since they held that the good man will be guided at every moment by the holy spirit from this premise they arrive at communism the diggers or true levellers were an early communistic movement during the time of the english civil war and are considered by some as forerunners of modern anarchism in the modern era the first to use the term to mean something other than chaos was louis armand baron de lahontan in his nouveaux voyages dans l am rique septentrionale one seven zero three where he described the indigenous american society which had no state laws prisons priests or private property as being in anarchy russell means a libertarian and leader in the american indian movement has repeatedly stated that he is an anarchist and so are all his ancestors in one seven nine three in the thick of the french revolution william godwin published an enquiry\n"
     ]
    }
   ],
   "source": [
    "examples = corpus.split('\\n')[:1]\n",
    "for line in examples:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Event (word) indexing\n",
    "Index the events that have occurred in the event sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from layer.preprocessing import (\n",
    "    EventIndexing, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexing = EventIndexing(\n",
    "    name=\"word_indexing_on_ptb\",\n",
    "    corpus=corpus\n",
    ")\n",
    "del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Word Embedding\n",
    "\n",
    "Embedding is to train the model to group similar events in a close proximity in the event vector space. If two events e.g. 'pencil' and 'pen' are similar concepts, then their event vectors resides in a close distance in the event space. \n",
    "\n",
    "* [Thought Vectors](https://wiki.pathmind.com/thought-vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "if USE_CBOW:\n",
    "    from layer.embedding_cbow_dual_vector_spaces.py import (\n",
    "        Embedding\n",
    "    )\n",
    "else:\n",
    "    from layer.embedding_sgram import (\n",
    "        Embedding\n",
    "    )\n",
    "\n",
    "from optimizer import (\n",
    "    SGD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding: Embedding = Embedding(\n",
    "    name=\"embedding\",\n",
    "    num_nodes=WINDOW_SIZE,\n",
    "    target_size=TARGET_SIZE,\n",
    "    context_size=CONTEXT_SIZE,\n",
    "    negative_sample_size=SAMPLE_SIZE,\n",
    "    event_vector_size=VECTOR_SIZE,\n",
    "    dictionary=word_indexing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluate the vector space\n",
    "\n",
    "Verify if the trained model, or the vector space W, has encoded the words in a way that **similar** words are close in the vector space.\n",
    "\n",
    "* [How to measure the similarity among vectors](https://math.stackexchange.com/questions/4132458)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark \n",
    "\n",
    "Use [gensim word2vec](https://radimrehurek.com/gensim/models/word2vec.html) as the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import (\n",
    "    Word2Vec\n",
    ")\n",
    "from gensim.models.word2vec import (\n",
    "    LineSentence    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence(source=path_to_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    sg=0,\n",
    "    window=3, \n",
    "    negative=3,\n",
    "    vector_size=100, \n",
    "    min_count=1, \n",
    "    workers=4\n",
    ")\n",
    "del sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "context = \"king\".split()\n",
    "word_indices = np.array(word_indexing.list_indices(context), dtype=TYPE_INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text8 based trained model\n",
    "\n",
    "Split text8 into lines where each line has N words (e.g. 512)\n",
    "```\n",
    "N=512\n",
    "cat text8 | xargs -n $N > text8_$N\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT8_C10_S5_WND_v100_LR20\n",
    "\n",
    "```\n",
    "USE_TEXT8 = True\n",
    "\n",
    "CORPUS_FILE = \"text8_512\" if USE_TEXT8 else \"ptb_train\"\n",
    "CORPUS_URL = \"https://data.deepai.org/text8.zip\" \\\n",
    "    if USE_TEXT8 else 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/ptb.train.txt'\n",
    "\n",
    "TARGET_SIZE = TYPE_INT(1)       # Size of the target event (word)\n",
    "CONTEXT_SIZE = TYPE_INT(10)     # Size of the context in which the target event occurs.\n",
    "WINDOW_SIZE = TARGET_SIZE + CONTEXT_SIZE\n",
    "SAMPLE_SIZE = TYPE_INT(5)      # Size of the negative samples\n",
    "VECTOR_SIZE = TYPE_INT(100)     # Number of features in the event vector.\n",
    "\n",
    "WEIGHT_SCHEME = \"normal\"\n",
    "WEIGHT_PARAMS = {\n",
    "    \"std\": 0.01\n",
    "}\n",
    "LR = TYPE_FLOAT(20.0)\n",
    "\n",
    "NUM_SENTENCES = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "event_size 1\n",
      "context_size: 10\n",
      "event_vector_size: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = embedding.load(STATE_FILE_TEXT8_C10_S5_WND_v100_LR20)\n",
    "\n",
    "fmt=\"\"\"Model loaded.\n",
    "event_size %s\n",
    "context_size: %s\n",
    "event_vector_size: %s\n",
    "\"\"\"\n",
    "print(fmt % (\n",
    "    state[\"target_size\"], \n",
    "    state[\"context_size\"], \n",
    "    state[\"event_vector_size\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT8_C6_S6_WND_V100_LR20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "event_size 1\n",
      "context_size: 6\n",
      "event_vector_size: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = embedding.load(STATE_FILE_TEXT8_C6_S6_WND_V100_LR20)\n",
    "\n",
    "fmt=\"\"\"Model loaded.\n",
    "event_size %s\n",
    "context_size: %s\n",
    "event_vector_size: %s\n",
    "\"\"\"\n",
    "print(fmt % (\n",
    "    state[\"target_size\"], \n",
    "    state[\"context_size\"], \n",
    "    state[\"event_vector_size\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision between text8-based model and gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text8 model predictions (cosine evaluation) for ['king']:\n",
      "8165:emperor\n",
      "3371:president\n",
      "5569:queen\n",
      "2971:son\n",
      "4567:iii\n",
      "4148:battle\n",
      "1351:john\n",
      "5657:charles\n",
      "6156:prince\n",
      "1015:italian\n",
      "\n",
      "Text8 model predictions (distance evaluation) for ['king']:\n",
      "3371:president\n",
      "8165:emperor\n",
      "2971:son\n",
      "1351:john\n",
      "4148:battle\n",
      "5657:charles\n",
      "287:book\n",
      "1286:david\n",
      "1670:george\n",
      "4906:england\n",
      "\n",
      "Gensim predictions for ['king']:\n",
      "('prince', 0.7660735249519348)\n",
      "('queen', 0.7235230207443237)\n",
      "('emperor', 0.7160524129867554)\n",
      "('pope', 0.7091274857521057)\n",
      "('throne', 0.7053828239440918)\n",
      "('tsar', 0.6905214190483093)\n",
      "('kings', 0.6828960180282593)\n",
      "('sultan', 0.6712819337844849)\n",
      "('lord', 0.6602793335914612)\n",
      "('crown', 0.6600614190101624)\n"
     ]
    }
   ],
   "source": [
    "cosines, distances = embedding.predict(word_indices, n)\n",
    "print(\"Text8 model predictions (cosine evaluation) for %s:\" % context)\n",
    "for word_index in cosines:\n",
    "    print(f\"{word_index}:{word_indexing.list_events([word_index])}\")\n",
    "    \n",
    "print(\"\\nText8 model predictions (distance evaluation) for %s:\" % context)\n",
    "for word_index in distances:\n",
    "    print(f\"{word_index}:{word_indexing.list_events([word_index])}\")\n",
    "    \n",
    "print(\"\\nGensim predictions for %s:\" % context)\n",
    "for word in w2v.wv.most_similar(context, topn=n):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PTB based training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C10_S5_WND_V100_LR5\n",
    "\n",
    "```\n",
    "TARGET_SIZE = TYPE_INT(1)       # Size of the target event (word)\n",
    "CONTEXT_SIZE = TYPE_INT(10)     # Size of the context in which the target event occurs.\n",
    "WINDOW_SIZE = TARGET_SIZE + CONTEXT_SIZE\n",
    "SAMPLE_SIZE = TYPE_INT(5)       # Size of the negative samples\n",
    "\n",
    "VECTOR_SIZE = TYPE_INT(100)     # Number of features in the event vector.\n",
    "WEIGHT_SCHEME = \"normal\"\n",
    "WEIGHT_PARAMS = {\n",
    "    \"std\": 0.01\n",
    "}\n",
    "\n",
    "LR = TYPE_FLOAT(5)\n",
    "NUM_SENTENCES = 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = embedding.load(STATE_PTB_FILE_C10_S5_WND_V100_LR5)\n",
    "\n",
    "fmt=\"\"\"Model loaded.\n",
    "event_size %s\n",
    "context_size: %s\n",
    "event_vector_size: %s\n",
    "\"\"\"\n",
    "print(fmt % (\n",
    "    state[\"target_size\"], \n",
    "    state[\"context_size\"], \n",
    "    state[\"event_vector_size\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = np.array(word_indexing.list_indices(context), dtype=TYPE_INT)\n",
    "\n",
    "print(f\"Words {context}\")\n",
    "print(f\"Word indices {word_indices}\")\n",
    "print(word_indexing.list_events([embedding.predict(word_indices, n)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C10_S5_WND_V100_LR20\n",
    "\n",
    "```\n",
    "TARGET_SIZE = TYPE_INT(1)       # Size of the target event (word)\n",
    "CONTEXT_SIZE = TYPE_INT(10)     # Size of the context in which the target event occurs.\n",
    "WINDOW_SIZE = TARGET_SIZE + CONTEXT_SIZE\n",
    "SAMPLE_SIZE = TYPE_INT(5)       # Size of the negative samples\n",
    "\n",
    "VECTOR_SIZE = TYPE_INT(100)     # Number of features in the event vector.\n",
    "WEIGHT_SCHEME = \"normal\"\n",
    "WEIGHT_PARAMS = {\n",
    "    \"std\": 0.01\n",
    "}\n",
    "\n",
    "LR = TYPE_FLOAT(20)\n",
    "NUM_SENTENCES = 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = embedding.load(STATE_FILE_PTB_C10_S5_WND_V100_LR20)\n",
    "\n",
    "fmt=\"\"\"Model loaded.\n",
    "event_size %s\n",
    "context_size: %s\n",
    "event_vector_size: %s\n",
    "\"\"\"\n",
    "print(fmt % (\n",
    "    state[\"target_size\"], \n",
    "    state[\"context_size\"], \n",
    "    state[\"event_vector_size\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = np.array(word_indexing.list_indices(context), dtype=TYPE_INT)\n",
    "\n",
    "print(f\"Words {context}\")\n",
    "print(f\"Word indices {word_indices}\")\n",
    "print(word_indexing.list_events([embedding.predict(word_indices, n)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
