{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "<img src=\"image/word2vec_cbow_mechanism.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "from itertools import islice\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_GOOGLE_COLAB = True\n",
    "except:\n",
    "    IN_GOOGLE_COLAB = False\n",
    "    \n",
    "if IN_GOOGLE_COLAB:\n",
    "    !pip install line_profiler\n",
    "    !google.colab.drive.mount('/content/gdrive')\n",
    "    !rm -rf /content/github\n",
    "    !mkdir -p /content/github\n",
    "    !git clone https://github.com/oonisim/python-programs.git /content/github\n",
    "        \n",
    "    import sys\n",
    "    sys.path.append('/content/github/nlp/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "import function.fileio as fileio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PTB = True\n",
    "DEBUG = False\n",
    "VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"To be, or not to be, that is the question that matters\"\n",
    "_file = \"ptb.train.txt\"\n",
    "if USE_PTB:\n",
    "    if not fileio.Function.is_file(f\"~/.keras/datasets/{_file}\"):\n",
    "        path_to_ptb = tf.keras.utils.get_file(\n",
    "            _file, \n",
    "            f'https://raw.githubusercontent.com/tomsercu/lstm/master/data/{_file}'\n",
    "        )\n",
    "    corpus = fileio.Function.read_file(path_to_ptb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N \n",
      " mr. <unk> is chairman of <unk> n.v. the dutch publishing group \n",
      " rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate \n",
      " a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported \n"
     ]
    }
   ],
   "source": [
    "examples = corpus.split('\\n')[:5]\n",
    "for line in examples:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from layer.preprocessing import (\n",
    "    EventIndexing, \n",
    "    EventContext\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EventIndexing instance for the corpus\n",
    "\n",
    "Adapt to the ```corpus``` and provides:\n",
    "* event_to_index dictionary\n",
    "* vocaburary of the corpus\n",
    "* word occurrence probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexing = EventIndexing(\n",
    "    name=\"word_indexing_on_ptb\",\n",
    "    corpus=corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventIndexing.vocabulary[10]:\n",
      "['<nil>' '<unk>' 'finance' 'targeting' 'perfect' 'commissioned' 'rainbow' 'redemptions' 'adjusted' 'amendments']\n",
      "\n",
      "EventIndexing.event_to_index[10]:\n",
      "('<nil>', 0)\n",
      "('<unk>', 1)\n",
      "('finance', 2)\n",
      "('targeting', 3)\n",
      "('perfect', 4)\n",
      "('commissioned', 5)\n",
      "('rainbow', 6)\n",
      "('redemptions', 7)\n",
      "('adjusted', 8)\n",
      "('amendments', 9)\n",
      "\n",
      "EventIndexing.probabilities[10]:\n",
      "<nil>                : 0.00000e+00\n",
      "<unk>                : 1.65308e-02\n",
      "finance              : 2.72638e-04\n",
      "targeting            : 3.87112e-05\n",
      "perfect              : 4.07670e-05\n",
      "commissioned         : 2.30178e-05\n",
      "rainbow              : 2.05047e-05\n",
      "redemptions          : 2.05047e-05\n",
      "adjusted             : 1.32202e-04\n",
      "amendments           : 3.66183e-05\n"
     ]
    }
   ],
   "source": [
    "words = word_indexing.list_events(range(10))\n",
    "print(f\"EventIndexing.vocabulary[10]:\\n{words}\\n\")\n",
    "\n",
    "indices = word_indexing.list_event_indices(words)\n",
    "print(f\"EventIndexing.event_to_index[10]:\")\n",
    "for item in zip(words, indices):\n",
    "    print(item)\n",
    "\n",
    "probabilities = word_indexing.list_probabilities(words)\n",
    "print(f\"\\nEventIndexing.probabilities[10]:\")\n",
    "for word, p in zip(words, probabilities):\n",
    "    print(f\"{word:20s} : {p:.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the             :  3302\n",
      "asbestos        :  6850\n",
      "fiber           :  4331\n",
      "<unk>           :     1\n",
      "is              :  5084\n",
      "unusually       :  6782\n",
      "<unk>           :     1\n",
      "once            :  1675\n",
      "it              :  7612\n",
      "enters          :  9156\n",
      "the             :  3302\n",
      "<unk>           :     1\n",
      "\n",
      "with           :     0\n",
      "even            :     0\n",
      "brief           :     0\n"
     ]
    }
   ],
   "source": [
    "# sentences = \"\\n\".join(corpus.split('\\n')[5:6])\n",
    "sentences = \"\"\"\n",
    "the asbestos fiber <unk> is unusually <unk> once it enters the <unk> \n",
    "with even brief exposures to it causing symptoms that show up decades later researchers said\n",
    "\"\"\"\n",
    "sequences = word_indexing.function(sentences)\n",
    "for pair in zip(sentences.strip().split(\" \"), sequences[0]):\n",
    "    print(f\"{pair[0]:15} : {pair[1]:5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Context of a word in a sentence\n",
    "\n",
    "In the sentence ```\"a form of asbestos once used to make kent cigarette filters\"```, one of the context windows ```a form of asbestos once``` of size 5 and event size 1 has.\n",
    "* ```of``` as a target word.\n",
    "* ```(a, form) and (asbestos, once)``` as its context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence of the word indices for the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
       "array([[ 971, 8320, 3254, 6850, 1675, 8484, 9072, 7580, 4410, 7564, 2809,    0,    0,    0,    0,    0],\n",
       "       [1313, 6534, 8814, 8264, 3443, 2613, 3254, 3470, 5798,  518, 1849,  629, 4143,  971, 4048,  885]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"\"\"\n",
    "a form of asbestos once used to make kent cigarette filters\n",
    "\n",
    "N years old and former chairman of consolidated gold fields plc was named a nonexecutive director\n",
    "\"\"\"\n",
    "\n",
    "sequence = word_indexing.function(sentences)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target, context pairs\n",
    "\n",
    "For each word in the setence ```(of, asbestos, ... , kent)``` excludnig the ends of the sentence, create ```(target, context)``` as:\n",
    "\n",
    "```\n",
    "[\n",
    "  [of, a, form, asbestos, once],              # target is 'of', context is (a, form, asbestos, once)\n",
    "  ['asbestos', 'form', 'of', 'once', 'used'],\n",
    "  ['once', 'of', 'asbestos', 'used', 'to'],\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_context = EventContext(\n",
    "    name=\"ev\",\n",
    "    window_size=5,\n",
    "    event_size=1    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3254,  971, 8320, 6850, 1675],\n",
       "        [6850, 8320, 3254, 1675, 8484],\n",
       "        [1675, 3254, 6850, 8484, 9072],\n",
       "        [8484, 6850, 1675, 9072, 7580],\n",
       "        [9072, 1675, 8484, 7580, 4410],\n",
       "        [7580, 8484, 9072, 4410, 7564],\n",
       "        [4410, 9072, 7580, 7564, 2809],\n",
       "        [7564, 7580, 4410, 2809,    0],\n",
       "        [2809, 4410, 7564,    0,    0],\n",
       "        [   0, 7564, 2809,    0,    0],\n",
       "        [   0, 2809,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0]],\n",
       "\n",
       "       [[8814, 1313, 6534, 8264, 3443],\n",
       "        [8264, 6534, 8814, 3443, 2613],\n",
       "        [3443, 8814, 8264, 2613, 3254],\n",
       "        [2613, 8264, 3443, 3254, 3470],\n",
       "        [3254, 3443, 2613, 3470, 5798],\n",
       "        [3470, 2613, 3254, 5798,  518],\n",
       "        [5798, 3254, 3470,  518, 1849],\n",
       "        [ 518, 3470, 5798, 1849,  629],\n",
       "        [1849, 5798,  518,  629, 4143],\n",
       "        [ 629,  518, 1849, 4143,  971],\n",
       "        [4143, 1849,  629,  971, 4048],\n",
       "        [ 971,  629, 4143, 4048,  885]]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_context_pairs = event_context.function(sequence)\n",
    "event_context_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target, context pairs in textual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['of', 'a', 'form', 'asbestos', 'once'],\n",
       "  ['asbestos', 'form', 'of', 'once', 'used'],\n",
       "  ['once', 'of', 'asbestos', 'used', 'to'],\n",
       "  ['used', 'asbestos', 'once', 'to', 'make'],\n",
       "  ['to', 'once', 'used', 'make', 'kent'],\n",
       "  ['make', 'used', 'to', 'kent', 'cigarette'],\n",
       "  ['kent', 'to', 'make', 'cigarette', 'filters'],\n",
       "  ['cigarette', 'make', 'kent', 'filters', '<nil>'],\n",
       "  ['filters', 'kent', 'cigarette', '<nil>', '<nil>'],\n",
       "  ['<nil>', 'cigarette', 'filters', '<nil>', '<nil>'],\n",
       "  ['<nil>', 'filters', '<nil>', '<nil>', '<nil>'],\n",
       "  ['<nil>', '<nil>', '<nil>', '<nil>', '<nil>']],\n",
       " [['old', 'n', 'years', 'and', 'former'],\n",
       "  ['and', 'years', 'old', 'former', 'chairman'],\n",
       "  ['former', 'old', 'and', 'chairman', 'of'],\n",
       "  ['chairman', 'and', 'former', 'of', 'consolidated'],\n",
       "  ['of', 'former', 'chairman', 'consolidated', 'gold'],\n",
       "  ['consolidated', 'chairman', 'of', 'gold', 'fields'],\n",
       "  ['gold', 'of', 'consolidated', 'fields', 'plc'],\n",
       "  ['fields', 'consolidated', 'gold', 'plc', 'was'],\n",
       "  ['plc', 'gold', 'fields', 'was', 'named'],\n",
       "  ['was', 'fields', 'plc', 'named', 'a'],\n",
       "  ['named', 'plc', 'was', 'a', 'nonexecutive'],\n",
       "  ['a', 'was', 'named', 'nonexecutive', 'director']]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indexing.sequence_to_sentence(event_context_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
