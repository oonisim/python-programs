{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "<img src=\"image/word2vec_cbow_mechanism.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "from itertools import islice\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_GOOGLE_COLAB = True\n",
    "except:\n",
    "    IN_GOOGLE_COLAB = False\n",
    "    \n",
    "if IN_GOOGLE_COLAB:\n",
    "    !pip install line_profiler\n",
    "    !google.colab.drive.mount('/content/gdrive')\n",
    "    !rm -rf /content/github\n",
    "    !mkdir -p /content/github\n",
    "    !git clone https://github.com/oonisim/python-programs.git /content/github\n",
    "        \n",
    "    import sys\n",
    "    sys.path.append('/content/github/nlp/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "import function.fileio as fileio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PTB = True\n",
    "DEBUG = False\n",
    "VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"To be, or not to be, that is the question that matters\"\n",
    "_file = \"ptb.train.txt\"\n",
    "if USE_PTB:\n",
    "    if not fileio.Function.is_file(f\"~/.keras/datasets/{_file}\"):\n",
    "        path_to_ptb = tf.keras.utils.get_file(\n",
    "            _file, \n",
    "            f'https://raw.githubusercontent.com/tomsercu/lstm/master/data/{_file}'\n",
    "        )\n",
    "    corpus = fileio.Function.read_file(path_to_ptb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N \n",
      " mr. <unk> is chairman of <unk> n.v. the dutch publishing group \n",
      " rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate \n",
      " a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported \n"
     ]
    }
   ],
   "source": [
    "examples = corpus.split('\\n')[:5]\n",
    "for line in examples:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from layer.preprocessing import (\n",
    "    EventIndexing, \n",
    "    EventContext\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EventIndexing instance for the corpus\n",
    "\n",
    "Adapt to the ```corpus``` and provides:\n",
    "* event_to_index dictionary\n",
    "* vocaburary of the corpus\n",
    "* word occurrence probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexing = EventIndexing(\n",
    "    name=\"word_indexing_on_ptb\",\n",
    "    corpus=corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventIndexing.vocabulary[10]:\n",
      "['<nil>' '<unk>' 'has' 'imposed' 'alter' 'subsidiary' 'bleeding' 'historically' 'asia' 'phil']\n",
      "\n",
      "EventIndexing.event_to_index[10]:\n",
      "('<nil>', 0)\n",
      "('<unk>', 1)\n",
      "('has', 2)\n",
      "('imposed', 3)\n",
      "('alter', 4)\n",
      "('subsidiary', 5)\n",
      "('bleeding', 6)\n",
      "('historically', 7)\n",
      "('asia', 8)\n",
      "('phil', 9)\n",
      "\n",
      "EventIndexing.probabilities[10]:\n",
      "<nil>                : 0.00000e+00\n",
      "<unk>                : 1.65308e-02\n",
      "has                  : 2.43071e-03\n",
      "imposed              : 6.51042e-05\n",
      "alter                : 4.47793e-05\n",
      "subsidiary           : 2.46237e-04\n",
      "bleeding             : 2.05047e-05\n",
      "historically         : 4.27888e-05\n",
      "asia                 : 8.66619e-05\n",
      "phil                 : 2.54424e-05\n"
     ]
    }
   ],
   "source": [
    "words = word_indexing.list_events(range(10))\n",
    "print(f\"EventIndexing.vocabulary[10]:\\n{words}\\n\")\n",
    "\n",
    "indices = word_indexing.list_event_indices(words)\n",
    "print(f\"EventIndexing.event_to_index[10]:\")\n",
    "for item in zip(words, indices):\n",
    "    print(item)\n",
    "\n",
    "probabilities = word_indexing.list_probabilities(words)\n",
    "print(f\"\\nEventIndexing.probabilities[10]:\")\n",
    "for word, p in zip(words, probabilities):\n",
    "    print(f\"{word:20s} : {p:.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the             :  3865\n",
      "asbestos        :  4861\n",
      "fiber           :   356\n",
      "<unk>           :     1\n",
      "is              :  2643\n",
      "unusually       :  7375\n",
      "<unk>           :     1\n",
      "once            :  5904\n",
      "it              :  7722\n",
      "enters          :  7242\n",
      "the             :  3865\n",
      "<unk>           :     1\n",
      "\n",
      "with           :     0\n",
      "even            :     0\n",
      "brief           :     0\n"
     ]
    }
   ],
   "source": [
    "# sentences = \"\\n\".join(corpus.split('\\n')[5:6])\n",
    "sentences = \"\"\"\n",
    "the asbestos fiber <unk> is unusually <unk> once it enters the <unk> \n",
    "with even brief exposures to it causing symptoms that show up decades later researchers said\n",
    "\"\"\"\n",
    "sequences = word_indexing.function(sentences)\n",
    "for pair in zip(sentences.strip().split(\" \"), sequences[0]):\n",
    "    print(f\"{pair[0]:15} : {pair[1]:5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Context of a word in a sentence\n",
    "\n",
    "In the sentence ```\"a form of asbestos once used to make kent cigarette filters\"```, one of the context windows ```a form of asbestos once``` of size 5 and event size 1 has.\n",
    "* ```of``` as a target word.\n",
    "* ```(a, form) and (asbestos, once)``` as its context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence of the word indices for the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2274, 4665, 8174, 4861, 5904, 7477, 8907, 8707,  198, 9119, 3214,    0,    0,    0,    0,    0],\n",
       "       [5016, 6114, 5416, 5980, 9300, 4650, 8174, 8850, 4103, 5874, 9391, 7317,  406, 2274, 7383, 1620]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"\"\"\n",
    "a form of asbestos once used to make kent cigarette filters\n",
    "\n",
    "N years old and former chairman of consolidated gold fields plc was named a nonexecutive director\n",
    "\"\"\"\n",
    "\n",
    "sequence = word_indexing.function(sentences)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target, context pairs\n",
    "\n",
    "For each word in the setence ```(of, asbestos, ... , kent)``` excludnig the ends of the sentence, create ```(target, context)``` as:\n",
    "\n",
    "```\n",
    "[\n",
    "  [of, a, form, asbestos, once],              # target is 'of', context is (a, form, asbestos, once)\n",
    "  ['asbestos', 'form', 'of', 'once', 'used'],\n",
    "  ['once', 'of', 'asbestos', 'used', 'to'],\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_context = EventContext(\n",
    "    name=\"ev\",\n",
    "    window_size=5,\n",
    "    event_size=1    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8174, 2274, 4665, 4861, 5904],\n",
       "        [4861, 4665, 8174, 5904, 7477],\n",
       "        [5904, 8174, 4861, 7477, 8907],\n",
       "        [7477, 4861, 5904, 8907, 8707],\n",
       "        [8907, 5904, 7477, 8707,  198],\n",
       "        [8707, 7477, 8907,  198, 9119],\n",
       "        [ 198, 8907, 8707, 9119, 3214],\n",
       "        [9119, 8707,  198, 3214,    0],\n",
       "        [3214,  198, 9119,    0,    0],\n",
       "        [   0, 9119, 3214,    0,    0],\n",
       "        [   0, 3214,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0]],\n",
       "\n",
       "       [[5416, 5016, 6114, 5980, 9300],\n",
       "        [5980, 6114, 5416, 9300, 4650],\n",
       "        [9300, 5416, 5980, 4650, 8174],\n",
       "        [4650, 5980, 9300, 8174, 8850],\n",
       "        [8174, 9300, 4650, 8850, 4103],\n",
       "        [8850, 4650, 8174, 4103, 5874],\n",
       "        [4103, 8174, 8850, 5874, 9391],\n",
       "        [5874, 8850, 4103, 9391, 7317],\n",
       "        [9391, 4103, 5874, 7317,  406],\n",
       "        [7317, 5874, 9391,  406, 2274],\n",
       "        [ 406, 9391, 7317, 2274, 7383],\n",
       "        [2274, 7317,  406, 7383, 1620]]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_context_pairs = event_context.function(sequence)\n",
    "event_context_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target, context pairs in textual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['of', 'a', 'form', 'asbestos', 'once'],\n",
       "  ['asbestos', 'form', 'of', 'once', 'used'],\n",
       "  ['once', 'of', 'asbestos', 'used', 'to'],\n",
       "  ['used', 'asbestos', 'once', 'to', 'make'],\n",
       "  ['to', 'once', 'used', 'make', 'kent'],\n",
       "  ['make', 'used', 'to', 'kent', 'cigarette'],\n",
       "  ['kent', 'to', 'make', 'cigarette', 'filters'],\n",
       "  ['cigarette', 'make', 'kent', 'filters', '<nil>'],\n",
       "  ['filters', 'kent', 'cigarette', '<nil>', '<nil>'],\n",
       "  ['<nil>', 'cigarette', 'filters', '<nil>', '<nil>'],\n",
       "  ['<nil>', 'filters', '<nil>', '<nil>', '<nil>'],\n",
       "  ['<nil>', '<nil>', '<nil>', '<nil>', '<nil>']],\n",
       " [['old', 'n', 'years', 'and', 'former'],\n",
       "  ['and', 'years', 'old', 'former', 'chairman'],\n",
       "  ['former', 'old', 'and', 'chairman', 'of'],\n",
       "  ['chairman', 'and', 'former', 'of', 'consolidated'],\n",
       "  ['of', 'former', 'chairman', 'consolidated', 'gold'],\n",
       "  ['consolidated', 'chairman', 'of', 'gold', 'fields'],\n",
       "  ['gold', 'of', 'consolidated', 'fields', 'plc'],\n",
       "  ['fields', 'consolidated', 'gold', 'plc', 'was'],\n",
       "  ['plc', 'gold', 'fields', 'was', 'named'],\n",
       "  ['was', 'fields', 'plc', 'named', 'a'],\n",
       "  ['named', 'plc', 'was', 'a', 'nonexecutive'],\n",
       "  ['a', 'was', 'named', 'nonexecutive', 'director']]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indexing.sequence_to_sentence(event_context_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
