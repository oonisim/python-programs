{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=400) \n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "<img src=\"image/word2vec_cbow_mechanism.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding (OHE) as row selector\n",
    "Each row of the identity matrix I extracts the row at the ```1``` position, e.g. ```[0, 1, 0, 0, 0, 0, 0]``` extracts the 2nd row.\n",
    "\n",
    "word2vec first convert a word into a one-hot-encoding vector, then use it to extract a ```word vector``` from the ```word vector space (word embedding matrix)```. Suppose the word vector space is ```(7, 4``` matrix:\n",
    "\n",
    "```\n",
    "[[ 0  1  2  3]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]\n",
    " [16 17 18 19]\n",
    " [20 21 22 23]\n",
    " [24 25 26 27]]\n",
    " ```\n",
    " \n",
    " The OHE ```[0, 1, 0, 0, 0, 0, 0]``` extracts the 2nd row ``` 4  5  6  7]``` by dot operation ```@```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]\n",
      " [24 25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([0, 1, 0, 0, 0, 0, 0])\n",
    "n = 4\n",
    "W = np.arange(len(c) * n).reshape(len(c), n)\n",
    "print(c)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c@W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import (\n",
    "    DELIMITER,\n",
    "    SPACE,\n",
    "    NIL\n",
    ")\n",
    "\n",
    "STRIDE = 2\n",
    "CONTEXT_SIZE = 1 + (STRIDE * 2)\n",
    "\n",
    "USE_PTB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.text import (\n",
    "    PAD_MODE_SQUEEZE,\n",
    "    pad_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"To be, or not to be, that is the question that matters\"\n",
    "if USE_PTB:\n",
    "    corpus=load_text('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.text import (\n",
    "    text_to_sequence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = re.sub(r'[.,:;]+', SPACE, corpus.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sequence, word_to_id, id_to_word, vocabulary_size) = text_to_sequence(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word to id \n",
      "{'to': 0, 'be': 1, 'or': 2, 'not': 3, 'that': 4, 'is': 5, 'the': 6, 'question': 7, 'matters': 8}\n",
      "id to word \n",
      "{0: 'to', 1: 'be', 2: 'or', 3: 'not', 4: 'that', 5: 'is', 6: 'the', 7: 'question', 8: 'matters'}\n",
      "\n",
      "corpus is \n",
      "[to be  or not to be  that is the question that matters]\n",
      "sequence is \n",
      "[0 1 2 3 0 1 4 5 6 7 4 8]\n",
      "corpus size is 12 sequence size is 12 expected sum is 32\n",
      "['to' 'be' 'or' 'not' 'to' 'be' 'that' 'is' 'the' 'question' 'that' 'matters']\n"
     ]
    }
   ],
   "source": [
    "if not USE_PTB:\n",
    "    print(\"word to id \\n{}\".format(word_to_id))\n",
    "    print(\"id to word \\n{}\".format(id_to_word))\n",
    "    print()\n",
    "    print(\"corpus is \\n[{}]\".format(corpus))\n",
    "    print(\"sequence is \\n{}\".format(sequence))\n",
    "    print(\"corpus size is {} sequence size is {} expected sum is {}\".format(\n",
    "        len(re.compile('[\\t\\s]+').split(corpus)), \n",
    "        len(sequence), \n",
    "        (len(sequence) - (2*STRIDE)) * (2*STRIDE)  # Exclude NIL from the sequence\n",
    "    ))\n",
    "    #print([id_to_word[index] for index in sequence])\n",
    "    print(np.array([id_to_word[index] for index in sequence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np.analytics import (\n",
    "    create_context_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 3, 0],\n",
       "       [1, 2, 0, 1],\n",
       "       [2, 3, 1, 4],\n",
       "       [3, 0, 4, 5],\n",
       "       [0, 1, 5, 6],\n",
       "       [1, 4, 6, 7],\n",
       "       [4, 5, 7, 4],\n",
       "       [5, 6, 4, 8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts, labels = create_context_set(sequence, CONTEXT_SIZE)\n",
    "contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be  or not to be  that is the question that matters\n",
      "context ['to', 'be', 'not', 'to']                label or        \n",
      "context ['be', 'or', 'to', 'be']                 label not       \n",
      "context ['or', 'not', 'be', 'that']              label to        \n",
      "context ['not', 'to', 'that', 'is']              label be        \n",
      "context ['to', 'be', 'is', 'the']                label that      \n",
      "context ['be', 'that', 'the', 'question']        label is        \n",
      "context ['that', 'is', 'question', 'that']       label the       \n",
      "context ['is', 'the', 'that', 'matters']         label question  \n"
     ]
    }
   ],
   "source": [
    "if not USE_PTB:\n",
    "    print(corpus)\n",
    "    for context, label in zip(contexts, labels):\n",
    "        print(\"context {:40} label {:10}\".format(\n",
    "            '{}'.format([id_to_word[index] for index in context]), \n",
    "            id_to_word[label]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to One Hot Encoding (OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.encoding import (\n",
    "    convert_one_hot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = max(word_to_id.values()) + 1\n",
    "ohe_contexts = convert_one_hot(contexts, length)\n",
    "ohe_labels = convert_one_hot(labels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
