{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "<img src=\"image/word2vec_cbow_mechanism.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "from itertools import islice\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_GOOGLE_COLAB = True\n",
    "except:\n",
    "    IN_GOOGLE_COLAB = False\n",
    "    \n",
    "if IN_GOOGLE_COLAB:\n",
    "    !pip install line_profiler\n",
    "    !google.colab.drive.mount('/content/gdrive')\n",
    "    !rm -rf /content/github\n",
    "    !mkdir -p /content/github\n",
    "    !git clone https://github.com/oonisim/python-programs.git /content/github\n",
    "        \n",
    "    import sys\n",
    "    sys.path.append('/content/github/nlp/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "import function.fileio as fileio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PTB = True\n",
    "DEBUG = False\n",
    "VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"To be, or not to be, that is the question that matters\"\n",
    "_file = \"ptb.train.txt\"\n",
    "if USE_PTB:\n",
    "    if not fileio.Function.is_file(f\"~/.keras/datasets/{_file}\"):\n",
    "        path_to_ptb = tf.keras.utils.get_file(\n",
    "            _file, \n",
    "            f'https://raw.githubusercontent.com/tomsercu/lstm/master/data/{_file}'\n",
    "        )\n",
    "    corpus = fileio.Function.read_file(path_to_ptb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N \n",
      " mr. <unk> is chairman of <unk> n.v. the dutch publishing group \n",
      " rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate \n",
      " a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported \n"
     ]
    }
   ],
   "source": [
    "examples = corpus.split('\\n')[:5]\n",
    "for line in examples:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from layer.preprocessing import (\n",
    "    WordIndexing, \n",
    "    EventContext\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordIndexing instance for the corpus\n",
    "\n",
    "Adapt to the ```corpus``` and provides:\n",
    "* word_to_index dictionary\n",
    "* vocaburary of the corpus\n",
    "* word occurrence probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexing = WordIndexing(\n",
    "    name=\"word_indexing_on_ptb\",\n",
    "    corpus=corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordIndexing.vocabulary[10]:\n",
      "['<nil>' '<unk>' 'develop' 'est' 'request' 'hero' 'breakfast' 'nutritional' 'art' 'satisfaction']\n",
      "\n",
      "WordIndexing.word_to_index[10]:\n",
      "('<nil>', 0)\n",
      "('<unk>', 1)\n",
      "('develop', 2)\n",
      "('est', 3)\n",
      "('request', 4)\n",
      "('hero', 5)\n",
      "('breakfast', 6)\n",
      "('nutritional', 7)\n",
      "('art', 8)\n",
      "('satisfaction', 9)\n",
      "\n",
      "WordIndexing.probabilities[10]:\n",
      "<nil>                : 0.00000e+00\n",
      "<unk>                : 5.05607e-02\n",
      "develop              : 9.09688e-05\n",
      "est                  : 2.47076e-05\n",
      "request              : 6.73843e-05\n",
      "hero                 : 1.01076e-05\n",
      "breakfast            : 1.12307e-05\n",
      "nutritional          : 6.73843e-06\n",
      "art                  : 7.97381e-05\n",
      "satisfaction         : 2.02153e-05\n"
     ]
    }
   ],
   "source": [
    "words = word_indexing.list_words(range(10))\n",
    "print(f\"WordIndexing.vocabulary[10]:\\n{words}\\n\")\n",
    "\n",
    "indices = word_indexing.list_word_indices(words)\n",
    "print(f\"WordIndexing.word_to_index[10]:\")\n",
    "for item in zip(words, indices):\n",
    "    print(item)\n",
    "\n",
    "probabilities = word_indexing.list_probabilities(words)\n",
    "print(f\"\\nWordIndexing.probabilities[10]:\")\n",
    "for word, p in zip(words, probabilities):\n",
    "    print(f\"{word:20s} : {p:.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentence is empty. Skipping...\n",
      "Sentence is empty. Skipping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the             :  6072\n",
      "asbestos        :  9467\n",
      "fiber           :  2220\n",
      "<unk>           :     1\n",
      "is              :  8569\n",
      "unusually       :  7332\n",
      "<unk>           :     1\n",
      "once            :  2480\n",
      "it              :  6455\n",
      "enters          :  1875\n",
      "the             :  6072\n",
      "<unk>           :     1\n",
      "with            :  1737\n",
      "even            :  9532\n",
      "brief           :  1111\n",
      "exposures       :  1120\n",
      "to              :  3007\n",
      "it              :  6455\n",
      "causing         :  1069\n",
      "symptoms        :   738\n",
      "that            :  1407\n",
      "show            :  5812\n",
      "up              :  4301\n",
      "decades         :  7624\n",
      "later           :  8536\n",
      "researchers     :  9612\n",
      "said            :  1758\n"
     ]
    }
   ],
   "source": [
    "# sentences = \"\\n\".join(corpus.split('\\n')[5:6])\n",
    "sentences = \"\"\"\n",
    "the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said\n",
    "\"\"\"\n",
    "sequences = word_indexing.function(sentences)\n",
    "for pair in zip(sentences.strip().split(\" \"), sequences[0]):\n",
    "    print(f\"{pair[0]:15} : {pair[1]:5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
