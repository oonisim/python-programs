{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [CS231n: Convolutional Neural Networks for Visual Recognition 2017](http://cs231n.stanford.edu/2017/syllabus)\n",
    "    - [cs231n 2017 assignment #1 kNN, SVM, SoftMax, two-layer network](https://cs231n.github.io/assignments2017/assignment1/)\n",
    "    - [Training a Softmax Linear Classifier](https://cs231n.github.io/neural-networks-case-study)\n",
    "* [ゼロから作る Deep Learning](https://github.com/oreilly-japan/deep-learning-from-scratch)\n",
    "* [Mathematics for Machine Learning](https://mml-book.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network \n",
    "Simple one layer neural network classifier. Mathjax formula not fully supported in github, hence the formulas get corrupted.\n",
    "\n",
    "<img src=\"image/nn_diagram.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/nn_functions.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Optional,\n",
    "    Union,\n",
    "    List,\n",
    "    Dict,\n",
    "    Tuple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python path\n",
    "Python path setup to avoid the relative imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=80) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install line_profile memory_profiler\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1    # Batch size\n",
    "D = 3    # Number of features in the input data\n",
    "M = 2    # Number of nodes in a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confiurations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X\n",
    "X is to have been standardized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T\n",
    "Labels for data X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For One Hot Encoding labels\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset{ (N,M) }{ T_{_{OHE}} } &= ( \n",
    "    \\overset{ (M,) }{ T_{(n=0)} }, \\; \\dots \\;, \\overset{ (M,) }{ T_{(n=N-1)} } \n",
    ") \n",
    "\\\\\n",
    "\\overset{ (N,M) }{ T_{_{OHE}} } = ( \n",
    "    \\overset{ (M,) }{ T_{(n=0)} }, \\dots , \\overset{ (M,) }{ T_{(n=N-1)} } \n",
    ") \n",
    "\\\\\n",
    "\\overset{ (M,) }{ T_{ _{OHE} (n)} } &= ( \\overset{ () }{ t_{(n)(m=0)} }, \\; \\dots \\;, \\overset{ () }{ t_{(n)(m=M-1)} })\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "### For index labels\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset{ (N,) }{ T_{_{IDX}} } &= (\\overset{ () }{ t_{(n=0)} }, \\; \\dots \\;, \\overset{ () }{ t_{(n=N-1)} }) \\qquad \\text {for index labels }\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W\n",
    "Weight parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import (\n",
    "    xavier,\n",
    "    he,\n",
    "    uniform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization Layer\n",
    "Apply normalization or use batch normaliation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matmul layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer.matmul import Matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset{ (N,M) }{ Y } \n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "{ Y_{(n=0)} } \\\\\n",
    "\\vdots \\\\\n",
    "{ Y_{(n)} } \\\\\n",
    "\\vdots \\\\\n",
    "{ Y_{(n=N-1)} }\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\overset{ (N,D) }{ X } \\; @ \\; \\overset{ (D,M) }{ W^T }\n",
    "\\\\\n",
    "\\\\\n",
    "\\overset{ (M,) }{ Y_{(n)} } &= (y_{(n)(m=0)}, \\; \\dots, \\; y_{(n)(m)},  \\; \\dots, \\; y_{(n)(m=M-1)})\n",
    "\\\\\n",
    "\\overset{ () }{ y_{(n)(m)} }\n",
    "&= \\overset{ (D,) }{ X_{(n)} } \\cdot \\overset{ (D,) }{ W_{(m)}^T }\n",
    "= \\sum\\limits ^{D}_{d=0}  \\overset{ () }{ x_{(n)(d)} } * \\overset{ () }{ w_{(m)(d)} }\n",
    "\\\\\n",
    "_{(0 \\le d \\le D, \\; 0 \\le n \\lt N, \\; 0 \\le m \\lt M)}\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient dL/dX\n",
    "\n",
    "Impact on L by $dX$.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset { (N,D) }{ \\frac {\\partial L }{ \\partial X } }\n",
    "= \\overset { (N,M) }{ \\frac {\\partial L}{\\partial Y} }\n",
    "@ \\overset { (M,D) }{ W } \n",
    "\\end{align*}\n",
    "$\n",
    "<img src=\"image/nn_back_propagation_dL_dX.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient dL/dW.T\n",
    "Impact on L by $dW^T$.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset { (N,M) }{ \\frac {\\partial L }{ \\partial W^T } }\n",
    "= \\overset { (D,N) }{ X^T } \n",
    "@ \n",
    "\\overset { (N,M) }{ \\frac {\\partial L}{\\partial Y} }\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "<img src=\"image/nn_back_propagation_dL_dWT.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset{ (N,M) }{ A } &= \n",
    "activation \\left( \n",
    "    \\overset{ (N,M) }{ Y }  = \n",
    "    \\begin{bmatrix}\n",
    "    { Y_{(n=0)} } \\\\\n",
    "    \\vdots \\\\\n",
    "    { Y_{(n)} } \\\\\n",
    "    \\vdots \\\\\n",
    "    { Y_{(n=N-1)} }\n",
    "    \\end{bmatrix}\n",
    "\\right)\n",
    "\\\\\n",
    "\\overset{ (M,) }{ A_{(n)} } \n",
    "&= activation \\left( \\overset{ (M,) }{ Y_{(n) }} \\right)  \\\\\n",
    "&= (a_{(n)(m=0)}, \\; \\dots, \\; a_{(n)(m)},  \\; \\dots, \\; a_{(n)(m=M-1)})\n",
    "\\\\\n",
    "\\overset{ () }{ a_{(n)(m)} } &= activation \\left( \\overset{ () }{ y_{(n)(m)} } \\right)\n",
    "\\quad _{(0 \\le n \\lt N, \\; 0 \\le m \\lt M)}\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient dL/dY\n",
    "\n",
    "Impact on L by dY from the matmul layer.\n",
    "\n",
    "$\n",
    "\\begin {align*}\n",
    "\\overset { (N,M) }{ \\frac {\\partial L }{ \\partial Y } }\n",
    "= \\overset { (N,M) }{ \\frac {\\partial L}{\\partial A} } \n",
    "* \n",
    "\\overset { (N,M) }{ \\frac {\\partial A}{\\partial Y} }\n",
    "\\end {align*}\n",
    "$\n",
    "\n",
    "### For sigmoid activation\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset {(N,M)}{\\frac { \\partial L }{ \\partial Y} }\n",
    "&= \\frac { \\partial A }{ \\partial Y} * A * (1 - A)\n",
    "\\\\\n",
    "\\frac { \\partial y_{(n)(m)} } { \\partial a_{(n)(m)} }\n",
    "&= a_{(n)(m)} * (1 - a_{(n)(m)} )  \\\\ \n",
    "y_{(n)(m)} = sigmoid(a_{(n)(m)} )&=  \\frac {1}{ 1 + exp(y_{(n)(m)})}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "### For ReLU activation\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\frac { \\partial a_{(n)(m)} }{ \\partial y_{(n)(m)} }\n",
    "&= 1 \\quad y_{(n)(m)}  \\gt 0 \\\\\n",
    "&= 0 \\quad y_{(n)(m)}  \\le 0 \\\\\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax layer\n",
    "$C_n$ is to prevent the overflow at $np.exp()$.\n",
    "\n",
    "<img src=\"image/softmax.png\" align=\"left\" width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp(x) can take all x values and produces a positive, which is required for log(y) that needs y > 0, hence fit-for-purpose to build a probability function.\n",
    "\n",
    "<img src=\"image/exp.gif\" align=\"left\" width=250/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax and Cross Entropy Log Loss are combined as the gradient results in a simple form $P - T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def softmax(X: Union[np.ndarray, float]) -> Union[np.ndarray, float]:\n",
      "    \"\"\"Softmax P = exp(X) / sum(exp(X))\n",
      "    Args:\n",
      "        X: batch input data of shape (N,M).\n",
      "            N: Batch size\n",
      "            M: Number of nodes\n",
      "    Returns:\n",
      "        P: Probability of shape (N,M)\n",
      "    \"\"\"\n",
      "    name = \"softmax\"\n",
      "    assert isinstance(X, float) or (isinstance(X, np.ndarray) and X.dtype == float), \\\n",
      "        \"X must be float or ndarray(dtype=float)\"\n",
      "\n",
      "    # --------------------------------------------------------------------------------\n",
      "    # exp(x-c) to prevent the infinite exp(x) for a large value x, with c = max(x).\n",
      "    # keepdims=True to be able to broadcast.\n",
      "    # --------------------------------------------------------------------------------\n",
      "    C = np.max(X, axis=-1, keepdims=True)   # オーバーフロー対策\n",
      "    exp = np.exp(X - C)\n",
      "    P = exp / np.sum(exp, axis=-1, keepdims=True)\n",
      "    Logger.debug(\"%s: X %s exp %s P %s\", name, X, exp, P)\n",
      "\n",
      "    return P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from layer import CrossEntropyLogLoss\n",
    "from common import softmax\n",
    "\n",
    "lines = inspect.getsource(softmax)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset{ (N,1) }{ C } &= np.max\\left( \n",
    "    \\overset{ (N,M) }{ A }, \\; axis=-1,  \\; keepdim=True \n",
    "\\right) \\\\\n",
    "&=  \n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix} \\overset{ () }{ c_{(n=0  )} } \\end{bmatrix} \\\\\n",
    "    \\begin{bmatrix} \\overset{ () }{ c_{(n    )} } \\end{bmatrix} \\\\\n",
    "    \\begin{bmatrix} \\overset{ () }{ c_{(n=N-1)} } \\end{bmatrix}\n",
    "\\end{bmatrix} \n",
    "\\\\\n",
    "\\overset{ (N,M) }{ EXP } &= np.exp \\left( \\overset{ (N,M) }{ A } - \\overset{ (N,1) }{ C } \\right)\n",
    "= np.exp \\left(\n",
    "    \\begin{bmatrix}\n",
    "    { A_{(n=0)} } - { C_{(n=0)} }\\\\\n",
    "    \\vdots \\\\\n",
    "    { A_{(n)} }   - { C_{(n)} }\\\\\n",
    "    \\vdots \\\\\n",
    "    { A_{(n=N-1)} } - { C_{(n=N-1)} }\\\\\n",
    "    \\end{bmatrix}\n",
    "\\right) \n",
    "\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "    e_{(n=0)(m=0)}   & \\dots      & e_{(n=0)(m=M-1)}   \\\\  \n",
    "    \\vdots           & e_{(n)(m)} & \\vdots             \\\\\n",
    "    e_{(n=N-1)(m=0)} & \\dots      & e_{(n=N-1)(m=M-1)} \n",
    "\\end{bmatrix} \n",
    "\\\\\n",
    "\\\\\n",
    "\\overset{ (N,1) }{ S } &= \\overset{ (N,1) }{ sum(EXP) } = np.sum \\left( \n",
    "    \\overset{ (N,M) }{ EXP }, \\; axis=-1,  \\; keepdim=True \n",
    "\\right)\n",
    "\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix} \\overset{ () }{ s_{(n=0  )} } \\end{bmatrix} \\\\\n",
    "    \\begin{bmatrix} \\overset{ () }{ s_{(n    )} } \\end{bmatrix} \\\\\n",
    "    \\begin{bmatrix} \\overset{ () }{ s_{(n=N-1)} } \\end{bmatrix}\n",
    "\\end{bmatrix} \n",
    "\\\\\n",
    "\\overset{ () }{ s_{(n)} } &= \\sum\\limits ^{M-1}_{m=0} np.exp(\\; a_{(n)(m)} - c_{(n)} \\; )\n",
    "\\\\\n",
    "\\\\\n",
    "\\overset{ (N,M) }{ P } &= \\overset{ (N,M) }{ EXP }  \\;\\; / \\;\\; \\overset{ (N,1) }{ sum(EXP) } \n",
    "\\\\\n",
    "\\overset{ (N,) }{ P_{(n)} } &= (p_{(n)(m=0)}, \\; \\dots, \\; p_{(n)(m)} , \\; \\dots, \\; p_{(n)(m=M-1)})\n",
    "\\\\\n",
    "{ p_{(n)(m)} } \n",
    "&= \\frac {np.exp \\left( \n",
    "    { a_{(n)(m) } } - { c_{(n)} }) \\right) \n",
    "}\n",
    "{  \n",
    "np.sum \\left( \n",
    "    np.exp \\left( \n",
    "        a_{(n)(m) } - c_{(n)}\n",
    "    \\right)\n",
    "\\right) \n",
    "}\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient dL/dA\n",
    "\n",
    "Impact on L by dA from the activation layer.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset { (N,M) }{ \\frac {\\partial L }{\\partial A} }\n",
    "= \\overset { (N,M) }{ \\frac {\\partial L}{\\partial P} }\n",
    "* \n",
    "\\overset { (N,M) }{ \\frac {\\partial P }{\\partial A} } \n",
    "= \n",
    "\\frac {1}{N} (P - T)\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "$\n",
    "Jacobian \\; : \\; f \\circ g \\rightarrow Jf \\circ Jg\n",
    "\\\\\n",
    "\\begin{align*}\n",
    "\\\\\n",
    "L &= f(\\; p_{(n)(m=0)} \\;) = f( \\; g(\\;  a_{(n)(m=0)} \\; ) \\; ) \\quad : p = g(a) = softmax(a)\n",
    "\\\\\n",
    "\\frac {\\partial L} { \\partial a_{(n)(m=0)} }\n",
    "&= Jf(p) \\circ Jg(a) \n",
    "=  \\frac {\\partial L} { \\partial p_{(n)(m=0)} } * \\frac {\\partial  p_{(n)(m=0)}} { \\partial a_{(n)(m=0)} }\n",
    "\\\\\n",
    "&= \\frac {1}{N} \\left(\n",
    " p_{(n)(m=0)} -t_{(n)(m=0)}\n",
    "\\right)\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient from cross entropy log loss\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\frac { \\partial L }{ \\partial  p_{(n)(m=0)} }\n",
    "&= \\frac{-1}{N} t_{(n)(m=0)} * \\frac {s_{(n)}}{e_{(n)(m=0)}}\n",
    "\\\\\n",
    "\\frac { \\partial L }{ \\partial  p_{(n)(m=1)} } \n",
    "&= \\frac{-1}{N} t_{(n)(m=1)} * \\frac {s_{(n)}}{e_{(n)(m=1)}}\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Gradient $\\frac { \\partial  L } { \\partial s^{-1}_{(n)} } $\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "p_{(n)(m=0)} &= \\frac {e_{(n)(m=0)} }{ s_{(n)} } \\\\\n",
    "p_{(n)(m=0)} &= f \\circ g_{(m=0)} = { s^{-1}_{(n)} } \\; * \\; { e_{(n)(m=0)} }\n",
    "\\rightarrow \\frac { \\partial  p_{(n)(m=0)} } { \\partial s^{-1}_{(n)} } = e_{(n)(m=0)}\n",
    "\\\\\n",
    "p_{(n)(m=1)} &= \\frac {e_{(n)(m=1)} }{ s_{(n)} } \\\\\n",
    "p_{(n)(m=1)} &= f \\circ g_{(m=1)} = { s^{-1}_{(n)} } \\; * \\; { e_{(n)(m=1)} }\n",
    "\\rightarrow \\frac { \\partial  p_{(n)(m=1)} } { \\partial s^{-1}_{(n)} } = e_{(n)(m=1)}\n",
    "\\\\\n",
    "\\frac { \\partial  L } { \\partial s^{-1}_{(n)} } \n",
    "&=\n",
    "\\left[\n",
    "    \\frac { \\partial  p_{(n)(m=0)} } { \\partial s^{-1}_{(n)} } * \n",
    "    \\frac { \\partial L }{ \\partial  p_{(n)(m=0)} } \n",
    "    +\n",
    "    \\frac { \\partial  p_{(n)(m=1)} } { \\partial s^{-1}_{(n)} } * \n",
    "    \\frac { \\partial L }{ \\partial  p_{(n)(m=1)} } \n",
    "\\right]\n",
    "\\\\\n",
    "&= \\sum\\limits^{M-1}_{m=0} \n",
    "    e_{(n)(m)}  * \\frac { \\partial L }{ \\partial  p_{(n)(m)} } \n",
    "\\\\\n",
    "\\\\\n",
    "\\frac { \\partial  L } { \\partial s^{-1}_{(n)} } \n",
    "&=\n",
    "    \\begin{bmatrix}\n",
    "    e_{(n)(m=0)}  * \\frac { \\partial L }{ \\partial  p_{(n)(m=0)} } \\\\\n",
    "    + \\\\\n",
    "    e_{(n)(m=1)}  * \\frac { \\partial L }{ \\partial  p_{(n)(m=1)} } \n",
    "    \\end{bmatrix}\n",
    "\\\\\n",
    "&= -s_{(n)}(\\; t_{(n)(m=0)} + t_{(n)(m=1)} \\;) \\\\\n",
    "&= -s_{(n)}\n",
    "\\\\\n",
    "\\frac { \\partial  L } { \\partial s^{-1}_{(n)} } \n",
    "&=\n",
    "\\left[\n",
    "    e_{(n)(m=0)}  * \\frac { \\partial L }{ \\partial  p_{(n)(m=0)} } \n",
    "    + \n",
    "    e_{(n)(m=1)}  * \\frac { \\partial L }{ \\partial  p_{(n)(m=1)} } \n",
    "\\right]\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient $\\frac {\\partial L }{ \\partial { s_{(n)} } } $\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\frac {1} { s_{(n)} } &= s^{-1}_{(n)} \\rightarrow\n",
    "\\frac { \\partial { s^{-1}_{(n)} } } {\\partial s_{(n)}} = \\frac {-1}{s^{2}_{(n)}}\n",
    "\\\\\n",
    "\\frac {\\partial L }{ \\partial { s_{(n)} } } \n",
    "&=\n",
    "\\frac {-1}{s^{2}_{(n)}} * \n",
    "\\frac {\\partial L}{ \\partial s^{-1}_{(n)} } \\\\\n",
    "&= \\frac {1}{s_n}\n",
    "\\end{align*} \\\\\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gradient $\\frac {\\partial L}{ \\partial e_{(n)(m=0)} } $\n",
    "$\n",
    "\\begin{align*}\n",
    "s_{(n)} &= \\sum\\limits ^{M-1}_{m=0} e_{(n)(m)} \\rightarrow \n",
    "\\frac { \\partial { s_{(n)} } } {\\partial e_{(n)(m=0)}} = 1\n",
    "\\\\\n",
    "p_{(n)(m=0)} &= \\frac {e_{(n)(m=0)} }{ s_{(n)} }\\rightarrow \n",
    "\\frac { \\partial { p_{(n)(m=0)} } } {\\partial e_{(n)(m=0)}} = \\frac {1}{s_{(n)}}\n",
    "\\\\\n",
    "\\frac {\\partial L}{ \\partial e_{(n)(m=0)} } \n",
    "&= \\begin{bmatrix}  \n",
    "    \\frac { \\partial { s_{(n)} } } {\\partial e_{(n)(m=0)}} *  \n",
    "    \\frac {\\partial L }{ \\partial { s_{(n)} } } \\\\\n",
    "    + \\\\\n",
    "    \\frac { \\partial { p_{(n)(m=0)} } } {\\partial e_{(n)(m=0)}} * \n",
    "    \\frac {\\partial L }{ \\partial p_{(n)(m=0)} } \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}  \n",
    "    \\frac {\\partial L }{ \\partial { s_{(n)} } } \\\\\n",
    "    + \\\\\n",
    "    \\frac {1}{s_{(n)}} * \n",
    "    \\frac {\\partial L }{ \\partial p_{(n)(m=0)} } \n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\frac {\\partial L}{ \\partial e_{(n)(m=0)} } &= \n",
    "\\left[\n",
    "    \\frac {1}{s_{(n)}} * \n",
    "    \\frac {\\partial L }{ \\partial p_{(n)(m=0)} } \n",
    "    + \n",
    "    \\frac {\\partial L }{ \\partial { s_{(n)} } } \n",
    "\\right]\n",
    "\\\\\n",
    "\\frac {\\partial L}{ \\partial e_{(n)(m=0)} } &= \n",
    "\\begin{bmatrix}  \n",
    "    \\frac {1}{s_{(n)}} * \n",
    "    \\frac {\\partial L }{ \\partial p_{(n)(m=0)} }  \\\\\n",
    "    +  \\\\\n",
    "    \\frac {\\partial L }{ \\partial s_{(n)} } \n",
    "\\end{bmatrix} \\\\\n",
    "&= \\frac {-t_{(n)(m=0)}}{e_{(n)(m=0)} } + \\frac {1}{s_{n}}\n",
    "\\end{align*}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gardient $\\frac {\\partial L}{ \\partial a_{(n)(m=0)} } $\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "e_{(n)(m)} &= exp(\\; a_{(n)(m)} \\; ) \\rightarrow \\frac { \\partial e_{(n)(m)} }{ \\partial a_{(n)(m)} } = e_{(n)(m)} \n",
    "\\\\\n",
    "e_{(n)(m=0)} &= exp(a_{(n)(m=0)}) \\rightarrow \\frac { \\partial e_{(n)(m=0)} }{ \\partial a_{(n)(m=0)} } = e_{(n)(m=0)} \n",
    "\\\\\n",
    "e_{(n)(m=1)} &= exp(a_{(n)(m=1)}) \\\\\n",
    "\\frac {\\partial L}{ \\partial a_{(n)(m=0)} } \n",
    "&=   \\frac { \\partial e_{(n)(m=0)} }{ \\partial a_{(n)(m=0)} } * \n",
    "    \\frac { \\partial L }{ \\partial e_{(n)(m=0)} } \n",
    "= e_{(n)(m=0)} * \\frac { \\partial L }{ \\partial e_{(n)(m=0)} } \n",
    "\\\\\n",
    "\\frac {\\partial L}{ \\partial a_{(n)(m=0)} } \n",
    "&= e_{(n)(m=0)} * \\frac { \\partial L }{ \\partial e_{(n)(m=0)} } \\\\\n",
    "&= -t_{(n)(m=0)} + \\frac { e_{(n)(m=0)} }{ s_{n} } \\\\\n",
    "&= p_{(n)(m=0)} -t_{(n)(m=0)} \n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Log Loss\n",
    "\n",
    "A probability distribution $P(x)$ can be represented with its entropy $E(x) = \\sum\\limits_{x}  \\frac {p(x)}{log(p(x)} = - \\sum\\limits_{x} p(x) log(p(x))$. In the diagram, x: (0:dog, 1:cat, 2:fish, 3:bird) are labels and p(dog) is 0.5. When  a NN predicts an input x as a probability distribution $P(x)$, then the $E(x) = 1.75$. \n",
    "\n",
    "0. $p(dog)=\\frac {1}{2}$\n",
    "1. $p(cat)=\\frac {1}{4}$\n",
    "2. $p(fish)=\\frac {1}{8}$\n",
    "3. $p(bird)=\\frac {1}{8}$\n",
    "\n",
    "When the truth is that x is a dog, then the probability distribution of the truth $P(t)$ has the entropy $E(t) = 0$.\n",
    "\n",
    "0. $p(dog)=1$\n",
    "1. $p(cat)=0$\n",
    "2. $p(fish)=0$\n",
    "3. $p(bird)=0$\n",
    "\n",
    "The difference E(x) - E(t) = E(x) = 1.75 can be used as the distance or the error of the prediction from the truth. Need to understand further but  the actuall loss function is $E(x) = -tlog(p(x)) = -log(p(x))$ where p(x) is the probability from the softmax for the correct label.\n",
    "\n",
    "\n",
    "<img src=\"image/entropy.png\" align=\"left\" width=600/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.log() is ln based on the mathematical constant $e$ and its derivative $\\frac {\\partial log(x)}{\\partial x} = \\frac {1}{x}$.\n",
    "\n",
    "* [Logarithm](https://en.wikipedia.org/wiki/Logarithm)\n",
    "\n",
    "\n",
    "<img src=\"image/logarithm_plots.png\" align=\"left\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [ML Grossary - Loss Functions](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n",
    "\n",
    "<img src=\"image/cross_entropy_log_loss.png\" align=\"left\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cross_entropy_log_loss_input_combinations.xlsx](./common/cross_entropy_log_loss_input_combinations.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def cross_entropy_log_loss(\n",
      "        P: Union[np.ndarray, float],\n",
      "        T: Union[np.ndarray, int],\n",
      "        f: Callable = categorical_log_loss,\n",
      "        offset: float = OFFSET_LOG\n",
      ") -> np.ndarray:\n",
      "    \"\"\"Cross entropy log loss [ -t(n)(m) * log(p(n)(m)) ] for multi labels.\n",
      "    Assumption:\n",
      "        Label is integer 0 or 1 for an OHE label and any integer for an index label.\n",
      "\n",
      "    NOTE:\n",
      "        Handle only the label whose value is True. The reason not to use non-labels to\n",
      "        calculate the loss is TBD.\n",
      "\n",
      "    Args:\n",
      "        P: probabilities of shape (N,M) from soft-max layer where:\n",
      "            N is Batch size\n",
      "            M is Number of nodes\n",
      "        T: label either in OHE format of shape (N,M) or index format of shape (N,).\n",
      "           OHE: One Hot Encoding\n",
      "        f: Cross entropy log loss function\n",
      "        offset: small number to avoid np.inf by log(0) by log(0+offset)\n",
      "\n",
      "    Returns:\n",
      "        J: Loss value of shape (N,), a loss value per batch.\n",
      "    \"\"\"\n",
      "    name = \"cross_entropy_log_loss\"\n",
      "    P, T = transform_X_T(P, T)\n",
      "\n",
      "    if P.ndim == 0:\n",
      "        assert False, \"P.ndim needs (N,M) after transform_X_T(P, T)\"\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # P is scalar, T is a scalar binary OHE label. Return -t * log(p).\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # assert T.ndim == 0, \"P.ndim==0 requires T.ndim==0 but %s\" % T.shape\n",
      "        # return f(P, T, offset)\n",
      "\n",
      "    if (1 < P.ndim == T.ndim) and (P.shape[1] == T.shape[1] == 1):\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # This condition X:(N,1), T(N,1) tells T is the 2D binary OHE labels.\n",
      "        # T is 2D binary OHE labels e.g. T[[0],[1],[0]], P[[0.9],[0.1],[0.3]].\n",
      "        # Return -T * log(P)\n",
      "        # --------------------------------------------------------------------------------\n",
      "        return np.squeeze(f(P=P, T=T, offset=offset), axis=-1)    # Shape from (N,M) to (N,)\n",
      "\n",
      "    # ================================================================================\n",
      "    # Calculate Cross entropy log loss -t * log(p).\n",
      "    # Select an element P[n][t] at each row n which corresponds to the true label t.\n",
      "    # Use the Numpy tuple indexing. e.g. P[n=0][t=2] and P[n=3][t=4].\n",
      "    # P[\n",
      "    #   (0, 3),\n",
      "    #   (2, 4)     # The tuple sizes must be the same at all axes\n",
      "    # ]\n",
      "    #\n",
      "    # Tuple indexing selects only one element per row.\n",
      "    # Beware the numpy behavior difference between P[(n),(m)] and P[[n],[m]].\n",
      "    # https://stackoverflow.com/questions/66269684\n",
      "    # P[1,1]  and P[(0)(0)] results in a scalar value, HOWEVER, P[[1],[1]] in array.\n",
      "    #\n",
      "    # P shape can be (1,1), (1, M), (N, 1), (N, M), hence P[rows, cols] are:\n",
      "    # P (1,1) -> P[rows, cols] results in a 1D of  (1,).\n",
      "    # P (1,M) -> P[rows, cols] results in a 1D of  (1,)\n",
      "    # P (N,1) -> P[rows, cols] results in a 1D of  (N,)\n",
      "    # P (N,M) -> P[rows, cols] results in a 1D of  (N,)\n",
      "    #\n",
      "    # J shape matches with the P[rows, cols] shape.\n",
      "    # ================================================================================\n",
      "    N = batch_size = P.shape[0]\n",
      "    rows = np.arange(N)     # (N,)\n",
      "    cols = T                # Same shape (N,) with rows\n",
      "    assert rows.shape == cols.shape, \\\n",
      "        f\"np P indices need the same shape but rows {rows.shape} cols {cols.shape}.\"\n",
      "\n",
      "    _P = P[rows, cols]\n",
      "    Logger.debug(\"%s: N is [%s]\", name, N)\n",
      "    Logger.debug(\"%s: P.shape %s\", name, P.shape)\n",
      "    Logger.debug(\"%s: P[rows, cols].shape %s\", name, _P.shape)\n",
      "    Logger.debug(\"%s: P[rows, cols] is %s\", name, _P)\n",
      "\n",
      "    J = f(P=_P, T=int(1), offset=offset)\n",
      "\n",
      "    assert not np.all(np.isnan(J)), \"log(x) caused nan for P \\n%s.\" % P\n",
      "    Logger.debug(\"%s: J is [%s]\", name, J)\n",
      "    Logger.debug(\"%s: J.shape %s\\n\", name, J.shape)\n",
      "\n",
      "    assert (J.ndim > 0) and (0 < N == J.shape[0]), \\\n",
      "        \"Loss J.shape is expected to be (%s,) but %s\" % (N, J.shape)\n",
      "    return J\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from common import (\n",
    "    cross_entropy_log_loss,\n",
    "    OFFSET_LOG\n",
    ")\n",
    "lines = inspect.getsource(cross_entropy_log_loss)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For label using One Hot Encoding (OHE)\n",
    "For instance, if multi labels are (0,1,2,3,4) and each label is OHE, then the label for 2 is (0,0,1,0,0).   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product of matrix rows\n",
    "\n",
    "There is no formal operation to calculate the dot products of the rows from two matrices, but to calculate the diagonal of the matlix multiplication that also calculate non-diagonals. To avoid calculating non-diagonals, use [einsum](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html).\n",
    "\n",
    "* [Name of matrix operation of ```[A[0] dot B[0], A[1] dot B[1] ]``` from 2x2 matrices A, B](https://math.stackexchange.com/questions/4010721/name-of-matrix-operation-of-a0-dot-b0-a1-dot-b1-from-2x2-matrices-a)\n",
    "\n",
    "<img src=\"image/dot_products_of_matrix_rows.png\" align=\"left\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is \n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "b.T is \n",
      "[[ 0 -3]\n",
      " [-1 -4]\n",
      " [-2 -5]]\n",
      "\n",
      "c[\n",
      "    np.inner(a[0], b[0]),\n",
      "    np.inner(a[1], b[1]),    \n",
      "] is [-5, -50]\n",
      "\n",
      "\n",
      "np.einsum('ij,ji->i', a, b.T) is [ -5 -50]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(6).reshape(2,3)\n",
    "b = np.arange(0,-6,-1).reshape(2,3)\n",
    "c = [\n",
    "    np.inner(a[0], b[0]),\n",
    "    np.inner(a[1], b[1]),    \n",
    "]\n",
    "print(f\"a is \\n{a}\")\n",
    "print(f\"b.T is \\n{b.T}\\n\")\n",
    "fmt=f\"\"\"c[\n",
    "    np.inner(a[0], b[0]),\n",
    "    np.inner(a[1], b[1]),    \n",
    "] is {c}\\n\n",
    "\"\"\"\n",
    "print(fmt)\n",
    "\n",
    "# Use einsum\n",
    "e = np.einsum('ij,ji->i', a, b.T)\n",
    "fmt=\"np.einsum('ij,ji->i', a, b.T)\"\n",
    "print(f\"{fmt} is {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foward path (OHE)\n",
    "$\n",
    "\\text{ for one hot encoding labels }\n",
    "\\\\\n",
    "\\begin{align*}\n",
    "\\overset{ (N,) }{ J } &= - \\sum\\limits^{M-1}_{m=0} \n",
    "    \\left[ \\; \\;  \n",
    "        t_{(n)(m)} \\;  * \\;  np.log(p_{(n)(m)}) \\;\\;  \n",
    "    \\right]\n",
    "\\\\\n",
    "\\overset{ () }{ j_{(n)} } &= \\overset{ (M,) }{ T_{(n)} } \\cdot \\overset{ (M,) }{ P_{(n)} } \n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient dL/dP\n",
    "\n",
    "Impact on L by the $dP$ from the softmax layer for one hot encoding labels.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset { (N,M) }{ \\frac { \\partial L }{ \\partial P} }\n",
    "&= \\overset { (N,) }{ \\frac { \\partial L }{ \\partial J} } * \n",
    "\\overset { (N,M) }{ \n",
    "\\left(\n",
    " - \\frac { \\partial T } { \\partial P }\n",
    " \\right) \n",
    "} \n",
    "= - \\frac {1}{N }  \\frac { \\partial T } { \\partial P }\n",
    "\\\\\n",
    "\\frac {\\partial L }{\\partial p_{(n)(m=0)}} \n",
    "&= \\frac {\\partial L}{\\partial j_{(n)}} * \\frac {\\partial j_{(n)}} {\\partial p_{(n)(m=0)}} \n",
    "= \\frac {1}{N} \\frac { -t_{(n)(m=0)}}{ p_{(n)(m=0)} } \n",
    "=  \\frac {1}{N} \\left(\n",
    " -t_{(n)(m=0)} * \\frac { s_{(n)} }{ e_{(n)(m=0)} }\n",
    "\\right)\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For label using indexing \n",
    "For instance, if the multi labels are (0,1,2,3,4) then the index is 2 for the label 2. If the labels are (2,4,6,8,9), then the index is 3 for the label 8.  \n",
    "\n",
    "Use LP to select the probabilities from P for the corresponding labels. For instance, if the label is 2 (hence the index is 2) for X(n=0), and 4 for X(n=3), then the numpy tuple indexing selects ```P[n=0][m=2]``` and ```P[n=3][m=4] ```.\n",
    "\n",
    "```\n",
    "P[\n",
    "   (0, 3),\n",
    "   (2, 4)\n",
    "]\n",
    "```\n",
    "\n",
    "$\n",
    "\\text{ for index labels e.g. (5, 2, 0, 9, ...)}\n",
    "\\\\\n",
    "\\\\\n",
    "\\overset{ (N,) }{ J } = - np.sum(\\; np.log(LP), \\; axis = -1 \\;) \\\\\n",
    "LP = label\\_probability = P \\left[ \\\\\n",
    "\\quad ( \\; 0, \\; \\dots, \\;  {N-1}) , \\\\\n",
    "\\quad ( \\; t_{(n=0)} \\; , \\dots , \\; t_{(n=N-1)}) \\\\\n",
    "\\right]\n",
    "\\\\\n",
    "\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward path\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset{ () }{ L } = \\frac {1}{N} \\sum\\limits^{N-1}_{n=0} \\overset{ () }{ j_{{(n)}} }\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gardient dL/dJ\n",
    "\n",
    "Impact on L by $dJ$ from the cross entropy log loss layer.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\overset { (N,) }{ \\frac {\\partial L}{\\partial J} }  &= \\frac {1}{N} \\overset{(N,)}{ones}\n",
    "\\\\\n",
    "\\frac {\\partial L}{\\partial j_{(n)} } &= \\frac {1}{N} \n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ = np.ones(N) / N\n",
    "dJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [two_layer_net.ipynb defines the lambda with parameter W which is redundant #254](https://github.com/cs231n/cs231n.github.io/issues/254)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```numerical_jacobian(f, X)``` returns ```J``` of the same shape with ```X```. It takes each element in ```x``` in ```X```, and calculate ```(f(x+h) and f(x-h))/2h```. For ```cross_entropy_logg_loss()```, the expected numerical gradient is ```gn = (-np.log(p+h+e) + -np.log(p-h+e)) / (2*h)``` for each element ```p``` in ```P```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def numerical_jacobian(\n",
      "        f: Callable[[np.ndarray], np.ndarray],\n",
      "        X: Union[np.ndarray, float],\n",
      "        delta: float = OFFSET_DELTA\n",
      ") -> np.ndarray:\n",
      "    \"\"\"Calculate Jacobian matrix J numerically with (f(X+h) - f(X-h)) / 2h\n",
      "    Jacobian matrix element Jpq = df/dXpq, the impact on J by the\n",
      "    small difference to Xpq where p is row index and q is col index of J.\n",
      "\n",
      "    Note:\n",
      "        Beware limitations by the float storage size, e.g. loss of significance.\n",
      "        https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html\n",
      "        https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/Contents/\n",
      "        https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/02Numerics/Weaknesses/\n",
      "        https://www.cise.ufl.edu/~mssz/CompOrg/CDA-arith.html\n",
      "\n",
      "    Args:\n",
      "        f: Y=f(X) where Y is a scalar or shape() array.\n",
      "        X: input of shame (N, M), or (N,) or ()\n",
      "        delta: small delta value to calculate the f value for X+/-h\n",
      "    Returns:\n",
      "        J: Jacobian matrix that has the same shape of X.\n",
      "    \"\"\"\n",
      "    name = \"numerical_jacobian\"\n",
      "    X = np.array(X, dtype=float) if isinstance(X, (float, int)) else X\n",
      "    J = np.zeros_like(X, dtype=float)\n",
      "\n",
      "    # --------------------------------------------------------------------------------\n",
      "    # (x+h) or (x-h) may cause an invalid value area for the function f.\n",
      "    # e.g log loss tries to offset x=0 by adding a small value k as log(0+k).\n",
      "    # However because k=1e-7 << h=1e-5, f(x-h) causes nan due to log(x < 0)\n",
      "    # as x needs to be > 0 for log.\n",
      "    #\n",
      "    # X and tmp must be float, or it will be int causing float calculation fail.\n",
      "    # e.g. f(1-h) = log(1-h) causes log(0) instead of log(1-h).\n",
      "    # --------------------------------------------------------------------------------\n",
      "    assert (X.dtype == float), \"X must be float type\"\n",
      "    assert delta > 0.0\n",
      "\n",
      "    it = np.nditer(X, flags=['multi_index'], op_flags=['readwrite'])\n",
      "    while not it.finished:\n",
      "        idx = it.multi_index\n",
      "        tmp: float = X[idx]\n",
      "\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # f(x+h)\n",
      "        # --------------------------------------------------------------------------------\n",
      "        X[idx] = tmp + delta\n",
      "        fx1: Union[np.ndarray, float] = f(X)  # f(x+h)\n",
      "        Logger.debug(\n",
      "            \"%s: idx[%s] x[%s] (x+h)[%s] fx1=[%s]\",\n",
      "            name, idx, tmp, tmp+delta, fx1\n",
      "        )\n",
      "\n",
      "        assert \\\n",
      "            ((isinstance(fx1, np.ndarray) and fx1.size == 1) or isinstance(fx1, float)), \\\n",
      "            \"The f function needs to return scalar or shape () but %s\" % fx1\n",
      "        assert np.isfinite(fx1), \\\n",
      "            \"f(x+h) caused nan for f %s for X %s\" % (f, (tmp + delta))\n",
      "\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # f(x-h)\n",
      "        # --------------------------------------------------------------------------------\n",
      "        X[idx] = tmp - delta\n",
      "        fx2: Union[np.ndarray, float] = f(X)\n",
      "        Logger.debug(\n",
      "            \"%s: idx[%s] x[%s] (x-h)[%s] fx2=[%s]\",\n",
      "            name, idx, tmp, tmp-delta, fx2\n",
      "        )\n",
      "        assert \\\n",
      "            ((isinstance(fx2, np.ndarray) and fx2.size == 1) or isinstance(fx2, float)), \\\n",
      "            \"The f function needs to return scalar or shape () but %s\" % fx2\n",
      "        assert np.isfinite(fx2), \\\n",
      "            \"f(x-h) caused nan for f %s for X %s\" % (f, (tmp - delta))\n",
      "\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # When f(x+k) and f(x-k) are relatively too close, subtract between them can ben\n",
      "        # too small, and the precision error 1/f(x) relative to f(x+k) and f(x-k) is much\n",
      "        # larger relative to that of f(x+k) or f(x-k), hence the result can be unstable.\n",
      "        # Prevent the subtract df(x) from being too small to f(x) by assuring df(x)/dx is\n",
      "        # greater than GN_DIFF_ACCEPTANCE_RATIO.\n",
      "        #\n",
      "        # e.g. For logistic log loss function f(x) with log(+1e-7) to avoid log(0)/inf.\n",
      "        # x[14.708627877981929] (x+h)[14.708627878981929] fx1=[14.708628288297405]\n",
      "        # x[14.708627877981929] (x-h)[14.708627876981929] fx2=[14.708628286670217]\n",
      "        # (fx1-fx2)=[1.6271872738116144e-09]\n",
      "        # (fx1-fx2) / fxn < 1e-10. The difference is relatively too small to f(x).\n",
      "        #\n",
      "        #\n",
      "        # If the gradient of f(x) at x is nearly zero, or saturation, then reconsider\n",
      "        # if using the numerical gradient is fit for the purpose. Prevent the gradient\n",
      "        # from being too close to zero by f(x+k)-f(x-k) > GN_DIFF_ACCEPTANCE_VALUE\n",
      "        # --------------------------------------------------------------------------------\n",
      "        Logger.debug(\"%s: (fx1-fx2)=[%s]\", name, (fx1-fx2))\n",
      "        difference = np.abs(fx1 - fx2)\n",
      "        subtract_cancellation_condition = (\n",
      "                (difference < (fx1 * GN_DIFF_ACCEPTANCE_RATIO)) or\n",
      "                (difference < (fx2 * GN_DIFF_ACCEPTANCE_RATIO))\n",
      "        )\n",
      "        if subtract_cancellation_condition:\n",
      "            fmt = \"%s; (fx1-fx2) / fxn > %s to avoid subtract cancellation but %s. GN is %s\"\n",
      "            args = tuple([\n",
      "                name,\n",
      "                GN_DIFF_ACCEPTANCE_RATIO,\n",
      "                difference,\n",
      "                (fx1-fx2) / (2 * delta)\n",
      "            ])\n",
      "            Logger.warning(fmt, *args)\n",
      "            assert \\\n",
      "                ENFORCE_STRICT_ASSERT and subtract_cancellation_condition, \\\n",
      "                fmt % args\n",
      "\n",
      "        # --------------------------------------------------------------------------------\n",
      "        # Set the gradient element scalar value or shape()\n",
      "        # --------------------------------------------------------------------------------\n",
      "        g: Union[np.ndarray, float] = np.subtract(fx1, fx2) / (2 * delta)\n",
      "        assert np.isfinite(g)\n",
      "\n",
      "        gradient_saturation_condition = (np.abs(g) < GRADIENT_SATURATION_THRESHOLD)\n",
      "        if gradient_saturation_condition:\n",
      "            msg = \"%s: The gradient [%s] should be saturated.\"\n",
      "            Logger.warning(msg, name, g)\n",
      "            assert ENFORCE_STRICT_ASSERT, msg % (name, g)\n",
      "\n",
      "        J[idx] = g\n",
      "        Logger.debug(\"%s: idx[%s] j=[%s]\", name, idx, g)\n",
      "\n",
      "        X[idx] = tmp\n",
      "        it.iternext()\n",
      "\n",
      "    return J\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from common import (\n",
    "    numerical_jacobian,\n",
    "    OFFSET_DELTA\n",
    ")\n",
    "lines = inspect.getsource(numerical_jacobian)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected numerical gradient=-1.1591416437806146\n",
      "Actual numerical gradient=[-1.15914178]\n",
      "Expected analytical gradient -T/P=-1.1591416792330183\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Example gradients for the cross entropy log loss -t*log(p).\n",
    "# --------------------------------------------------------------------------------\n",
    "p =0.86270721\n",
    "h = OFFSET_DELTA\n",
    "e = OFFSET_LOG\n",
    "\n",
    "expected_gn = (-np.log(p+h+e) + np.log(p-h+e)) / (2*h)\n",
    "actual_gn = (cross_entropy_log_loss(p+h, 1) - cross_entropy_log_loss(p-h, 1)) / (2*h)\n",
    "print(f\"Expected numerical gradient={expected_gn}\")\n",
    "print(f\"Actual numerical gradient={actual_gn}\")\n",
    "print(f\"Expected analytical gradient -T/P={-1 / (p+e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.96369904])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.50924298 \n",
    "gn = (cross_entropy_log_loss(p+h, 1) - cross_entropy_log_loss(p-h, 1)) / (2*h)\n",
    "gn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Matmul binary classification (logisitc regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (500, 3) T.shape (500,) W [ 0.52143852  0.25871212 -0.81312355]\n"
     ]
    }
   ],
   "source": [
    "MAX_TEST_TIMES = 100\n",
    "N = 500\n",
    "D = 3\n",
    "M = 1\n",
    "from data.classifications import (\n",
    "    linear_separable\n",
    ")\n",
    "X, T, V = linear_separable(d=D, n=N)\n",
    "print(f\"X.shape {X.shape} T.shape {T.shape} W {V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[T==0, 1], X[T==0, 2], c='red')\n",
    "plt.scatter(X[T==1, 1], X[T==1, 2], c='green')\n",
    "\n",
    "# Hyperplace (X-b)V = 0 -> x1V1 + x2V2 - bV2 = 0\n",
    "x = np.linspace(-3,3,100)\n",
    "y = -(V[1] / V[2]) * x - (V[0] / V[2])\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Optional,\n",
    "    Union,\n",
    "    List,\n",
    "    Dict,\n",
    "    Tuple,\n",
    "    Callable\n",
    ")\n",
    "import logging\n",
    "import copy\n",
    "import numpy as np\n",
    "from common import (\n",
    "    OFFSET_LOG,\n",
    "    OFFSET_DELTA,\n",
    "    numerical_jacobian,\n",
    "    weights,\n",
    "    random_string,\n",
    "    softmax,\n",
    "    sigmoid,\n",
    "    cross_entropy_log_loss,\n",
    "    logistic_log_loss\n",
    ")\n",
    "from layer import (\n",
    "    Matmul,\n",
    "    CrossEntropyLogLoss\n",
    ")\n",
    "from optimizer import(\n",
    "    SGD\n",
    ")\n",
    "from data.classifications import (\n",
    "    linear_separable\n",
    ")\n",
    "from network.test_020_binary_classifier import (\n",
    "    train_binary_classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"431.1111225316557\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel('x label')  # Add an x-label to the axes.\n",
    "ax.set_ylabel('y label')  # Add a y-label to the axes.\n",
    "\n",
    "\n",
    "def draw_training(W, colors=['b']):\n",
    "    w0 = W[0]\n",
    "    w1 = W[1]\n",
    "    w2 = W[2]\n",
    "    \n",
    "    ax.set_title(label=str(W))\n",
    "    ax.scatter(X[T==0, 1], X[T==0, 2], c='red')\n",
    "    ax.scatter(X[T==1, 1], X[T==1, 2], c='green')\n",
    "    x = np.linspace(-3,3,100)\n",
    "    if ax.lines:\n",
    "        for line in ax.lines:\n",
    "            line.set_xdata(x)\n",
    "            y = -w1/w2 * x - w0 / w2\n",
    "            line.set_ydata(y)\n",
    "    else:\n",
    "        for color in colors:\n",
    "            y = -w1/w2 * x - w0 / w2\n",
    "            ax.plot(x, y, color)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    _x = np.linspace(-3,3,100)\n",
    "    _y = -w1/w2 * x - w0 / w2\n",
    "    plt.plot(_x, _y, label='linear')  # Plot some data on the axes.\n",
    "\n",
    "    ax.legend()  # Add a legend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "Logger = logging.getLogger(\"test_020_matmul_methods\")\n",
    "Logger.setLevel(logging.INFO)\n",
    "\n",
    "W = weights.he(M, D)\n",
    "optimizer = SGD(lr=0.1)\n",
    "train_binary_classifier(\n",
    "    N=N,\n",
    "    D=D,\n",
    "    X=X,\n",
    "    T=T,\n",
    "    W=W,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=MAX_TEST_TIMES,\n",
    "    callback=draw_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[0]. Loss is [0.5724153798615018]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.48590037  0.35668928 -0.10832689]]\n",
      "0.5724153798615018\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[1]. Loss is [0.5610819825489035]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.49892584  0.35480972 -0.13865017]]\n",
      "0.5610819825489035\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[2]. Loss is [0.5502993705891872]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.51165295  0.35306614 -0.16823065]]\n",
      "0.5502993705891872\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[3]. Loss is [0.540035018924789]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.52409498  0.35145544 -0.1970939 ]]\n",
      "0.540035018924789\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[4]. Loss is [0.5302580442552121]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.53626465  0.34997432 -0.22526515]]\n",
      "0.5302580442552121\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[5]. Loss is [0.5209392257163813]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.54817414  0.34861929 -0.25276916]]\n",
      "0.5209392257163813\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[6]. Loss is [0.512050998270154]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.55983508  0.34738677 -0.27963012]]\n",
      "0.512050998270154\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[7]. Loss is [0.5035674244084946]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.57125851  0.34627307 -0.3058716 ]]\n",
      "0.5035674244084946\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[8]. Loss is [0.49546414919715925]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.58245494  0.34527446 -0.33151645]]\n",
      "0.49546414919715925\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[9]. Loss is [0.4877183430266185]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.59343431  0.34438722 -0.35658678]]\n",
      "0.4877183430266185\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[10]. Loss is [0.48030863576669003]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.60420606  0.34360759 -0.38110393]]\n",
      "0.48030863576669003\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[11]. Loss is [0.47321504537906955]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.6147791   0.34293186 -0.40508846]]\n",
      "0.47321504537906955\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[12]. Loss is [0.46641890345497217]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.62516185  0.34235638 -0.42856016]]\n",
      "0.46641890345497217\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[13]. Loss is [0.459902779626951]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.63536227  0.34187751 -0.451538  ]]\n",
      "0.459902779626951\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[14]. Loss is [0.45365040635893206]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.64538787  0.34149174 -0.4740402 ]]\n",
      "0.45365040635893206\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[15]. Loss is [0.44764660524487543]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.65524575  0.34119558 -0.49608422]]\n",
      "0.44764660524487543\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[16]. Loss is [0.44187721563884225]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.66494259  0.34098567 -0.51768678]]\n",
      "0.44187721563884225\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[17]. Loss is [0.4363290261903538]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.67448471  0.34085871 -0.53886387]]\n",
      "0.4363290261903538\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[18]. Loss is [0.43098970966083683]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.68387808  0.3408115  -0.55963081]]\n",
      "0.43098970966083683\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[19]. Loss is [0.42584776124181506]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.69312833  0.34084095 -0.58000224]]\n",
      "0.42584776124181506\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[20]. Loss is [0.42089244047605384]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.70224076  0.34094405 -0.59999214]]\n",
      "0.42089244047605384\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[21]. Loss is [0.4161137167925806]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.71122042  0.3411179  -0.61961389]]\n",
      "0.4161137167925806\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[22]. Loss is [0.41150221859976177]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.72007203  0.3413597  -0.63888029]]\n",
      "0.41150221859976177\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[23]. Loss is [0.4070491858326219]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.7288001   0.34166672 -0.65780355]]\n",
      "0.4070491858326219\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[24]. Loss is [0.4027464258173742]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.73740888  0.34203637 -0.67639537]]\n",
      "0.4027464258173742\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[25]. Loss is [0.3985862722944015]\n",
      "INFO:network.test_020_binary_classifier:W after is \n",
      "[[ 0.74590239  0.34246612 -0.6946669 ]]\n",
      "0.3985862722944015\n",
      "INFO:network.test_020_binary_classifier:network.test_020_binary_classifier: iteration[26]. Loss is [0.3945615474280387]\n",
      "*** KeyboardInterrupt exception caught in code being profiled.\n",
      "*** Profile printout saved to text file 'train_binary_classifier.log'. *** KeyboardInterrupt exception caught in code being profiled.\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 30.1522 s\n",
      "File: /home/oonisim/home/repository/git/oonisim/python_programs/nlp/src/network/test_020_binary_classifier.py\n",
      "Function: train_binary_classifier at line 41\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    41                                           def train_binary_classifier(\n",
      "    42                                                   N: int,\n",
      "    43                                                   D: int,\n",
      "    44                                                   X: np.ndarray,\n",
      "    45                                                   T: np.ndarray,\n",
      "    46                                                   W: np.ndarray,\n",
      "    47                                                   optimizer: Optimizer,\n",
      "    48                                                   num_epochs: int = 100,\n",
      "    49                                                   callback: Callable = None\n",
      "    50                                           ):\n",
      "    51                                               \"\"\"Test case for binary classification with matmul + logistic log loss.\n",
      "    52                                               Args:\n",
      "    53                                                   N: Batch size\n",
      "    54                                                   D: Number of features\n",
      "    55                                                   X: train data\n",
      "    56                                                   T: labels\n",
      "    57                                                   W: weight\n",
      "    58                                                   optimizer: Optimizer\n",
      "    59                                                   num_epochs: Number of epochs to run\n",
      "    60                                                   callback: callback function to invoke at the each epoch end.\n",
      "    61                                               \"\"\"\n",
      "    62         1          3.0      3.0      0.0      name = __name__\n",
      "    63         1          1.0      1.0      0.0      M = 1\n",
      "    64         1         18.0     18.0      0.0      assert isinstance(T, np.ndarray) and T.dtype == int and T.ndim == 1 and T.shape[0] == N\n",
      "    65         1          4.0      4.0      0.0      assert isinstance(X, np.ndarray) and X.dtype == float and X.ndim == 2 and X.shape[0] == N and X.shape[1] == D\n",
      "    66         1          3.0      3.0      0.0      assert isinstance(W, np.ndarray) and W.dtype == float and W.ndim == 2 and W.shape[0] == M and W.shape[1] == D\n",
      "    67         1          2.0      2.0      0.0      assert num_epochs > 0 and N > 0 and D > 0\n",
      "    68                                           \n",
      "    69         1         26.0     26.0      0.0      def objective_logloss(X: np.ndarray) -> Union[float, np.ndarray]:\n",
      "    70                                                   \"\"\"Dummy objective_logloss function to calculate the loss L\"\"\"\n",
      "    71                                                   assert X.ndim == 0, \"The output of the log loss should be of shape ()\"\n",
      "    72                                                   return X\n",
      "    73                                           \n",
      "    74                                               # --------------------------------------------------------------------------------\n",
      "    75                                               # Instantiate a CrossEntropyLogLoss layer\n",
      "    76                                               # --------------------------------------------------------------------------------\n",
      "    77         2        330.0    165.0      0.0      loss = CrossEntropyLogLoss(\n",
      "    78         1          2.0      2.0      0.0          name=\"loss\",\n",
      "    79         1          1.0      1.0      0.0          num_nodes=M,\n",
      "    80         1          2.0      2.0      0.0          activation=sigmoid,\n",
      "    81         1          4.0      4.0      0.0          log_level=logging.WARNING\n",
      "    82                                               )\n",
      "    83         1          8.0      8.0      0.0      loss.objective = objective_logloss\n",
      "    84                                           \n",
      "    85                                               # --------------------------------------------------------------------------------\n",
      "    86                                               # Instantiate a Matmul layer\n",
      "    87                                               # --------------------------------------------------------------------------------\n",
      "    88         2        180.0     90.0      0.0      matmul = Matmul(\n",
      "    89         1          1.0      1.0      0.0          name=\"matmul\",\n",
      "    90         1          1.0      1.0      0.0          num_nodes=M,\n",
      "    91         1          1.0      1.0      0.0          W=W,\n",
      "    92         1          1.0      1.0      0.0          optimizer=optimizer,\n",
      "    93         1          2.0      2.0      0.0          log_level=logging.WARNING\n",
      "    94                                               )\n",
      "    95         1          8.0      8.0      0.0      matmul.objective = loss.function\n",
      "    96                                           \n",
      "    97         1          2.0      2.0      0.0      history: List[float] = []\n",
      "    98        27         62.0      2.3      0.0      for i in range(num_epochs):\n",
      "    99                                                   # --------------------------------------------------------------------------------\n",
      "   100                                                   # Layer forward path\n",
      "   101                                                   # Calculate the matmul output Y=f(X), and get the loss L = objective(Y)\n",
      "   102                                                   # Test the numerical gradient dL/dX=matmul.gradient_numerical().\n",
      "   103                                                   # --------------------------------------------------------------------------------\n",
      "   104        27       8694.0    322.0      0.0          Y = matmul.function(X)\n",
      "   105        27       1170.0     43.3      0.0          loss.T = T\n",
      "   106        27      19086.0    706.9      0.1          L = loss.function(Y)\n",
      "   107        27         98.0      3.6      0.0          history.append(L)\n",
      "   108        27      46232.0   1712.3      0.2          Logger.info(\"%s: iteration[%s]. Loss is [%s]\", name, i, L)\n",
      "   109        27        660.0     24.4      0.0          if L > history[-1]:\n",
      "   110                                                       Logger.warning(\n",
      "   111                                                           \"Loss [%s] should decrease but increased from previous [%s]\",\n",
      "   112                                                           L, history[-1]\n",
      "   113                                                       )\n",
      "   114                                           \n",
      "   115                                                   # --------------------------------------------------------------------------------\n",
      "   116                                                   # Numerical gradient\n",
      "   117                                                   # --------------------------------------------------------------------------------\n",
      "   118        27   30012891.0 1111588.6     99.5          gn = matmul.gradient_numerical()\n",
      "   119                                           \n",
      "   120                                                   # --------------------------------------------------------------------------------\n",
      "   121                                                   # Layer backward path\n",
      "   122                                                   # Calculate the analytical gradient dL/dX=matmul.gradient(dL/dY) with a dummy dL/dY.\n",
      "   123                                                   # Confirm the numerical gradient (dL/dX, dL/dW) are closer to the analytical ones.\n",
      "   124                                                   # --------------------------------------------------------------------------------\n",
      "   125        26        878.0     33.8      0.0          before = copy.deepcopy(matmul.W)\n",
      "   126        26       2214.0     85.2      0.0          dY = loss.gradient(float(1))\n",
      "   127        26       2760.0    106.2      0.0          dX = matmul.gradient(dY)\n",
      "   128                                           \n",
      "   129                                                   # --------------------------------------------------------------------------------\n",
      "   130                                                   # Gradient update.\n",
      "   131                                                   # Run the gradient descent to update Wn+1 = Wn - lr * dL/dX.\n",
      "   132                                                   # Confirm the new objective L(Yn+1) < L(Yn) with the Wn+1.\n",
      "   133                                                   # Confirm W in the matmul has been updated by the gradient descent.\n",
      "   134                                                   # --------------------------------------------------------------------------------\n",
      "   135        26       4228.0    162.6      0.0          dS = matmul.update()  # Analytical dL/dX, dL/dW\n",
      "   136        26        443.0     17.0      0.0          assert not np.array_equal(before, matmul.W), \"W has not been updated. \\n%s\\n\"\n",
      "   137        26        697.0     26.8      0.0          assert np.all(np.abs(dS[0] - gn[0]) < 0.0001), \\\n",
      "   138                                                       \"dL/dX analytical gradient \\n%s \\nneed to close to numerical gradient \\n%s\\n\" \\\n",
      "   139                                                       % (dS[0], gn[0])\n",
      "   140        26        405.0     15.6      0.0          assert np.all(np.abs(dS[1] - gn[1]) < 0.0001), \\\n",
      "   141                                                       \"dL/dW analytical gradient \\n%s \\nneed to close to numerical gradient \\n%s\\n\" \\\n",
      "   142                                                       % (dS[1], gn[1])\n",
      "   143                                           \n",
      "   144        26      45164.0   1737.1      0.1          Logger.info(\"W after is \\n%s\", matmul.W)\n",
      "   145        26       5816.0    223.7      0.0          print(L)\n",
      "   146        26         74.0      2.8      0.0          if callback: callback(matmul.W[0])\n"
     ]
    }
   ],
   "source": [
    "%lprun \\\n",
    "    -T train_binary_classifier.log \\\n",
    "    -f train_binary_classifier \\\n",
    "train_binary_classifier(N=N,D=D,X=X,T=T,W=W,optimizer=optimizer,num_epochs=MAX_TEST_TIMES)\n",
    "\n",
    "print(open('train_binary_classifier.log', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
