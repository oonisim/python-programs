{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(linewidth=80) \n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRIDE size?2\n",
      "USE_PTB? Just enter for False or any string for True\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import (\n",
    "    DELIMITER,\n",
    "    SPACE,\n",
    "    NIL\n",
    ")\n",
    "\n",
    "STRIDE = int(input(\"STRIDE size?\"))\n",
    "CONTEXT_SIZE = 1 + (STRIDE * 2)\n",
    "\n",
    "USE_PTB = bool(input(\"USE_PTB? Just enter for False or any string for True\"))\n",
    "USE_NATIVE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "VALIDATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = \"The fool doth think he is wise, but the wise man knows himself to be a fool.\"\n",
    "#corpus = \"To be, or not to be, that is the question\"\n",
    "#corpus = \"To to be be, or not not not not not to be, that is that the question that matters\"\n",
    "corpus = \"To be, or not to be, that is the question that matters\"\n",
    "\n",
    "#corpus = \"I know how to build an attention in neural networks. But I don’t understand how attention layers learn the weights that pay attention to some specific embedding. I have this question because I’m tackling a NLP task using attention layer. I believe it should be very easy to learn (the most important part is to learn alignments). However, my neural networks only achieve 50% test set accuracy. And the attention matrix is weird. I don’t know how to improve my networks.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTB (Penn Treebank) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oonisim/dataset\n"
     ]
    }
   ],
   "source": [
    "from data.ptb import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid boundary checking when iterate through the sequenced corpus, pad the source text with '<nil>'.\n",
    "e.g. (when context is of size 5):    \n",
    "From:\n",
    "```\n",
    "|B|X|Y|Z|...|P|Q|R|E|\n",
    "```\n",
    "\n",
    "To:\n",
    "```\n",
    "|<nil>|<nil>|B|X|Y|Z|...|P|Q|R|E|<nil>|<nil>| \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.text import (\n",
    "    PAD_MODE_SQUEEZE,\n",
    "    pad_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word indexing\n",
    "Assign a numerical id to each word.\n",
    "\n",
    "The row index of co-occurrence matrix is a word index. The number of words in the corpus can be less than the number of word indices because additional meta-word such as OOV, UNK, NIL can be added to the original corpus.\n",
    "\n",
    "Make sure **the co-occurrence matrix row index matches with the word index**, unless explicitly adjust when row-index and word-index do not match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the corpus text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corpus: \n",
      "[To be, or not to be, that is the question that matters]\n",
      "Padded corpus: \n",
      "[<nil> <nil> To be, or not to be, that is the question that matters <nil> <nil>]\n"
     ]
    }
   ],
   "source": [
    "if USE_PTB:\n",
    "    corpus = pad_text(\n",
    "        corpus=load_text('train'), mode=PAD_MODE_SQUEEZE, delimiter=SPACE, padding=NIL, length=STRIDE\n",
    "    )\n",
    "else:\n",
    "    print(\"Original corpus: \\n[{}]\".format(corpus))\n",
    "    corpus = pad_text(\n",
    "        corpus=corpus, mode=PAD_MODE_SQUEEZE, delimiter=SPACE, padding=NIL, length=STRIDE\n",
    "    )\n",
    "    print(\"Padded corpus: \\n[{}]\".format(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.text import (\n",
    "    text_to_sequence\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = re.sub(r'[.,:;]+', SPACE, corpus.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9927\n"
     ]
    }
   ],
   "source": [
    "if USE_NATIVE:\n",
    "    (sequence, word_to_id, id_to_word, vocabulary_size) = native_word_indexing(corpus)\n",
    "\n",
    "print(vocabulary_size)\n",
    "if not USE_PTB:\n",
    "    print(word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Tokenizer indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "\n",
    "USE_TENSORFLOW = (not USE_NATIVE)\n",
    "if USE_TENSORFLOW:\n",
    "    # Each text in \"texts\" is a complete document as one string, \n",
    "    # e.g \"To be or not to be, that is the question.\"\n",
    "    texts = [ corpus ]   \n",
    "\n",
    "    # fit_on_texts() processes multiple documents and handles all words in all the documents.\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    word_to_id = tokenizer.word_index\n",
    "\n",
    "    # texts_to_sequences() ruturns sequences, one sequence for each text in \"texts\".\n",
    "    sequences = (tokenizer.texts_to_sequences(texts))\n",
    "    sequence = sequences[0]\n",
    "\n",
    "    print(len(sequences))\n",
    "    print(len(word_to_id))\n",
    "    \n",
    "    # Index of tokenizer.word_index starts at 1, NOT 0.\n",
    "    # e.g. {'<OOV>': 1, 'the': 2, 'fool': 3, 'wise': 4, 'doth': 5, ...}\n",
    "    vocabulary_size = max(word_to_id.values()) + 1\n",
    "    print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PTB:\n",
    "    print(\"word to id \\n{}\".format(word_to_id))\n",
    "    print(\"id to word \\n{}\".format(id_to_word))\n",
    "    print()\n",
    "    print(\"corpus is \\n[{}]\".format(corpus))\n",
    "    print(\"sequence is \\n{}\".format(sequence))\n",
    "    print(\"corpus size is {} sequence size is {} expected sum is {}\".format(\n",
    "        len(re.compile('[\\t\\s]+').split(corpus)), \n",
    "        len(sequence), \n",
    "        (len(sequence) - (2*STRIDE)) * (2*STRIDE)  # Exclude NIL from the sequence\n",
    "    ))\n",
    "    #print([id_to_word[index] for index in sequence])\n",
    "    print(np.array([id_to_word[index] for index in sequence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-occurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np.analytics import (\n",
    "    create_cooccurrence_matrix,\n",
    "    cooccurrence_words,\n",
    "    word_frequency,\n",
    "    total_frequencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = create_cooccurrence_matrix(sequence, vocabulary_size, CONTEXT_SIZE)\n",
    "\n",
    "if VALIDATION:\n",
    "    print(matrix.shape)\n",
    "\n",
    "    if not USE_PTB:\n",
    "        print(matrix)\n",
    "        print(\"com.sum() {}\".format(matrix.sum()))\n",
    "\n",
    "    assert total_frequencies(matrix, word_to_id, CONTEXT_SIZE, NIL) == len(sequence) - (CONTEXT_SIZE -1)\n",
    "    assert np.array_equal(com0, com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
