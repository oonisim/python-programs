{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Command line"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8033737f7549783"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /home/eml/venv/ml/lib/python3.10/site-packages (0.16.4)\r\n",
      "Collecting huggingface_hub[cli]\r\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m330.1/330.1 KB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.31.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (2023.9.2)\r\n",
      "Requirement already satisfied: filelock in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.9.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.9.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.64.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (23.2)\r\n",
      "Requirement already satisfied: InquirerPy==0.3.4 in /home/eml/venv/ml/lib/python3.10/site-packages (from huggingface_hub[cli]) (0.3.4)\r\n",
      "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /home/eml/venv/ml/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (0.3.4)\r\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /home/eml/venv/ml/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.41)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eml/venv/ml/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eml/venv/ml/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2023.11.17)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/eml/venv/ml/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/eml/venv/ml/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.3.2)\r\n",
      "Requirement already satisfied: wcwidth in /home/eml/venv/ml/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.12)\r\n",
      "Installing collected packages: huggingface_hub\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.16.4\r\n",
      "    Uninstalling huggingface-hub-0.16.4:\r\n",
      "      Successfully uninstalled huggingface-hub-0.16.4\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "deepdoctection 0.28 requires pyyaml==6.0, but you have pyyaml 6.0.1 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed huggingface_hub-0.20.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub[cli] --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:59:00.509091894Z",
     "start_time": "2023-12-30T14:58:57.827267108Z"
    }
   },
   "id": "1445b12171996641"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>]\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  {env,login,whoami,logout,repo,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}\r\n",
      "                        huggingface-cli command helpers\r\n",
      "    env                 Print information about the environment.\r\n",
      "    login               Log in using a token from\r\n",
      "                        huggingface.co/settings/tokens\r\n",
      "    whoami              Find out which huggingface.co account you are logged\r\n",
      "                        in as.\r\n",
      "    logout              Log out\r\n",
      "    repo                {create, ls-files} Commands to interact with your\r\n",
      "                        huggingface.co repos.\r\n",
      "    lfs-enable-largefiles\r\n",
      "                        Configure your repository to enable upload of files >\r\n",
      "                        5GB.\r\n",
      "    lfs-multipart-upload\r\n",
      "                        Command will get called by git-lfs, do not call it\r\n",
      "                        directly.\r\n",
      "    scan-cache          Scan cache directory.\r\n",
      "    delete-cache        Delete revisions from the cache directory.\r\n",
      "\r\n",
      "options:\r\n",
      "  -h, --help            show this help message and exit\r\n"
     ]
    }
   ],
   "source": [
    "! huggingface-cli --help"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T14:58:45.678016558Z",
     "start_time": "2023-12-30T14:58:45.406913229Z"
    }
   },
   "id": "16bdb3bc3ad32612"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>] download [-h]\r\n",
      "                                                   [--repo-type {model,dataset,space}]\r\n",
      "                                                   [--revision REVISION]\r\n",
      "                                                   [--include [INCLUDE ...]]\r\n",
      "                                                   [--exclude [EXCLUDE ...]]\r\n",
      "                                                   [--cache-dir CACHE_DIR]\r\n",
      "                                                   [--local-dir LOCAL_DIR]\r\n",
      "                                                   [--local-dir-use-symlinks {auto,True,False}]\r\n",
      "                                                   [--force-download]\r\n",
      "                                                   [--resume-download]\r\n",
      "                                                   [--token TOKEN] [--quiet]\r\n",
      "                                                   repo_id [filenames ...]\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  repo_id               ID of the repo to download from (e.g. `username/repo-\r\n",
      "                        name`).\r\n",
      "  filenames             Files to download (e.g. `config.json`,\r\n",
      "                        `data/metadata.jsonl`).\r\n",
      "\r\n",
      "options:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --repo-type {model,dataset,space}\r\n",
      "                        Type of repo to download from (e.g. `dataset`).\r\n",
      "  --revision REVISION   An optional Git revision id which can be a branch\r\n",
      "                        name, a tag, or a commit hash.\r\n",
      "  --include [INCLUDE ...]\r\n",
      "                        Glob patterns to match files to download.\r\n",
      "  --exclude [EXCLUDE ...]\r\n",
      "                        Glob patterns to exclude from files to download.\r\n",
      "  --cache-dir CACHE_DIR\r\n",
      "                        Path to the directory where to save the downloaded\r\n",
      "                        files.\r\n",
      "  --local-dir LOCAL_DIR\r\n",
      "                        If set, the downloaded file will be placed under this\r\n",
      "                        directory either as a symlink (default) or a regular\r\n",
      "                        file. Check out https://huggingface.co/docs/huggingfac\r\n",
      "                        e_hub/guides/download#download-files-to-local-folder\r\n",
      "                        for more details.\r\n",
      "  --local-dir-use-symlinks {auto,True,False}\r\n",
      "                        To be used with `local_dir`. If set to 'auto', the\r\n",
      "                        cache directory will be used and the file will be\r\n",
      "                        either duplicated or symlinked to the local directory\r\n",
      "                        depending on its size. It set to `True`, a symlink\r\n",
      "                        will be created, no matter the file size. If set to\r\n",
      "                        `False`, the file will either be duplicated from cache\r\n",
      "                        (if already exists) or downloaded from the Hub and not\r\n",
      "                        cached.\r\n",
      "  --force-download      If True, the files will be downloaded even if they are\r\n",
      "                        already cached.\r\n",
      "  --resume-download     If True, resume a previously interrupted download.\r\n",
      "  --token TOKEN         A User Access Token generated from\r\n",
      "                        https://huggingface.co/settings/tokens\r\n",
      "  --quiet               If True, progress bars are disabled and only the path\r\n",
      "                        to the download files is printed.\r\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download --help"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-30T14:59:05.357607290Z"
    }
   },
   "id": "d043f187ae1a822e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\r\n",
      "Fetching 14 files:   0%|                                 | 0/14 [00:00<?, ?it/s]downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/1_Pooling/config.json to /home/eml/.cache/huggingface/hub/tmp944nf_m6\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/.gitattributes to /home/eml/.cache/huggingface/hub/tmpti3fc99a\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/2_Dense/pytorch_model.bin to /home/eml/.cache/huggingface/hub/tmpans9egzg\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/config_sentence_transformers.json to /home/eml/.cache/huggingface/hub/tmp46wu1chj\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/README.md to /home/eml/.cache/huggingface/hub/tmpw3xprmmr\r\n",
      "\r\n",
      "1_Pooling/config.json: 100%|████████████████████| 190/190 [00:00<00:00, 561kB/s]\u001B[A\r\n",
      "\r\n",
      ".gitattributes: 100%|██████████████████████| 1.18k/1.18k [00:00<00:00, 4.58MB/s]\u001B[A\r\n",
      "Fetching 14 files:   7%|█▊                       | 1/14 [00:01<00:14,  1.08s/it]\r\n",
      "config_sentence_transformers.json: 100%|████████| 122/122 [00:00<00:00, 583kB/s]\u001B[A\r\n",
      "\r\n",
      "README.md: 100%|███████████████████████████| 1.90k/1.90k [00:00<00:00, 6.77MB/s]\u001B[A\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/2_Dense/config.json to /home/eml/.cache/huggingface/hub/tmpvxxuj8i_\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/modules.json to /home/eml/.cache/huggingface/hub/tmp1acsuotn\r\n",
      "downloading https://huggingface.co/sentence-transformers/gtr-t5-large/resolve/fd31cff184d356b3a9a5794706551fc5306071a2/sentence_bert_config.json to /home/eml/.cache/huggingface/hub/tmpls9c_oun\r\n",
      "\r\n",
      "2_Dense/config.json: 100%|██████████████████████| 116/116 [00:00<00:00, 729kB/s]\u001B[A\r\n",
      "Fetching 14 files:  21%|█████▎                   | 3/14 [00:01<00:04,  2.41it/s]\r\n",
      "modules.json: 100%|████████████████████████████| 461/461 [00:00<00:00, 2.70MB/s]\u001B[A\r\n",
      "\r\n",
      "sentence_bert_config.json: 100%|██████████████| 53.0/53.0 [00:00<00:00, 432kB/s]\u001B[A\r\n",
      "\r\n",
      "pytorch_model.bin:   0%|                            | 0.00/3.15M [00:00<?, ?B/s]\u001B[A\r\n",
      "pytorch_model.bin: 100%|███████████████████| 3.15M/3.15M [00:01<00:00, 2.73MB/s]\u001B[A\r\n",
      "Fetching 14 files: 100%|████████████████████████| 14/14 [00:02<00:00,  4.83it/s]\r\n",
      "/home/eml/.cache/huggingface/hub/models--sentence-transformers--gtr-t5-large/snapshots/fd31cff184d356b3a9a5794706551fc5306071a2\r\n"
     ]
    }
   ],
   "source": [
    "! huggingface-cli download sentence-transformers/gtr-t5-large"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T15:00:41.327155901Z",
     "start_time": "2023-12-30T15:00:36.452398991Z"
    }
   },
   "id": "39fd522f902cdbb4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c0415f3fc56138c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
