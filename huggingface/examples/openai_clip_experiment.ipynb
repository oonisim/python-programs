{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44fe5ce0-e04c-4a87-adae-635b47f6958d",
   "metadata": {},
   "source": [
    "# OpenAI CLIP Demo\n",
    "\n",
    "Using [Github Minimal user-friendly demo of OpenAI's CLIP](https://github.com/vivien000/clip-demo) also available at [Huggingface CLIP demo](https://huggingface.co/spaces/vivien/clip).\n",
    "\n",
    "* [Huggingface CLIP model](https://huggingface.co/docs/transformers/main/en/model_doc/clip)\n",
    "* [Huggingface Model openai/clip-vit-base-patch32](https://huggingface.co/openai/clip-vit-base-patch32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e8441-5a60-4160-a1f4-c81ea8887ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch tensorflow > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ee63e-486e-40da-8578-dfceba0ad925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pathlib\n",
    "import urllib.request\n",
    "import urllib\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool\n",
    "from typing import (\n",
    "    List,\n",
    "    Dict,\n",
    "    Callable,\n",
    "    Any,\n",
    "    Union,\n",
    "    Optional\n",
    ")\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    CLIPProcessor, \n",
    "    CLIPTextModel, \n",
    "    CLIPModel, \n",
    "    logging\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bc3da-714a-44ef-8937-51d1c3dc0398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.get_verbosity = lambda: logging.NOTSET\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d05fa",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_CPU: str = 'cpu'\n",
    "DEVICE_CUDA: str = 'cuda'\n",
    "DEVICE_IS_CUDA: bool = torch.cuda.is_available()\n",
    "DEVICE = torch.device(DEVICE_CUDA if torch.cuda.is_available() else DEVICE_CPU)\n",
    "DEVICE_TYPE: str = DEVICE.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7068dd",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS: int = multiprocessing.cpu_count()\n",
    "RUN_EMBEDDING: bool = True\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "MODEL_NAME: str = \"openai/clip-vit-base-patch32\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098abd6-4e00-4b1f-8648-dbbf990332c9",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad87eb2-9820-430b-8a6f-94c0af8d7956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_url(url_filename, data_dir=DATA_DIR):\n",
    "    try:\n",
    "        url, filename = url_filename\n",
    "        urllib.request.urlretrieve(url, os.path.join(data_dir, filename))\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(f\"featch URL:[{url}] filename:[{filename}] failed due to {error}\")\n",
    "\n",
    "def get_fetch_url(data_dir):\n",
    "    def fetch(url_filename):\n",
    "        fetch_url(url_filename, data_dir)\n",
    "        \n",
    "    return fetch\n",
    "\n",
    "def load_image(path_to_file, same_height=False):\n",
    "    try:\n",
    "        im = Image.open(path_to_file)\n",
    "        if im.mode != 'RGB':\n",
    "            im = im.convert('RGB')\n",
    "        if same_height:\n",
    "            ratio = 224/im.size[1]\n",
    "            return im.resize((int(im.size[0]*ratio), int(im.size[1]*ratio)))    \n",
    "        else:\n",
    "            ratio = 224/min(im.size)\n",
    "            return im.resize((int(im.size[0]*ratio), int(im.size[1]*ratio)))\n",
    "    except FileNotFoundError as error:\n",
    "        print(f\"path: {os.path.join(data_dir, path)} does not exist.\")\n",
    "        \n",
    "        \n",
    "def is_file(path, data_dir=DATA_DIR):\n",
    "    return pathlib.Path(os.path.join(data_dir, path)).is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d82ac5-8d04-4493-a7fe-7d93684b6820",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccd5d3-c766-4e3a-9a63-2bb41a9d07d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pathlib.Path(DATA_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e95772-e7b3-4ffb-aba3-ebaea96d7158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    'https://drive.google.com/uc?export=download&id=1bt1O-iArKuU9LGkMV1zUPTEHZk8k7L65', \n",
    "    os.path.join(DATA_DIR, 'unsplush.csv')\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    'https://drive.google.com/uc?export=download&id=19aVnFBY-Rc0-3VErF_C7PojmWpBsb5wk', \n",
    "    os.path.join(DATA_DIR, 'movies.csv')\n",
    ")\n",
    "# urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1onKr-pfWb4l6LgL-z8WDod3NMW-nIJxE', 'embeddings.npy')\n",
    "# urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1KbwUkE0T8bpnHraqSzTeGGV4-TZO_CFB', 'embeddings2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07ea68-6e5b-4767-a94c-5df80bb98166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download(df, data_dir:str = DATA_DIR, fetch_fn=None):\n",
    "    max_n_parallel = NUM_CPUS * 3\n",
    "    latency = 1  # idle duration to reduce the download rate for the images\n",
    "    divider = 200\n",
    "    length = len(df)\n",
    "    print(f\"total images:[{length}]\")\n",
    "\n",
    "    position: int = 0\n",
    "    while position < length:\n",
    "        n_parallel = min(max_n_parallel, length - position)\n",
    "        url_filename_list = [\n",
    "            (df.iloc[position + increment]['path'], str(position + increment) + '.jpeg') \n",
    "            for increment in range(n_parallel)\n",
    "        ]\n",
    "        _ = Pool(n_parallel).map(fetch_fn, url_filename_list)\n",
    "        position += n_parallel\n",
    "\n",
    "        if position // divider > 0:\n",
    "            print(position)\n",
    "            divider += 200\n",
    "\n",
    "        time.sleep(latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78e0f9-12be-4d4c-a929-d59b1076a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in ['unsplush', 'movies']:\n",
    "for name in ['movies']:\n",
    "    data_dir: str = os.path.join(DATA_DIR, name)\n",
    "    pathlib.Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, f'{name}.csv'))\n",
    "    download(df=df, data_dir=data_dir, fetch_fn=get_fetch_url(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9b249-dbd7-4a0b-aee4-7baaf6c33d55",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0c4c9-0a17-4a55-af26-466295c03b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", from_tf=True)\n",
    "model = CLIPModel.from_pretrained(MODEL_NAME)\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4705b4f-d332-41eb-b088-20b530429099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEVICE_IS_CUDA:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7cb2a",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "* [compute_CLIP_embeddings.ipynb](https://github.com/vivien000/clip-demo/blob/master/compute_CLIP_embeddings.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def compute_text_embeddings(\n",
    "    queries: List[str], model: torch.nn.Module, device: torch.device\n",
    "):\n",
    "    inputs = processor(text=queries, return_tensors=\"pt\", padding=True)\n",
    "    inputs.to(device)\n",
    "    return model.get_text_features(**inputs)\n",
    "\n",
    "\n",
    "def compute_image_embeddings(\n",
    "    images: List[np.ndarray], model: torch.nn.Module, device: torch.device\n",
    "):\n",
    "    processed = processor(images=images, return_tensors=\"pt\", padding=True)\n",
    "    processed['pixel_values'] = processed['pixel_values'].to(device)\n",
    "    \n",
    "    # return model.get_image_features(**processor(images=list_of_images, return_tensors=\"pt\", padding=True))    \n",
    "    return model.get_image_features(**processed)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800cffa-2c46-431e-a502-3c9685c00002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_image_embeddings(\n",
    "    image_dir:str, \n",
    "    model: torch.nn.Module, \n",
    "    device: torch.device,\n",
    "    path_to_embedding_file:str, \n",
    "):\n",
    "    files: List[str] = glob.glob(os.path.join(image_dir, '*.jpeg'))\n",
    "    num_files: int = len(files)\n",
    "    assert num_files > 0\n",
    "\n",
    "    image_embeddings: np.ndarray = None\n",
    "    position :int = 0      # Current position \n",
    "    batch_size: int = 32\n",
    "    checkpoint_size: int = batch_size * 10\n",
    "\n",
    "    def path_to_file(position, index) -> str:\n",
    "        return os.path.join(\n",
    "            image_dir,\n",
    "            str(position + index) + '.jpeg'\n",
    "        )\n",
    "    \n",
    "    while position < num_files:\n",
    "        images: List[np.ndarray] = [\n",
    "            load_image(path_to_file=path_to_file(position=position, index=index)) \n",
    "            for index in range(batch_size)\n",
    "            if is_file(str(position + index) + '.jpeg')\n",
    "        ]\n",
    "        assert len(images) > 0\n",
    "        \n",
    "        batch_embeddings = compute_image_embeddings(images=images, model=model, device=device)\n",
    "        if device.type == DEVICE_CUDA:\n",
    "            batch_embeddings = batch_embeddings.cpu()\n",
    "\n",
    "        batch_embeddings = batch_embeddings.detach().numpy()\n",
    "\n",
    "        if image_embeddings is None:\n",
    "            image_embeddings = batch_embeddings\n",
    "        else:\n",
    "            image_embeddings = np.vstack((image_embeddings, batch_embeddings))\n",
    "\n",
    "        position += batch_size\n",
    "        assert position >= image_embeddings.shape[0], \\\n",
    "            f\"expected position:[{position}] > size of embeddings:[{image_embeddings.shape[0]}]\"\n",
    "\n",
    "        # Save the current embeddings\n",
    "        if position // checkpoint_size > 0:\n",
    "            checkpoint_size += batch_size * 10\n",
    "            np.save(path_to_embedding_file, image_embeddings)\n",
    "            print(position)\n",
    "\n",
    "    np.save(path_to_embedding_file, image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b807d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EMBEDDING:\n",
    "    for name in ['unsplush', 'movies']:\n",
    "        image_dir: str = os.path.join(DATA_DIR, name)\n",
    "        path_to_embedding_file: str = f\"embedding_{name}.npy\"\n",
    "        run_image_embeddings(\n",
    "            image_dir=image_dir, \n",
    "            path_to_embedding_file=path_to_embedding_file, \n",
    "            model=model\n",
    "            device=DEVICE\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63386fd",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00765492-ce49-4a6c-89d6-c61033d64cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes: Dict[int, pd.DataFrame] = {\n",
    "    0: pd.read_csv('unsplush.csv'), \n",
    "    1: pd.read_csv('movies.csv')\n",
    "}\n",
    "embeddings = {\n",
    "    0: np.load(\"embedding_unsplush.npy\"), \n",
    "    1: np.load(\"embedding_movies.npy\")\n",
    "}\n",
    "\n",
    "for k in [0, 1]:\n",
    "    embeddings[k] = np.divide(\n",
    "        embeddings[k], \n",
    "        np.sqrt(np.sum(embeddings[k]**2, axis=1, keepdims=True))\n",
    "    )\n",
    "\n",
    "source = {\n",
    "    0: '\\nSource: Unsplash', \n",
    "    1: '\\nSource: The Movie Database (TMDB)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745e4a5-367a-4ccd-a609-4f932ef394d2",
   "metadata": {},
   "source": [
    "# Image Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53783acf-b93d-48a3-8109-beb59bc8608f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_html(url_list, height=200):\n",
    "    html = \"<div style='margin-top: 20px; display: flex; flex-wrap: wrap; justify-content: space-evenly'>\"\n",
    "    for url, title, link in url_list:\n",
    "        html2 = f\"<img title='{title}' style='height: {height}px; margin-bottom: 10px' src='{url}'>\"\n",
    "        if len(link) > 0:\n",
    "            html2 = f\"<a href='{link}' target='_blank'>\" + html2 + \"</a>\"\n",
    "        html = html + html2\n",
    "    html += \"</div>\"\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e7442-1c45-4bc9-9b32-1588d2317de5",
   "metadata": {},
   "source": [
    "# Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1003345-2a87-4ae6-a1ed-d6d61f7944b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = image_search(\"lion\")\n",
    "result[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a37d34-76b3-47b7-970d-ae34cc67bb98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = widgets.Text(layout=widgets.Layout(width='400px'))\n",
    "dataset =widgets.Dropdown(\n",
    "    options=['Unsplash', 'Movies'],\n",
    "    value='Unsplash'\n",
    ")\n",
    "button = widgets.Button(description=\"Search\")\n",
    "output = widgets.Output()\n",
    "\n",
    "display(\n",
    "    widgets.HBox(\n",
    "        [query, button, dataset],\n",
    "        layout=widgets.Layout(justify_content='center')\n",
    "    ),\n",
    "    output\n",
    ")\n",
    "\n",
    "def image_search(\n",
    "    query: str, model: torch.nn.Module, device:torch.device, n_results: int = 12\n",
    "):\n",
    "    text_embeddings = compute_text_embeddings(queries=[query], model=model, device=device)\n",
    "    if device.type == DEVICE_CUDA:\n",
    "        text_embeddings = text_embeddings.cpu()\n",
    "        \n",
    "    text_embeddings = text_embeddings.detach().numpy()\n",
    "    \n",
    "    k = 0 if dataset.value == 'Unsplash' else 1\n",
    "    results = np.argsort((embeddings[k] @ text_embeddings.T)[:, 0])[-1:-n_results-1:-1]\n",
    "    return [\n",
    "        (df[k].iloc[i]['path'], df[k].iloc[i]['tooltip'] + source[k], df[k].iloc[i]['link']) \n",
    "        for i in results\n",
    "    ]\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    if len(query.value) > 0:\n",
    "        results = image_search(query=query.value, model=model, device=DEVICE)\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            display(HTML(get_html(results)))\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "dataset.observe(on_button_clicked, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228268ae-12ea-4f74-9854-31e22ecbf7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
