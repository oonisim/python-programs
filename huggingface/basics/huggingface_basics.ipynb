{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94da98cc",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [Quick Tour](https://huggingface.co/docs/transformers/main/en/quicktour)\n",
    "* [Transformers Notebooks](https://github.com/huggingface/transformers/tree/main/notebooks)\n",
    "\n",
    "> You can find here a list of the official notebooks provided by Hugging Face.\n",
    "\n",
    "* [Fine tuning the model](https://huggingface.co/docs/transformers/main/en/training)\n",
    "\n",
    "> ### Fine-tune a pretrained model  \n",
    "> There are significant benefits to using a pretrained model. It reduces computation costs, your carbon footprint, and allows you to use state-of-the-art models without having to train one from scratch. ðŸ¤— Transformers provides access to thousands of pretrained models for a wide range of tasks. When you use a pretrained model, you train it on a dataset specific to your task. This is known as fine-tuning, an incredibly powerful training technique. In this tutorial, you will fine-tune a pretrained model with a deep learning framework of your choice:\n",
    "> \n",
    "> * Fine-tune a pretrained model with ðŸ¤— Transformers Trainer.\n",
    "> * Fine-tune a pretrained model in TensorFlow with Keras.\n",
    "> * Fine-tune a pretrained model in native PyTorch.\n",
    "\n",
    "See the [Transformers Notebooks](https://github.com/huggingface/transformers/tree/main/notebooks) as well.\n",
    "\n",
    "* [Hugging Face course](https://huggingface.co/course/chapter0/1?fw=pt)\n",
    "\n",
    "> Welcome to the Hugging Face course! This introduction will guide you through setting up a working environment. If youâ€™re just starting the course, we recommend you first take a look at Chapter 1, then come back and set up your environment so you can try the code yourself.\n",
    "\n",
    "* [Huggingface Github - pipeline source](https://github.com/huggingface/transformers/blob/main/src/transformers/pipelines/__init__.py#L494)\n",
    "\n",
    "---\n",
    "\n",
    "# HuggingFace on SageMaker\n",
    "\n",
    "* [Hugging Face on Amazon SageMaker](https://huggingface.co/docs/sagemaker/index)\n",
    "* [Deploy models to Amazon SageMaker](https://huggingface.co/docs/sagemaker/inference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662e9cc",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888ef34",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "A utility class for convenience.\n",
    "\n",
    "* [pipeline](https://huggingface.co/transformers/main_classes/pipelines.html?highlight=pipeline#transformers.pipeline)\n",
    "\n",
    "> These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. See the task summary for examples of use.\n",
    "><br>\n",
    "\n",
    "\n",
    "Based on the task specified, ```pipeline``` auto-loads the appropriate model pretrained for the task.\n",
    "\n",
    "## Tutorial\n",
    "\n",
    "See:\n",
    "* [Summary of the tasks](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)\n",
    "* [Quick Tour](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)\n",
    "\n",
    "## Available Tasks\n",
    "\n",
    "> * \"feature-extraction\" -  FeatureExtractionPipeline\n",
    "> * \"text-classification\" -  TextClassificationPipeline\n",
    "> * \"sentiment-analysis\" (alias of \"text-classification\") TextClassificationPipeline\n",
    "> * \"token-classification\" -  TokenClassificationPipeline\n",
    "> * \"ner\" (alias of \"token-classification\") - TokenClassificationPipeline\n",
    "> * \"question-answering\" -  QuestionAnsweringPipeline\n",
    "> * \"fill-mask\" -  FillMaskPipeline\n",
    "> * \"summarization\" -  SummarizationPipeline\n",
    "> * \"translation_xx_to_yy\" -  TranslationPipeline\n",
    "> * \"text2text-generation\" -  Text2TextGenerationPipeline\n",
    "> * \"text-generation\" -  TextGenerationPipeline\n",
    "> * \"zero-shot-classification: -  ZeroShotClassificationPipeline\n",
    "> * \"conversational\" -  ConversationalPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ace279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-03 13:48:23.005540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-03 13:48:23.005586: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da2cf98fc9f492b90fb81c5f8fe4edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed8e6a027b5474da1e14ba4e0bef244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-03 13:49:37.849765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-03 13:49:37.849826: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-03 13:49:37.849858: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2021-07-03 13:49:37.851011: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-03 13:49:37.886386: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52aec7208b1945c6a78510b5388ed5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a89af1b42c4372bcc77ca62a15b821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, with score: 0.9991\n",
      "label: POSITIVE, with score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", framework='tf')\n",
    "\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = classifier(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e7bf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b570a707ec3048d5b13744f1e1dbd318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281d82a3355a43859688625154c08c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed0c6dfc58c4570a8e0179e4f981af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b36899d885f4075921c4ca75f99bbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5ea00b55b347fc95ec8c7cee747dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'Conversation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_117293/3825715033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconversational_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conversational\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconversation_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Going to the movies tonight - any suggestions?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconversation_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What's the last book you have read?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conversation' is not defined"
     ]
    }
   ],
   "source": [
    "Conversation = pipeline(\"conversational\")\n",
    "\n",
    "conversation_1 = Conversation(\"Going to the movies tonight - any suggestions?\")\n",
    "conversation_2 = Conversation(\"What's the last book you have read?\")\n",
    "\n",
    "conversational_pipeline([conversation_1, conversation_2])\n",
    "\n",
    "conversation_1.add_user_input(\"Is it an action movie?\")\n",
    "conversation_2.add_user_input(\"What is the genre of this book?\")\n",
    "\n",
    "conversational_pipeline([conversation_1, conversation_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efdb1b",
   "metadata": {},
   "source": [
    "---\n",
    "# Using specific Model\n",
    "\n",
    "Use ```TFAutoModelForSequenceClassification``` and ```AutoTokenizer``` to load the pretrained model and itâ€™s associated tokenizer.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.\")\n",
    "```\n",
    "\n",
    "See for details:\n",
    "* [Auto Model](https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f359cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
