{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debc1e39-c50c-4b56-a293-3dfc7cc92512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c30aeb-bcd0-49b6-9044-6abbfb1af5d0",
   "metadata": {},
   "source": [
    "# Hugging Face LLM Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9456a4-b7c8-4742-ae28-f4eb36a31ccc",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "\n",
    "* [HF - PEFT](https://huggingface.co/docs/peft/en/index) ([github](https://github.com/huggingface/peft))\n",
    "* [HF - LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)\n",
    "* [Fine-Tuning Large Language Models (LLMs)](https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91)\n",
    "```\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01,\n",
    "                        target_modules = ['q_lin']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ce760-1dd1-47e2-9bd1-7305b5d85740",
   "metadata": {},
   "source": [
    "# Find Tuning Tools\n",
    "\n",
    "## [Unsloth](https://unsloth.ai/) ([Github](https://github.com/unslothai/unsloth))\n",
    "\n",
    "> Finetune Llama 3.2, Mistral, Phi-3.5 & Gemma 2-5x faster with 80% less memory!\n",
    "\n",
    "* [Unsloth Guide: Optimize and Speed Up LLM Fine-Tuning (OCT 2024)](https://www.datacamp.com/tutorial/unsloth-guide-optimize-and-speed-up-llm-fine-tuning)\n",
    "> Fine-tuning the Llama 3.1 model to solve specialized algebra problems with high accuracy and detailed results using Unsloth.\n",
    "> Unsloth AI is a Python framework designed for fast fine-tuning and accessing large language models. It offers a simple API and performance that is 2x faster compared to Transformers. \n",
    "\n",
    "* [HF - Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth](https://huggingface.co/blog/mlabonne/sft-llama3) ([colab](https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z)) MUST\n",
    "\n",
    "> In this article, we will provide a comprehensive overview of supervised fine-tuning. We will compare it to prompt engineering to understand when it makes sense to use it, detail the main techniques with their pros and cons, and introduce major concepts, such as LoRA hyperparameters, storage formats, and chat templates. Finally, we will implement it in practice by fine-tuning Llama 3.1 8B in Google Colab with state-of-the-art optimization using Unsloth.\n",
    "\n",
    "* [LLAMA-3.1 ðŸ¦™: EASIET WAY To FINE-TUNE ON YOUR DATA](https://www.youtube.com/watch?v=rpAtVIZB72U) ([colab](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp))\n",
    "\n",
    "## [Axolotl.ai](https://axolotl.ai/) ([github](https://github.com/axolotl-ai-cloud/axolotl))\n",
    "\n",
    "> Axolotl is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple configurations and architectures.\n",
    "\n",
    "\n",
    "## Transformer Reinforcement Learning (TRL)\n",
    "* [TRL - Transformer Reinforcement Learning](https://huggingface.co/docs/trl/en/index#trl---transformer-reinforcement-learning)\n",
    "\n",
    "> TRL is a full stack library where we provide a set of tools to train transformer language models with Reinforcement Learning, from the Supervised Fine-tuning step (SFT), Reward Modeling step (RM) to the Proximal Policy Optimization (PPO) step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20689b3b-045b-4820-8def-bb1e7c2b3b99",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "* [Large Language Model Course by Maxime Labonne](https://github.com/mlabonne/llm-course) MUST\n",
    "\n",
    "### Fine Tuning\n",
    "\n",
    "|              Notebook             |                              Description                              |\n",
    "|:---------------------------------:|:---------------------------------------------------------------------:|\n",
    "| Fine-tune Llama 2 with QLoRA      | Step-by-step guide to supervised fine-tune Llama 2 in Google Colab.   |\n",
    "| Fine-tune CodeLlama using Axolotl | End-to-end guide to the state-of-the-art tool for fine-tuning.        |\n",
    "| Fine-tune Mistral-7b with QLoRA   | Supervised fine-tune Mistral-7b in a free-tier Google Colab with TRL. |\n",
    "| Fine-tune Mistral-7b with DPO     | Boost the performance of supervised fine-tuned models with DPO.       |\n",
    "| Fine-tune Llama 3 with ORPO       | Cheaper and faster fine-tuning in a single stage with ORPO.           |\n",
    "| Fine-tune Llama 3.1 with Unsloth  | Ultra-efficient supervised fine-tuning in Google Colab.               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c763df-971c-476b-b77c-0cf57673b172",
   "metadata": {},
   "source": [
    "\n",
    "### Quantization\n",
    "\n",
    "|                  Notebook                  |                                   Description                                  |\n",
    "|:------------------------------------------:|:------------------------------------------------------------------------------:|\n",
    "|Introduction to Quantization               | Large language model optimization using 8-bit quantization.                    |\n",
    "| 4-bit Quantization using GPTQ              | Quantize your own open-source LLMs to run them on consumer hardware.           |\n",
    "| Quantization with GGUF and llama.cpp       | Quantize Llama 2 models with llama.cpp and upload GGUF versions to the HF Hub. |\n",
    "| ExLlamaV2: The Fastest Library to Run LLMs | Quantize and run EXL2 models and upload them to the HF Hub.                    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
