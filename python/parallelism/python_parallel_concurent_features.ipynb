{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692abc24",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "**Python only uses one thread on 1 CPU by default**.\n",
    "\n",
    "\n",
    "* generator, asyncio, threads run on **single kernel thread on 1 CPU**. One gets the [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) and gets hold of it until surrenders it.\n",
    "* generator, asyncio are not parallel-safe (often said as *not thread-safe*).\n",
    "* generator, asyncio are same with Windows 3.x. Switch only occurs when the current execution ```yields``` or surrender the single thread on 1 CPU.\n",
    "* context switch among threads is rather naive as in \n",
    "[How does python handle thread locking / context switching?](https://stackoverflow.com/a/33352871/4281353)\n",
    ">  The way Python threads work with the GIL is with a simple counter. With every 100 byte codes executed the GIL is supposed to be released by the thread currently executing in order to give other threads a chance to execute code. When you use a thread lock Python will only execute the threads that are not locked. So if you have several threads sharing 1 lock, then only one thread will execute at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a622510",
   "metadata": {},
   "source": [
    "# Threading vs asyncio\n",
    "\n",
    "If multiple tasks on the one-threaded execution is I/O bound, use asyncio because **yielding** or voluntarily surrendering the single thread/CPU is much efficient than the naive thread context switch. Because when the I/O-wait happens is the best timing to surrender the 1 CPU. \n",
    "\n",
    "\n",
    "To evenly execute multiple tasks, use threading. However, the application is **dominated by waiting** on completions such as I/O, consider the async/coroutine approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db292d15",
   "metadata": {},
   "source": [
    "# Principle\n",
    "\n",
    "Stick to:\n",
    "\n",
    "* Fit for the purpose\n",
    "* Stick to purpose designed\n",
    "\n",
    "Python has been designed and implemented with 1 thread on 1 CPU in mind when 1 CPU in core on a computer was normal. Attempts to fit such 1 thread on 1 CPU into multi CPU parallel or distributed nodes paradigm does not fit for the purpose.\n",
    "\n",
    "Consider using purpose built framework e.g. Ray or other programming languages when parallel processing is by design required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669d471",
   "metadata": {},
   "source": [
    "# Concurrency vs Parallel\n",
    "\n",
    "In Python, **curncurrency** is mostly used on switching tasks on 1 thread on 1 CPU. Hence for genefator or asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5950033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
